{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# graph\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "#  for multicolinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 All year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = ['Month', 'Time']\n",
    "\n",
    "dict_dtypes = {x : 'str'  for x in string_cols}\n",
    "\n",
    "# 1. all year data\n",
    "all_year = pd.read_csv('./Data/weather_st2', index_col = 0, dtype = dict_dtypes)\n",
    "j9 = pd.read_csv('./Data/weather_j9', index_col = 0, dtype = dict_dtypes)\n",
    "\n",
    "# 2. score data\n",
    "scores_df = pd.read_csv('./Data/score', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_year.drop(labels = ['CHWTON'], axis =1)\n",
    "Y = all_year['CHWTON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 20)\n",
    "\n",
    "# 2. Train\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_RF = RandomForestRegressor(n_estimators = 100, random_state = 20)\n",
    "model_RF.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tuning using RandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to set the parameter for our RF regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 150, 200, 250, 300], 'max_depth': [2, 6, 10, 15, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [2, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 6)]\n",
    "\n",
    "# 2. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 15, num = 4)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 3. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 4. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 2, 5, 10]\n",
    "\n",
    "# 5. Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 6, 10, 15, None],\n",
       "                                        'min_samples_leaf': [2, 5, 10],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300]},\n",
       "                   random_state=20, scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 20,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': 15,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 200,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "0.9325812455674513\n"
     ]
    }
   ],
   "source": [
    "# print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(rf_random.best_estimator_.get_params())\n",
    "pprint(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_type</th>\n",
       "      <th>RF_allyear</th>\n",
       "      <th>RF_J9_AZ</th>\n",
       "      <th>RF_J9_micro</th>\n",
       "      <th>RF_J9_AZ_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.937572</td>\n",
       "      <td>0.876395</td>\n",
       "      <td>0.854341</td>\n",
       "      <td>0.890315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.491681</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.463167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score_type  RF_allyear  RF_J9_AZ  RF_J9_micro  RF_J9_AZ_random\n",
       "0         R2    0.937572  0.876395     0.854341         0.890315\n",
       "1       RMSE    0.896675  0.491681     0.533744         0.463167"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # June 9th prediction\n",
    "# # 1. get X Y\n",
    "X_j9 = j9.drop(labels = ['CHWTON'], axis =1)\n",
    "Y_j9 = j9['CHWTON']\n",
    "\n",
    "# 2. Ypred\n",
    "Y_pred_random_j9 = rf_best.predict(X_j9)\n",
    "\n",
    "# 3. Score\n",
    "R2_j9_random = rf_best.score(X_j9, Y_j9)\n",
    "RMSE_j9_random = np.sqrt(metrics.mean_squared_error(Y_j9, Y_pred_random_j9))\n",
    "\n",
    "# 4. append to score df\n",
    "score_J9_random = [R2_j9_random, RMSE_j9_random]\n",
    "scores_df['RF_J9_AZ_random'] = score_J9_random\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "all_year_dum = pd.read_csv('./Data/weather_st', index_col = 0, dtype = dict_dtypes)\n",
    "all_year_dum = all_year_dum.drop(labels = ['Hour_num', 'Month_num','Minute_num'], axis = 1)\n",
    "\n",
    "# 1. dummify dates and time\n",
    "all_year_dum = pd.get_dummies(all_year_dum, prefix=None, prefix_sep='_')\n",
    "\n",
    "# 2. get j9 data\n",
    "j9_dum = all_year_dum.iloc[15150:15246]\n",
    "\n",
    "# 3. concat j9_dum with j9 to remove non 0 minute\n",
    "j9_dum =  pd.concat([j9_dum, j9.drop(labels = ['Air Temp', 'Rel Humid', 'KW'], axis = 1)], axis = 1, join = \"inner\")\n",
    "\n",
    "# 3. drop June 9th data on original data\n",
    "all_year_dum = all_year_dum.drop(all_year_dum.index[15150:15246])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get X and Y\n",
    "X_dum = all_year_dum.drop(labels = ['CHWTON'], axis =1)\n",
    "\n",
    "# 5. Train test split\n",
    "X_train_dum, X_test_dum, Y_train, Y_test = train_test_split(X_dum, Y, test_size=0.2, random_state = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 398.09 seconds for 20 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "    'n_estimators':[50, 100 , 250],\n",
    "    'min_child_weight':[4,5], \n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "reg = XGBRegressor()\n",
    "\n",
    "n_iter_search = 20\n",
    "xgb_random = RandomizedSearchCV(reg,\n",
    "                                param_distributions = params,\n",
    "                                n_iter = n_iter_search,\n",
    "                                cv = 5,\n",
    "                                verbose = 2,\n",
    "                                random_state = 20,\n",
    "                                scoring ='r2',\n",
    "                                n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "xgb_random.fit(X_train_dum, Y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5,\n",
      " 'booster': 'gbtree',\n",
      " 'colsample_bylevel': 1,\n",
      " 'colsample_bynode': 1,\n",
      " 'colsample_bytree': 0.6,\n",
      " 'eta': 0.3,\n",
      " 'eval_metric': 'rmse',\n",
      " 'gamma': 0.4,\n",
      " 'gpu_id': -1,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': '',\n",
      " 'learning_rate': 0.300000012,\n",
      " 'max_delta_step': 0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': '()',\n",
      " 'n_estimators': 250,\n",
      " 'n_jobs': 0,\n",
      " 'num_parallel_tree': 1,\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 0,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 1,\n",
      " 'scale_pos_weight': 1,\n",
      " 'subsample': 1.0,\n",
      " 'tree_method': 'exact',\n",
      " 'validate_parameters': 1,\n",
      " 'verbosity': None}\n",
      "0.9061622427610543\n"
     ]
    }
   ],
   "source": [
    "# 1. print winning set of hyperparameters\n",
    "pprint(xgb_random.best_estimator_.get_params())\n",
    "pprint(xgb_random.best_score_)\n",
    "\n",
    "# 2. save model\n",
    "xgb_best = xgb_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_type</th>\n",
       "      <th>RF_allyear</th>\n",
       "      <th>RF_J9_AZ</th>\n",
       "      <th>RF_J9_micro</th>\n",
       "      <th>RF_J9_AZ_random</th>\n",
       "      <th>XGB_J9_AZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.937572</td>\n",
       "      <td>0.876395</td>\n",
       "      <td>0.854341</td>\n",
       "      <td>0.890315</td>\n",
       "      <td>0.829280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.491681</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.463167</td>\n",
       "      <td>0.577838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score_type  RF_allyear  RF_J9_AZ  RF_J9_micro  RF_J9_AZ_random  XGB_J9_AZ\n",
       "0         R2    0.937572  0.876395     0.854341         0.890315   0.829280\n",
       "1       RMSE    0.896675  0.491681     0.533744         0.463167   0.577838"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# June 9th prediction\n",
    "# 1. get X\n",
    "X_j9_dum = j9_dum.drop(labels = ['CHWTON', 'Month', 'Time'], axis = 1)\n",
    "\n",
    "# 2. Ypred\n",
    "Y_pred_xgb_j9 = xgb_best.predict(X_j9_dum)\n",
    "\n",
    "# 3. Score\n",
    "R2_j9_xgb = xgb_best.score(X_j9_dum, Y_j9)\n",
    "RMSE_j9_xgb = np.sqrt(metrics.mean_squared_error(Y_j9, Y_pred_xgb_j9))\n",
    "\n",
    "# 4. append to score df\n",
    "score_J9_xgb = [R2_j9_xgb, RMSE_j9_xgb]\n",
    "scores_df['XGB_J9_AZ'] = score_J9_xgb\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

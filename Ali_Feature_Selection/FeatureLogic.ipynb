{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a7ed99-6fce-4e30-82e1-1d5ee3feaf87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea609698-9482-468b-943f-bb61cc1c2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from functions import print_bold, create_pkl, load_pkl, load_latest_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8516b1d3-d7d3-4bab-b3a8-16ebc6c25747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest pickle file (dfs.pkl) loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "pkl_file = 'dfs'\n",
    "\n",
    "## Load latest file for pkl_file\n",
    "dfs = load_latest_pkl(pkl_file)\n",
    "PSYCHOLOGY = 0\n",
    "PSYCHOLOGY_NORTH = 1\n",
    "ISTB_4 = 2\n",
    "\n",
    "basePsy = pd.DataFrame(dfs['Scenarios'][ISTB_4])\n",
    "basePsy\n",
    "# Iterate over each group\n",
    "for scenario, group in basePsy.groupby('Scenario'):\n",
    "    # Format the directory name (lowercase and replace spaces with underscores for consistency)\n",
    "    dir_name = f'../data/dataset3/{scenario.replace(\" \", \"_\").lower()}'\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        \n",
    "    # Define the file path\n",
    "    file_path = os.path.join(dir_name, 'Istb_4.csv')\n",
    "    \n",
    "    # Save the group to a CSV file\n",
    "    group.to_csv(file_path, index=False)  # Set 'index=False' if you don't want to save the index\n",
    "\n",
    "    \n",
    "## Define variables\n",
    "# base,scen='Baseline','Scenarios'\n",
    "# bld_list = ['Psychology', 'Psychology North', 'ISTB 4']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303c424-8a28-4c62-9b77-5aa9b8fa3673",
   "metadata": {},
   "source": [
    "    Example Use of dfs:\n",
    "\n",
    "    dfs['Baseline'][bld_list.index('Psychology')]\n",
    "    dfs['Scenarios'][bld_list.index('Psychology North')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b748a-e6fd-4776-b98e-7dd707140916",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions and How to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1070f-5110-45e3-ae8e-2a88a4e231b1",
   "metadata": {},
   "source": [
    "**How to select a combination of variables for selected facades**  \n",
    "\n",
    "Define a list then use add_lists() function, which takes in variable lists below \n",
    "\n",
    "    Example:  \n",
    "      \n",
    "    X_vars = [KW, AirT, AirP, RelH]\n",
    "    fac = ['Top', 'North', 'East']\n",
    "    X_vars = vars_facades(X_vars,fac,var_facades)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c672919-beb9-4c09-a690-132892e3c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "KWm2   = 'KW/SQM'\n",
    "KW     = 'KW'\n",
    "HTm2   = 'HTmmBTU/SQM'\n",
    "HT     = 'HTmmBTU'\n",
    "HR     = 'Hour'\n",
    "AirT   = ['AirT_Top', 'AirT_North', 'AirT_East', 'AirT_South', 'AirT_West', 'AirT_Mean']\n",
    "AirP   = ['AirP_Top', 'AirP_North', 'AirP_East', 'AirP_South', 'AirP_West']\n",
    "RelH   = ['RelH_Top', 'RelH_North', 'RelH_East', 'RelH_South', 'RelH_West', 'RelH_Mean']\n",
    "AbsH   = ['AbsH_Top', 'AbsH_North', 'AbsH_East', 'AbsH_South', 'AbsH_West', 'AbsH_Mean']\n",
    "Wind   = ['Wind_Top', 'Wind_North', 'Wind_East', 'Wind_South', 'Wind_West', 'Wind_Mean']\n",
    "ShortW = ['ShortW_Top', 'ShortW_North', 'ShortW_East', 'ShortW_South', 'ShortW_West', 'Shade_Top', 'Shade_North', 'Shade_East', 'Shade_South', 'Shade_West']\n",
    "LongW  = ['LongW_Top', 'LongW_North', 'LongW_East', 'LongW_South', 'LongW_West']\n",
    "RadT   = ['RadT_Top', 'RadT_North', 'RadT_East', 'RadT_South', 'RadT_West']\n",
    "all_vars = [KWm2] + [KW] + [HTm2] + [HT] + [HR] + AirT + AirP + RelH + AbsH + Wind + ShortW + LongW + RadT\n",
    "\n",
    "def var_facades(feature, facades):\n",
    "    v_fs = []\n",
    "    for fac in facades:\n",
    "        v_fs = v_fs + [item for item in feature if item.split('_', 1)[1] == fac]\n",
    "    return v_fs\n",
    "def vars_facades(features,facades,var_facades=None):\n",
    "    vs_fs = []\n",
    "    if var_facades:\n",
    "        for feat in features:\n",
    "            if isinstance(feat, str):\n",
    "                vs_fs.append(feat)\n",
    "            elif isinstance(feat, list) and all(isinstance(item, str) for item in feat):\n",
    "                vs_fs = vs_fs + var_facades(feat, facades)\n",
    "            else:\n",
    "                pass      \n",
    "    return vs_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e0fb1-18af-449a-8f95-f6f35f571807",
   "metadata": {},
   "source": [
    "**How to get X and y**  \n",
    "\n",
    "**Get X and y by giving the X_y_data() function y_var (the y variable) and X_vars (all the x variables)**  \n",
    "\n",
    "    EXAMPLE:  \n",
    "    \n",
    "    y_var='CHWTON'\n",
    "    X_vars=['Hour','AirT_Top','RelH_Top']\n",
    "    X_base_dic,y_base_dic,X_scen_dic,y_scen_dic = X_y_data(X_vars, y_var)\n",
    "\n",
    "\n",
    "**Selecting Baseline by Building Name** : :   X_base_dic['Building Name']\n",
    "\n",
    "    EXAMPLE:\n",
    "    \n",
    "    X_base_dic['ISTB 4']\n",
    "    y_base_dic['Psychology North']\n",
    "**Selecting Scenarios by Building Name and Scenarios Name** : :  X_scen_dic['Building Name']['Scenario_Name']  \n",
    "\n",
    "    EXAMPLE:    \n",
    "    \n",
    "    X_scen_dic['Psychology']['Cool_Pavement']\n",
    "    X_scen_dic['Psychology']['Wall_Shade']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac97302-0534-4687-9792-3c6da1d8e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(dfs,X_vars,y_var,building,scen_base,scen=''):\n",
    "    bld_list = ['Psychology', 'Psychology North', 'ISTB 4']\n",
    "    idx = bld_list.index(building)\n",
    "    df = dfs[scen_base][idx]\n",
    "    if scen_base == 'Baseline':\n",
    "        X,y = df[X_vars], df[y_var]\n",
    "    else:\n",
    "        df = df[df['Scenario'] == scen]\n",
    "        X,y = df[X_vars], df[y_var]\n",
    "        \n",
    "    return X, y\n",
    "def X_y_data(X_vars, y_vars):\n",
    "    X_base_dic = {key: None for key in bld_list}\n",
    "    y_base_dic = {key: None for key in bld_list}\n",
    "    X_scen_dic = {key: {} for key in bld_list}\n",
    "    y_scen_dic = {key: {} for key in bld_list}\n",
    "    for idx,b in enumerate(bld_list):\n",
    "        X_base_dic[b], y_base_dic[b] = get_X_y(dfs=dfs, \n",
    "                                               X_vars=X_vars, \n",
    "                                               y_var=y_var, \n",
    "                                               building=b, \n",
    "                                               scen_base='Baseline')\n",
    "        for s in dfs[scen][idx]['Scenario'].unique():\n",
    "            df = dfs[scen][idx]\n",
    "            df = df[df['Scenario'] == s]\n",
    "            X_scen_dic[b][s], y_scen_dic[b][s] = get_X_y(dfs=dfs, \n",
    "                                               X_vars=X_vars, \n",
    "                                               y_var=y_var, \n",
    "                                               building=b, \n",
    "                                               scen_base='Scenarios', scen=s)\n",
    "    return (X_base_dic,y_base_dic,X_scen_dic,y_scen_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7df0a1-56d2-4e0a-995d-73df9d9f166d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Examples, Feature Selection, and Getting X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bee4b-2f2f-46fc-929a-e01b0521acc3",
   "metadata": {},
   "source": [
    "**Get (X, y) data in (X_dic, y_dic) for list of variables for specific facades**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bb0ac-378f-4740-b155-c2e4265e039e",
   "metadata": {},
   "source": [
    "Variable Options --> KWm2 , KW , HTm2 , HT , HR , AirT , AirP , RelH , AbsH , Wind , ShortW , LongW , RadT  \n",
    "For All Variable --> all_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70aa8bf3-366a-4d40-b9d0-02dd210e4f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_vars = [KW, HR, AirT, AirP, RelH]\n",
    "fac = ['Top', 'North', 'East']\n",
    "X_vars = vars_facades(X_vars,fac,var_facades)\n",
    "y_var='CHWTON'\n",
    "\n",
    "X_base_dic,y_base_dic,X_scen_dic,y_scen_dic = X_y_data(X_vars, y_var)\n",
    "\n",
    "## Loop over X and y dictionaries \n",
    "for b in bld_list:\n",
    "    X = X_base_dic[b]\n",
    "    y = y_base_dic[b]\n",
    "    # Perform X and y operations below this line\n",
    "    ## code here ##\n",
    "    for s in dfs['Scenarios'][0]['Scenario'].unique():\n",
    "        X_s = X_scen_dic[b][s]\n",
    "        y_s = y_scen_dic[b][s]\n",
    "        # Perform X_s and y_s Operations below this line\n",
    "        ## code here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f03dda-967b-4cf0-a956-a4634fe0911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KW</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AirT_Top</th>\n",
       "      <th>AirT_North</th>\n",
       "      <th>AirT_East</th>\n",
       "      <th>AirP_Top</th>\n",
       "      <th>AirP_North</th>\n",
       "      <th>AirP_East</th>\n",
       "      <th>RelH_Top</th>\n",
       "      <th>RelH_North</th>\n",
       "      <th>RelH_East</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-03 05:00:00</th>\n",
       "      <td>115.33</td>\n",
       "      <td>5</td>\n",
       "      <td>22.753289</td>\n",
       "      <td>21.967301</td>\n",
       "      <td>22.163870</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>24.575123</td>\n",
       "      <td>26.039355</td>\n",
       "      <td>25.670397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03 05:15:00</th>\n",
       "      <td>116.74</td>\n",
       "      <td>5</td>\n",
       "      <td>22.189748</td>\n",
       "      <td>22.031662</td>\n",
       "      <td>22.443350</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>27.958344</td>\n",
       "      <td>30.043552</td>\n",
       "      <td>27.913478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03 05:30:00</th>\n",
       "      <td>118.65</td>\n",
       "      <td>5</td>\n",
       "      <td>21.922418</td>\n",
       "      <td>21.670921</td>\n",
       "      <td>22.125737</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>27.753713</td>\n",
       "      <td>29.561067</td>\n",
       "      <td>27.690508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03 05:45:00</th>\n",
       "      <td>114.99</td>\n",
       "      <td>5</td>\n",
       "      <td>21.797758</td>\n",
       "      <td>21.493868</td>\n",
       "      <td>21.963489</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>27.896575</td>\n",
       "      <td>29.616969</td>\n",
       "      <td>27.836425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03 06:00:00</th>\n",
       "      <td>130.32</td>\n",
       "      <td>6</td>\n",
       "      <td>21.639051</td>\n",
       "      <td>21.292527</td>\n",
       "      <td>21.783249</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>27.996461</td>\n",
       "      <td>29.664269</td>\n",
       "      <td>27.950468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-13 22:45:00</th>\n",
       "      <td>121.01</td>\n",
       "      <td>22</td>\n",
       "      <td>39.866070</td>\n",
       "      <td>39.333752</td>\n",
       "      <td>39.643206</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>16.617879</td>\n",
       "      <td>16.979914</td>\n",
       "      <td>16.872741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-13 23:00:00</th>\n",
       "      <td>124.69</td>\n",
       "      <td>23</td>\n",
       "      <td>39.795682</td>\n",
       "      <td>39.257100</td>\n",
       "      <td>39.569846</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>16.610960</td>\n",
       "      <td>16.972853</td>\n",
       "      <td>16.870894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-13 23:15:00</th>\n",
       "      <td>125.98</td>\n",
       "      <td>23</td>\n",
       "      <td>39.671685</td>\n",
       "      <td>39.125970</td>\n",
       "      <td>39.452524</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>16.863582</td>\n",
       "      <td>17.251447</td>\n",
       "      <td>17.096013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-13 23:30:00</th>\n",
       "      <td>122.12</td>\n",
       "      <td>23</td>\n",
       "      <td>39.481918</td>\n",
       "      <td>38.925144</td>\n",
       "      <td>39.271220</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>17.417485</td>\n",
       "      <td>17.879763</td>\n",
       "      <td>17.631672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-13 23:45:00</th>\n",
       "      <td>119.78</td>\n",
       "      <td>23</td>\n",
       "      <td>39.271213</td>\n",
       "      <td>38.701126</td>\n",
       "      <td>39.068621</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>18.050562</td>\n",
       "      <td>18.591459</td>\n",
       "      <td>18.250105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1509 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         KW  Hour   AirT_Top  AirT_North  AirT_East  AirP_Top  \\\n",
       "Date_Time                                                                       \n",
       "2023-05-03 05:00:00  115.33     5  22.753289   21.967301  22.163870  0.000087   \n",
       "2023-05-03 05:15:00  116.74     5  22.189748   22.031662  22.443350  0.000090   \n",
       "2023-05-03 05:30:00  118.65     5  21.922418   21.670921  22.125737  0.000090   \n",
       "2023-05-03 05:45:00  114.99     5  21.797758   21.493868  21.963489  0.000091   \n",
       "2023-05-03 06:00:00  130.32     6  21.639051   21.292527  21.783249  0.000092   \n",
       "...                     ...   ...        ...         ...        ...       ...   \n",
       "2023-07-13 22:45:00  121.01    22  39.866070   39.333752  39.643206  0.000079   \n",
       "2023-07-13 23:00:00  124.69    23  39.795682   39.257100  39.569846  0.000080   \n",
       "2023-07-13 23:15:00  125.98    23  39.671685   39.125970  39.452524  0.000080   \n",
       "2023-07-13 23:30:00  122.12    23  39.481918   38.925144  39.271220  0.000081   \n",
       "2023-07-13 23:45:00  119.78    23  39.271213   38.701126  39.068621  0.000081   \n",
       "\n",
       "                     AirP_North  AirP_East   RelH_Top  RelH_North  RelH_East  \n",
       "Date_Time                                                                     \n",
       "2023-05-03 05:00:00    0.000558   0.003277  24.575123   26.039355  25.670397  \n",
       "2023-05-03 05:15:00    0.000555   0.003285  27.958344   30.043552  27.913478  \n",
       "2023-05-03 05:30:00    0.000555   0.003285  27.753713   29.561067  27.690508  \n",
       "2023-05-03 05:45:00    0.000555   0.003283  27.896575   29.616969  27.836425  \n",
       "2023-05-03 06:00:00    0.000554   0.003282  27.996461   29.664269  27.950468  \n",
       "...                         ...        ...        ...         ...        ...  \n",
       "2023-07-13 22:45:00    0.000682   0.004465  16.617879   16.979914  16.872741  \n",
       "2023-07-13 23:00:00    0.000682   0.004452  16.610960   16.972853  16.870894  \n",
       "2023-07-13 23:15:00    0.000682   0.004440  16.863582   17.251447  17.096013  \n",
       "2023-07-13 23:30:00    0.000682   0.004428  17.417485   17.879763  17.631672  \n",
       "2023-07-13 23:45:00    0.000683   0.004417  18.050562   18.591459  18.250105  \n",
       "\n",
       "[1509 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base_dic['Psychology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07f2bc4-7f6c-42e9-880f-95f26ed12819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KW</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AirT_Top</th>\n",
       "      <th>AirT_North</th>\n",
       "      <th>AirT_East</th>\n",
       "      <th>AirP_Top</th>\n",
       "      <th>AirP_North</th>\n",
       "      <th>AirP_East</th>\n",
       "      <th>RelH_Top</th>\n",
       "      <th>RelH_North</th>\n",
       "      <th>RelH_East</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-07 05:00:00</th>\n",
       "      <td>120.06</td>\n",
       "      <td>5</td>\n",
       "      <td>33.192825</td>\n",
       "      <td>31.752097</td>\n",
       "      <td>32.200205</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>16.547022</td>\n",
       "      <td>18.744312</td>\n",
       "      <td>18.030808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 05:15:00</th>\n",
       "      <td>122.69</td>\n",
       "      <td>5</td>\n",
       "      <td>31.536327</td>\n",
       "      <td>30.429439</td>\n",
       "      <td>31.106952</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>19.530020</td>\n",
       "      <td>22.060448</td>\n",
       "      <td>20.256823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 05:30:00</th>\n",
       "      <td>129.83</td>\n",
       "      <td>5</td>\n",
       "      <td>31.384425</td>\n",
       "      <td>30.225176</td>\n",
       "      <td>30.945300</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>19.229157</td>\n",
       "      <td>21.555420</td>\n",
       "      <td>19.904036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 05:45:00</th>\n",
       "      <td>119.98</td>\n",
       "      <td>5</td>\n",
       "      <td>31.265410</td>\n",
       "      <td>30.067066</td>\n",
       "      <td>30.822145</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>19.115522</td>\n",
       "      <td>21.368934</td>\n",
       "      <td>19.766133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 06:00:00</th>\n",
       "      <td>133.21</td>\n",
       "      <td>6</td>\n",
       "      <td>31.142929</td>\n",
       "      <td>29.939922</td>\n",
       "      <td>30.712110</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>18.997878</td>\n",
       "      <td>21.179887</td>\n",
       "      <td>19.626329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 22:30:00</th>\n",
       "      <td>124.97</td>\n",
       "      <td>22</td>\n",
       "      <td>37.696020</td>\n",
       "      <td>36.644255</td>\n",
       "      <td>37.174315</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>10.717249</td>\n",
       "      <td>11.505262</td>\n",
       "      <td>11.073083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 22:45:00</th>\n",
       "      <td>122.86</td>\n",
       "      <td>22</td>\n",
       "      <td>37.529240</td>\n",
       "      <td>36.458664</td>\n",
       "      <td>37.005471</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>10.673709</td>\n",
       "      <td>11.457724</td>\n",
       "      <td>11.036489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 23:00:00</th>\n",
       "      <td>123.10</td>\n",
       "      <td>23</td>\n",
       "      <td>37.365820</td>\n",
       "      <td>36.283051</td>\n",
       "      <td>36.842097</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>10.609534</td>\n",
       "      <td>11.384406</td>\n",
       "      <td>10.977022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 23:15:00</th>\n",
       "      <td>119.67</td>\n",
       "      <td>23</td>\n",
       "      <td>37.218550</td>\n",
       "      <td>36.117061</td>\n",
       "      <td>36.688579</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>10.576805</td>\n",
       "      <td>11.348026</td>\n",
       "      <td>10.942418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 23:30:00</th>\n",
       "      <td>118.94</td>\n",
       "      <td>23</td>\n",
       "      <td>37.113553</td>\n",
       "      <td>36.005070</td>\n",
       "      <td>36.579036</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>10.600485</td>\n",
       "      <td>11.379048</td>\n",
       "      <td>10.966730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         KW  Hour   AirT_Top  AirT_North  AirT_East  AirP_Top  \\\n",
       "Date_Time                                                                       \n",
       "2023-07-07 05:00:00  120.06     5  33.192825   31.752097  32.200205  0.000072   \n",
       "2023-07-07 05:15:00  122.69     5  31.536327   30.429439  31.106952  0.000074   \n",
       "2023-07-07 05:30:00  129.83     5  31.384425   30.225176  30.945300  0.000075   \n",
       "2023-07-07 05:45:00  119.98     5  31.265410   30.067066  30.822145  0.000075   \n",
       "2023-07-07 06:00:00  133.21     6  31.142929   29.939922  30.712110  0.000075   \n",
       "...                     ...   ...        ...         ...        ...       ...   \n",
       "2023-07-07 22:30:00  124.97    22  37.696020   36.644255  37.174315  0.000033   \n",
       "2023-07-07 22:45:00  122.86    22  37.529240   36.458664  37.005471  0.000034   \n",
       "2023-07-07 23:00:00  123.10    23  37.365820   36.283051  36.842097  0.000034   \n",
       "2023-07-07 23:15:00  119.67    23  37.218550   36.117061  36.688579  0.000034   \n",
       "2023-07-07 23:30:00  118.94    23  37.113553   36.005070  36.579036  0.000035   \n",
       "\n",
       "                     AirP_North  AirP_East   RelH_Top  RelH_North  RelH_East  \n",
       "Date_Time                                                                     \n",
       "2023-07-07 05:00:00    0.000420   0.002837  16.547022   18.744312  18.030808  \n",
       "2023-07-07 05:15:00    0.000415   0.002714  19.530020   22.060448  20.256823  \n",
       "2023-07-07 05:30:00    0.000414   0.002696  19.229157   21.555420  19.904036  \n",
       "2023-07-07 05:45:00    0.000414   0.002680  19.115522   21.368934  19.766133  \n",
       "2023-07-07 06:00:00    0.000413   0.002665  18.997878   21.179887  19.626329  \n",
       "...                         ...        ...        ...         ...        ...  \n",
       "2023-07-07 22:30:00    0.000296   0.002086  10.717249   11.505262  11.073083  \n",
       "2023-07-07 22:45:00    0.000296   0.002075  10.673709   11.457724  11.036489  \n",
       "2023-07-07 23:00:00    0.000295   0.002065  10.609534   11.384406  10.977022  \n",
       "2023-07-07 23:15:00    0.000295   0.002055  10.576805   11.348026  10.942418  \n",
       "2023-07-07 23:30:00    0.000295   0.002046  10.600485   11.379048  10.966730  \n",
       "\n",
       "[75 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scen_dic['Psychology']['Trees_Light']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25b9f9-3b5f-460b-981b-0c394e224166",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Choosing the Right Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916e8bb-b0ec-4df0-8ee5-d6177ce3b177",
   "metadata": {},
   "source": [
    "**Problem Specificity:** The best feature selection method depends on your specific problem, the nature of your data, and the type of model you're building. For predictive modeling where accuracy is paramount, and multicollinearity is not a concern, model-based methods like feature importances or permutation importance can be very effective.\n",
    "\n",
    "**Exploration:** Often, the most successful approach involves trying multiple feature selection methods and comparing their impact on model performance. This exploratory phase can also offer insights into the data and how different features influence the prediction.\n",
    "\n",
    "**Computational Resources:** Some methods, especially wrapper methods like RFE, can be computationally intensive. Consider your available computational resources when choosing an approach.\n",
    "\n",
    "Given the variety of methods at your disposal, starting with the ones you mentioned should be adequate for most models. However, incorporating additional techniques like mutual information or Boruta can further enhance your feature selection process, especially if you seek to understand the underlying data structure or ensure that you're not missing important features that could improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616f451-3624-4920-b09c-3e892ea1a910",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sklearn Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e43065-4c8c-4427-b61c-3b7c9e8c1c88",
   "metadata": {},
   "source": [
    "**Implementation Tips:\n",
    "Cross-Validation: Always use cross-validation to evaluate feature selection methods to ensure that the selected features generalize well to unseen data.\n",
    "Experiment: There is no one-size-fits-all method for feature selection. It's often beneficial to experiment with multiple approaches and compare their performance on a validation set or via cross-validation.\n",
    "By focusing on these approaches, you can iteratively refine your feature set to improve model accuracy without worrying about multicollinearity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77bf83-0c63-4c97-b9c9-8eb63fffdc7c",
   "metadata": {},
   "source": [
    "## 1. Wrapper Methods Recursive Feature Elimination (RFE):\n",
    "This method fits a model and removes the weakest feature (or features) until the specified number of features is reached. With cross-validation (RFECV), it can find the optimal number of features that maximize the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915c3e77-a5db-4948-b05e-50fab362e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4d0c02-c45b-45d3-9422-fb8af69165fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Hour', 'Minute', 'Building', 'KW', 'KW/SQM',\n",
       "       'CHWTON', 'CHWTON/SQM', 'HTmmBTU', 'HTmmBTU/SQM', 'AirT_Top',\n",
       "       'AirT_North', 'AirT_East', 'AirT_South', 'AirT_West', 'AirT_Mean',\n",
       "       'RelH_Top', 'RelH_North', 'RelH_East', 'RelH_South', 'RelH_West',\n",
       "       'RelH_Mean', 'AbsH_Top', 'AbsH_North', 'AbsH_East', 'AbsH_South',\n",
       "       'AbsH_West', 'AbsH_Mean', 'Wind_Top', 'Wind_North', 'Wind_East',\n",
       "       'Wind_South', 'Wind_West', 'Wind_Mean', 'AirP_Top', 'AirP_North',\n",
       "       'AirP_East', 'AirP_South', 'AirP_West', 'ShortW_Top', 'ShortW_North',\n",
       "       'ShortW_East', 'ShortW_South', 'ShortW_West', 'LongW_Top',\n",
       "       'LongW_North', 'LongW_East', 'LongW_South', 'LongW_West', 'RadT_Top',\n",
       "       'RadT_North', 'RadT_East', 'RadT_South', 'RadT_West', 'Shade_Top',\n",
       "       'Shade_North', 'Shade_East', 'Shade_South', 'Shade_West'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['Baseline'][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da465800-330c-4b76-93ab-bc419e08bee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_lists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Get X and y data for X:[KW, HT, AirT] variables for all facades\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43madd_lists\u001b[49m(X_vars, [KW, HT, AirT])\n\u001b[1;32m      3\u001b[0m y_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCHWTON\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m X_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirT_Top\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelH_Top\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_lists' is not defined"
     ]
    }
   ],
   "source": [
    "## Get X and y data for X:[KW, HT, AirT] variables for all facades\n",
    "add_lists(X_vars, [KW, HT, AirT])\n",
    "y_var='CHWTON'\n",
    "X_vars=['Hour','AirT_Top','RelH_Top']\n",
    "X_base_dic,y_base_dic,X_scen_dic,y_scen_dic = X_y_data(X_vars, y_var)\n",
    "\n",
    "estimator = RandomForestRegressor()\n",
    "selector = RFECV(estimator, step=1, cv=KFold(n_splits=5), scoring='neg_mean_squared_error')\n",
    "\n",
    "## Perform for each building and save results\n",
    "\n",
    "RFE_dic = {key: None for key in bld_list}\n",
    "for b in bld_list:\n",
    "    X = X_base_dic[b]\n",
    "    y = y_base_dic[b]\n",
    "    selector = selector.fit(X, y)\n",
    "    X_selected = selector.transform(X)\n",
    "    RFE_dic[b] = X_selected\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8bccee-1c22-47ea-9647-e349061c90db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RFE_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mRFE_dic\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPsychology\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RFE_dic' is not defined"
     ]
    }
   ],
   "source": [
    "RFE_dic['Psychology']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387b0e8-3a1b-4373-9b5c-5d7106a153ce",
   "metadata": {},
   "source": [
    "## 2. Embedded Methods\n",
    "Feature Importance from Tree-based Models: Models like Random Forest, Extra Trees, and Gradient Boosting can inherently provide feature importances based on how each feature contributes to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1383fb3-c554-4ffd-bcf7-488a8eada1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Select features based on importance threshold\n",
    "indices = np.argsort(importances)[::-1]\n",
    "selected_features = [X.columns[i] for i in indices if importances[i] > threshold]  # Define your threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373001d-a573-4f78-8750-d37a48704764",
   "metadata": {},
   "source": [
    "## 3. Model-Agnostic Methods\n",
    "Permutation Feature Importance: This technique involves randomly shuffling individual features and measuring the change in the model's performance. Features that significantly decrease model performance when shuffled are considered important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caee43-dde9-4a95-b5f4-0ddf51e8b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(model, X, y, n_repeats=10)\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "X_selected = X[X.columns[perm_sorted_idx]]  # Adjust based on importance threshold or top N features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e0e56-0df4-42f7-b85f-e3c2435ff857",
   "metadata": {},
   "source": [
    "4. Algorithm-Specific Techniques\n",
    "Lasso Regression (L1 Regularization): For linear models, Lasso can shrink some coefficients to zero, effectively performing feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2078486-d0ae-4b1d-a9bd-b0c587085a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model = LassoCV(cv=5).fit(X, y)\n",
    "importance = np.abs(model.coef_)\n",
    "print(importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d784326-e648-4c3d-8c44-bc7e79d875f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# High-level Libraries for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce4f9d-a1f9-4964-899d-80093197ad7f",
   "metadata": {},
   "source": [
    "**Several Python libraries offer sophisticated tools and methods for feature selection, simplifying the process by providing high-level APIs. These can be particularly useful in automating the selection process, handling multicollinearity, and improving model accuracy. Here are details on three notable libraries:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812aff5-040a-42c4-8c19-341d482746bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Feature-engine  \n",
    "Feature-engine is a feature selection library that offers a wide array of techniques, including selection methods based on statistical tests, feature importance, and correlation strategies.\n",
    "\n",
    "        Installation:\n",
    "           pip install feature-engine\n",
    "        \n",
    "        Key Features:\n",
    "           DropCorrelatedFeatures: Removes correlated features.\n",
    "           SelectByShuffling: Evaluates feature importance through shuffling.\n",
    "           SmartCorrelatedSelection: Selects a representative from a group of correlated features based on performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3015d7-59da-4b54-a695-2abc04da55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "\n",
    "# Initialize the selector\n",
    "sel = DropCorrelatedFeatures(variables=None, method=\"pearson\", threshold=0.8)\n",
    "\n",
    "# Fit the selector\n",
    "sel.fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_selected = sel.transform(X_train)\n",
    "X_test_selected = sel.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b1710-3589-44fb-bb33-0ec1b0a3bbff",
   "metadata": {},
   "source": [
    "## 2. BorutaPy  \n",
    "An all-relevant feature selection method that uses random forests. Boruta tries to find all features carrying information usable for prediction, thus providing a more comprehensive set.\n",
    "\n",
    "        Installation: \n",
    "            pip install Boruta\n",
    "        \n",
    "        Key Features:\n",
    "            Works with any regressor that supports the feature_importances_ or coef_ attribute.\n",
    "            Employs a statistical test to decide on the importance of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53833c3-f548-4a14-b45c-311315631626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "boruta = BorutaPy(forest, n_estimators='auto', verbose=2, random_state=1)\n",
    "boruta.fit(X.values, y.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2797f7-74b5-432a-a184-b947793c7e39",
   "metadata": {},
   "source": [
    "## 3. Scikit-learn  \n",
    "Scikit-learn itself provides a comprehensive suite of feature selection methods, including recursive feature elimination, feature selection based on importance, and univariate statistical tests.\n",
    "\n",
    "        Key Methods:\n",
    "            SelectFromModel: Meta-transformer for selecting features based on importance weights.\n",
    "            RFECV: Feature ranking with recursive feature elimination and cross-validated selection of the best number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfdd9f-2f5b-4b24-aaaa-83a3beaf4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Initialize SelectFromModel\n",
    "sel = SelectFromModel(logistic)\n",
    "\n",
    "# Fit the selector\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "# Transform the dataset\n",
    "X_train_selected = sel.transform(X_train)\n",
    "X_test_selected = sel.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ddc7ff-3b33-4b69-aadd-b2449c3fe1bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Additional Techniques Worth Considering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c4304-f6bd-4b7b-82d6-c727ea4c21e0",
   "metadata": {},
   "source": [
    "## 1. Mutual Information \n",
    "A filter method that measures the dependency between variables. Unlike correlation, mutual information can capture any kind of relationship, not just linear ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903d49d-08ef-4e34-ad9e-21441f45f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mutual_info = mutual_info_regression(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3158e-b5de-4e56-946c-f20842eee3c9",
   "metadata": {},
   "source": [
    "## 2. Sequential Feature Selection\n",
    "This is another wrapper method that adds or removes features to form a feature subset in a greedy fashion. SequentialFeatureSelector from scikit-learn can be used for both forward selection and backward elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4576763-9fb5-4fc9-8d7e-74bd2f9ebf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sfs = SequentialFeatureSelector(LinearRegression(), n_features_to_select=10, direction='forward').fit(X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

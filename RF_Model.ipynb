{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f6a95c-cd5a-4267-a601-ad667c78e46e",
   "metadata": {},
   "source": [
    "Build a baseline model using the weather station data (this approach used all days in 2018 since the data was available).\n",
    "\n",
    "\n",
    "Then use the model to make predictions for the ENVI-met(micro-climate) data for that specific day and compare it to model predictions using weather station data also for the same day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e1207-9300-4a88-8a5c-018f487b78bf",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "\n",
    "#  for multicolinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "import PyQt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8de9e-804f-4b18-9045-f1c3f386126f",
   "metadata": {},
   "source": [
    "# 2. Import Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1cc7b-a97c-4f1a-bc03-a3a5f508eb33",
   "metadata": {},
   "source": [
    "## 2.1 Save csv files as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116d399-5c7a-47f3-8c0f-c0dc69e3e18d",
   "metadata": {},
   "source": [
    "Only run this once to save our csv data as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954bfc0-fd9e-48cf-8bee-b070ad6b8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> NO NEED TO RUN SAVED AS PICKLE FILES <--\n",
    "# WEATHER FILES ##\n",
    "\n",
    "# AZ PHX Sky Harbor Data #\n",
    "AZW_15 = pd.read_csv(\"./Data/Weather Data/KPHX-15.csv\")\n",
    "\n",
    "# ENVIMET DATA #\n",
    "BPS = []\n",
    "Fname = []\n",
    "for path in pathlib.Path(\"./Data/BPS\").iterdir():\n",
    "    if path.is_file():\n",
    "        current_file = pd.read_csv(path)\n",
    "        BPS.append(current_file)\n",
    "        Fname.append(path.name.replace('.csv', ''))\n",
    "\n",
    "# CAMPUS METABOLISM DATA #\n",
    "metabol14 = []\n",
    "for path in pathlib.Path('./Data/ASU 2018').iterdir():\n",
    "    if path.is_file():\n",
    "        current_file = pd.read_csv(path)\n",
    "        metabol14.append(current_file)\n",
    "\n",
    "## Drop last row of EnviMet Data\n",
    "for i in range(len(BPS)):\n",
    "    BPS[i] = BPS[i].drop(16)\n",
    "\n",
    "## Save files as pickle\n",
    "AZW_15.to_pickle(\"./Data/AZW_15.pkl\")\n",
    "\n",
    "with open('./Data/BPS.pkl', 'wb') as f:\n",
    "    pickle.dump(BPS, f)\n",
    "\n",
    "with open('./Data/Fname.pkl', 'wb') as f:\n",
    "    pickle.dump(Fname, f)\n",
    "\n",
    "with open('./Data/metabol14.pkl', 'wb') as f:\n",
    "    pickle.dump(metabol14, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a4864-e1d6-49c8-9a69-72d440091748",
   "metadata": {},
   "source": [
    "## 2.2 Reload Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8004c9-b0fc-4451-bd33-c3c54739a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Load AZ Weather Data (15-min)\n",
    "# weather_station = pd.read_pickle('AZW_15.pkl')\n",
    "\n",
    "# We will convert these to df depending on the building we choose\n",
    "# 2. Load 14 envimet bldgData (14 filtered buildings)\n",
    "with open('./Data/BPS.pkl', 'rb') as f:\n",
    "    envi14 = pickle.load(f)\n",
    "\n",
    "# 3. Load names of BPS files\n",
    "with open('./Data/Fname.pkl', 'rb') as f:\n",
    "    Fname = pickle.load(f)\n",
    "\n",
    "# 4. Load 14 campus metabolism building energy data\n",
    "with open('./Data/metabol14.pkl', 'rb') as f:\n",
    "    metabol14 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff27af-83bb-4831-8ee1-d76d132e7f13",
   "metadata": {},
   "source": [
    "## 2.3 Choose building name to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c48fa-6e04-463c-b72e-3365e3b6773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Print Building Names ##\n",
    "for i in range(len(Fname)):\n",
    "    print(Fname[i])\n",
    "    \n",
    "bldname = input('Enter building name: ')\n",
    "\n",
    "for i in range(len(envi14)):\n",
    "    if bldname == Fname[i]:\n",
    "        # save \n",
    "        envi_bldg = envi14[i]\n",
    "\n",
    "if bldname not in Fname:\n",
    "    print(\"\\x1b[31m\\\"Please enter a valid name from the list above\\\"\\x1b[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ffdc5-57f3-43e4-a5e5-97fe862a79a9",
   "metadata": {},
   "source": [
    "## 2.4 Create Data Frame for envimet and metabolism data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13e172-2ae4-455b-aebe-f8eb064195b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class building:\n",
    "    \n",
    "    def __init__(self, bldgname):\n",
    "        self.bldgname = bldgname\n",
    "    \n",
    "    def campusmetabolism(self):\n",
    "        for i in range(len(metabol14)):\n",
    "            if metabol14[i]['bldgname'][0] == bldname:\n",
    "                cmp = metabol14[i]\n",
    "        return cmp\n",
    "    \n",
    "    def envimet(self):\n",
    "        env = envi_bldg[['Date', 'Time', 'AirTempInFrontOfAllFacades_MEAN', 'RelativeAirHumidityInFrontOfAllFacades_MEAN',\n",
    "                     'WindSpeedInFrontOfAllFacades_MEAN']]\n",
    "        \n",
    "        env = env.rename(columns = {'AirTempInFrontOfAllFacades_MEAN':'Air Temp',\n",
    "                                    'RelativeAirHumidityInFrontOfAllFacades_MEAN':'Rel Humid',\n",
    "                                    'WindSpeedInFrontOfAllFacades_MEAN':'Wind Speed'})\n",
    "        return env\n",
    "\n",
    "\n",
    "Bldg = building(bldname)\n",
    "metabol = Bldg.campusmetabolism() # campus metabolism\n",
    "envimet = Bldg.envimet()          # envimet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87ea96-86c5-467f-b10b-8b97e3209ed6",
   "metadata": {},
   "source": [
    "## 2.5 Create Data Frame for weather station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e986022-d134-4495-ab48-640cf75919de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AZ Weather Data (15-min)\n",
    "weather_station = pd.read_pickle('./Data/AZW_15.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b284403b-4b4b-4cf8-919d-6b0b4a90be8b",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5060df-c598-4830-9411-f2a61f1cd6e7",
   "metadata": {},
   "source": [
    "## 3.1 Formatting Date and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e6d10-528d-4c9e-9af7-ad9a0871ce64",
   "metadata": {},
   "source": [
    "### a) Envimet dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ad52e-095f-45bf-b17b-4b1e68bcd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. format time\n",
    "envimet['Time'] = envimet['Time'].str.replace('.',':')\n",
    "envimet['Time'] = envimet['Time'].str.replace('01','00')\n",
    "\n",
    "# 2. convert to 24 hour format\n",
    "envimet['Time'] = pd.to_datetime(envimet['Time']).dt.strftime('%H:%M')\n",
    "\n",
    "# 3. format date (still in string)\n",
    "envimet['Date'] = pd.to_datetime(envimet['Date']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# 4. combine date time column as string and set as index\n",
    "envimet['Date_Time'] = envimet['Date'] + ' ' + envimet['Time']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1361645-341a-4d68-8ee1-7f7d22f1a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get string type for month and time\n",
    "envimet['Month'] = envimet['Date_Time'].str[0:2]\n",
    "envimet['Time'] = envimet['Time'].str.replace(':','')\n",
    "\n",
    "# 5. Rearrange columns\n",
    "envimet = envimet[['Date_Time','Month','Time', 'Air Temp', 'Rel Humid' ]]\n",
    "\n",
    "envimet = envimet.set_index('Date_Time')\n",
    "\n",
    "envimet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5f714-f56b-417b-92ec-f4a915675eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Get numeric for month hour and minute\n",
    "# microclimate.Date_Time = pd.to_datetime(microclimate.Date_Time)\n",
    "# microclimate['Month_num'] = microclimate.Date_Time.dt.month\n",
    "# microclimate['Hour_num'] = microclimate.Date_Time.dt.hour\n",
    "# microclimate['Minute_num'] = microclimate.Date_Time.dt.minute\n",
    "# microclimate.Date_Time = pd.to_datetime(microclimate.Date_Time).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# # 7. Rearrange columns\n",
    "# print(list(microclimate.columns))\n",
    "# microclimate = microclimate[['Date_Time','Month','Time','Month_num', 'Hour_num', 'Minute_num', 'Air Temp', 'Rel Humid' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ae739-f65a-4628-af3b-659d836db374",
   "metadata": {},
   "source": [
    "### c) Format weather station dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a46d7b-0964-4a40-b050-bb1573b272d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get string type for month and time\n",
    "weather_station['Month'] = weather_station['Date_Time'].str[0:2]\n",
    "weather_station['Time'] = weather_station['Date_Time'].str[11:]\n",
    "weather_station['Time'] = weather_station['Time'].str.replace(':','')\n",
    "\n",
    "# 2. Get numeric for month hour and minute\n",
    "weather_station.Date_Time = pd.to_datetime(weather_station.Date_Time)\n",
    "weather_station['Month_num'] = weather_station.Date_Time.dt.month\n",
    "weather_station['Hour_num'] = weather_station.Date_Time.dt.hour\n",
    "weather_station['Minute_num'] = weather_station.Date_Time.dt.minute\n",
    "weather_station.Date_Time = pd.to_datetime(weather_station.Date_Time).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# 3. set date time as index\n",
    "weather_station = weather_station.set_index('Date_Time') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59d7e7-c179-4b0e-b21e-f9251baabb7f",
   "metadata": {},
   "source": [
    "### d) Format Building energy dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1844c88-eaa2-4559-8aa7-3ea657c21f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabol.tstamp = pd.to_datetime(metabol.tstamp).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# remove unwanted columns\n",
    "metabol = metabol[['tstamp','KW', 'CHWTON']]\n",
    "\n",
    "# set date time as index\n",
    "metabol = metabol.set_index('tstamp')\n",
    "\n",
    "metabol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa15a6-0d08-4376-8178-1fe4861253a9",
   "metadata": {},
   "source": [
    "## 3.2 Append Energy Consumption to Weather Station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcf70a-15e1-4927-8e60-3ad37c51e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station =  pd.concat([metabol, weather_station], axis = 1, join = \"inner\")\n",
    "\n",
    "# rearrange column\n",
    "weather_station = weather_station[['Month','Time','Month_num', 'Hour_num', 'Minute_num', 'Air Temp', 'Rel Humid', 'KW','CHWTON' ]]\n",
    "weather_station "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de531c-38c7-4f97-ac61-c1190911ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_station.to_csv('./Data/weather_st')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1385a4a-bbf8-4ef0-9463-4ed2e7ab3e0b",
   "metadata": {},
   "source": [
    "# 4. Create June 9th Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea1607-36cf-49c4-9b6b-6d6c74bc4f96",
   "metadata": {},
   "source": [
    "## 4.1 For Microclimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68eda78-49d3-43b2-a168-3cf574ea3d5c",
   "metadata": {},
   "source": [
    "We want: month, hour, minute, CHWTON, KW, date, air temp, and real humidity for microclimate June 9th.\n",
    "We do this by merging with building_energy to get KW and CHWTON on the dates that appear in microclimate data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd1aa1-970d-4135-b009-61c014b4e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "envimet_j9 = pd.merge(envimet, metabol, left_index = True, right_index = True)\n",
    "envimet_j9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d8266-241c-4bbb-b5c3-139a441eb80c",
   "metadata": {},
   "source": [
    "## 4.2 For Weather Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a381c3b-9318-4246-9cd7-0c9226cc9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract june 9th data \n",
    "station_j9 = weather_station.iloc[15150:15246]\n",
    "\n",
    "# 2. Filter time ( only minute 00)\n",
    "station_j9 = station_j9[ (station_j9['Hour_num'] >= 5) & (station_j9['Hour_num'] <= 20) & (station_j9['Minute_num'] == 0)]\n",
    "\n",
    "# 3. drop June 9th data on original data\n",
    "weather_station = weather_station.drop(weather_station.index[15150:15246])\n",
    "\n",
    "# 4. drop numeric column\n",
    "weather_station = weather_station.drop(labels = ['Hour_num', 'Month_num','Minute_num'], axis = 1)\n",
    "station_j9 = station_j9.drop(labels = ['Hour_num', 'Month_num','Minute_num'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24970f-9f95-4193-85d5-b3591eca6a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_j9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebdd13c-9126-45d7-b490-bcb46c288c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. convert index to date time object\n",
    "weather_station.index = pd.to_datetime(weather_station.index)\n",
    "\n",
    "# 6. ensure theres no more june 9th data on weather_station data\n",
    "print(weather_station[(weather_station.index.month == 6) & (weather_station.index.day == 9)])\n",
    "\n",
    "# convert back\n",
    "# weather_station.index = pd.to_datetime(weather_station.index).dt.strftime('%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aca76d-465d-498f-847c-843c4c6679de",
   "metadata": {},
   "source": [
    "# 5. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d77199-f83f-40b3-a10b-690e4e53dc3a",
   "metadata": {},
   "source": [
    "## 5.1 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f833d54-9677-4c71-aba1-da46203054e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = weather_station.corr()\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(corrMatrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927e0df-112e-4fba-89d7-d019b9235067",
   "metadata": {},
   "source": [
    "## 5.2 Multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700cca6-109e-44b8-a079-87cc4faf8711",
   "metadata": {},
   "source": [
    "A simple method to detect multicollinearity in a model is by using something called the variance inflation factor or the VIF for each predicting variable. An acceptable VIF is if itâ€™s less than the max of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a826edd-daf9-496e-b92f-2bcadbd83703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and Y\n",
    "Y = weather_station['CHWTON']\n",
    "X = weather_station.drop(labels = ['CHWTON'], axis = 1)\n",
    "\n",
    "X_int = X.drop(labels = ['Month', 'Time'], axis = 1)\n",
    "\n",
    "# get multicolinearity data\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_int.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_int.values, i) for i in range(len(X_int.columns))]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f84ee-452d-4f45-ba11-ce06eaed8a43",
   "metadata": {},
   "source": [
    "# 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11a3af-50da-4091-8db9-254c79ccaef0",
   "metadata": {},
   "source": [
    "Scoring:\n",
    "One one hand, RMSE tells us the typical distance between the predicted value made by the regression model and the actual value.\n",
    "\n",
    "On the other hand, R2 tells us how well the predictor variables can explain the variation in the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8407d6-5079-4f49-8067-04ae14d26590",
   "metadata": {},
   "source": [
    "## 6.1 Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ RANDOM FORESTS #################################\n",
    "\n",
    "# 1. Get train test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "\n",
    "# 2. Using RandomForestRegressor to make predictions\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# - string\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# 3. Get prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "ModelPred = pd.DataFrame({'Actual CHWTON':Y_test, 'Predicted CHWTON':Y_pred})\n",
    "ModelPred = ModelPred.sort_index()\n",
    "print(ModelPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccc585-ef91-4ce1-ab3d-e461c94d4d03",
   "metadata": {},
   "source": [
    "## 6.2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd7913-16c3-4e98-92e2-d6b101f553d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. RMSE and R2\n",
    "R2_all = model.score(X_test, Y_test)\n",
    "RMSE_all = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred))\n",
    "\n",
    "# 2.Feature importance\n",
    "feature_list = list(X_train.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_, index = feature_list).sort_values(ascending=False)\n",
    "print(\"\\033[1m\" + \"Feature Importances:\" + \"\\033[0m\")\n",
    "print(feature_imp, \"\\n\")\n",
    "\n",
    "# 3. create score df\n",
    "scores_df = pd.DataFrame({\"score_type\": [\"R2\", \"RMSE\"], \"RF_allyear\": [R2_all, RMSE_all]})\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a5004-f1ac-454e-bd18-1929ced89695",
   "metadata": {},
   "source": [
    "# 7. June 9th Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699dd895-2462-41d5-8fb6-a6db970832eb",
   "metadata": {},
   "source": [
    "## 7.1 Weather Station prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5305a94-58a5-4fd2-8bd9-048018c796f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get X and Y (all test)\n",
    "X_j9 = station_j9.drop(labels = ['CHWTON'], axis = 1)\n",
    "\n",
    "# 2. Get Y\n",
    "Y_actual_j9 = station_j9['CHWTON']\n",
    "\n",
    "# 3. Get Y_pred\n",
    "Y_pred_j9 = model.predict(X_j9)\n",
    "\n",
    "# 4. Score\n",
    "R2_j9 = model.score(X_j9, Y_actual_j9)\n",
    "RMSE_j9 = np.sqrt(metrics.mean_squared_error(Y_actual_j9, Y_pred_j9))\n",
    "\n",
    "# 5. Append score to df\n",
    "score_j9_AZ = [R2_j9, RMSE_j9]\n",
    "scores_df['RF_j9_AZ'] = score_j9_AZ\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d42650-244b-40aa-bb95-a499399c7500",
   "metadata": {},
   "source": [
    "## 7.2 Microclimate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc42539-afa1-4c95-aaba-b2e40fb3117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get X\n",
    "X_j9_envi = envimet_j9.drop(labels = ['CHWTON'], axis = 1)\n",
    "\n",
    "# 2. Get Y_pred\n",
    "Y_pred_j9_envi = model.predict(X_j9_envi)\n",
    "\n",
    "# 3. Score\n",
    "R2_j9_envi = model.score(X_j9_envi, Y_actual_j9)\n",
    "RMSE_j9_envi = np.sqrt(metrics.mean_squared_error(Y_actual_j9, Y_pred_j9_envi))\n",
    "\n",
    "# 4. append to score df\n",
    "score_j9_envi = [R2_j9_envi, RMSE_j9_envi]\n",
    "scores_df['RF_j9_micro'] = score_j9_envi\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea93c54-1395-4c23-9504-9526754905ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = pd.DataFrame({'Actual':Y_actual_j9,'Baseline Predictions (AZW)': Y_pred_j9, 'Microclimate Predictions': Y_pred_j9_envi})\n",
    "Pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50086d1d-8cc9-4ab1-a013-f6a2897ff0bf",
   "metadata": {},
   "source": [
    "# 8. Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de764d-ae41-41bf-a5a3-651cffecaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([Y_pred_j9, Y_pred_j9_envi])\n",
    "plt.xticks([1,2],['Baseline_pred', 'Microclimate_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342275b-12c4-4079-a745-f483bbb0db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred_j9.mean())\n",
    "print(Y_pred_j9_envi.mean())\n",
    "print('mu:', Y_pred_j9.mean()- Y_pred_j9_envi.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364231d",
   "metadata": {},
   "source": [
    "# Two-Sample T Test\n",
    "\n",
    "\n",
    "mean differences in CHWTON = $ \\mu_{baseline} - \\mu_{microclimate} $ \n",
    "\n",
    "$ H_0: $ Mean of CHWTON in baseline and microclimate are the same\n",
    "\n",
    "$ H_1: $ Mean of CHWTON in baseline and microclimate are NOT the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16c2e6-e6cd-4a43-bcf4-8e7c843c47cd",
   "metadata": {},
   "source": [
    "## 8.1 calculate standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8632054-a03d-4c1d-a822-37cea5e7dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.variance\n",
    "var_baseline = Y_pred_j9.var(ddof = 1)\n",
    "var_micro = Y_pred_j9_envi.var(ddof = 1)\n",
    "print('var: ',var_baseline, var_micro)\n",
    "\n",
    "# 2. standard deviation\n",
    "s = np.sqrt((var_baseline + var_micro)/2)\n",
    "print('sd: ',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e0198-7135-481e-aeed-eaf39ea9e6b5",
   "metadata": {},
   "source": [
    "## 8.2 calculate T-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5af72c-d801-4bd2-84c1-ced1e04d87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "t_stat, p_val = stats.ttest_ind(Y_pred_j9, Y_pred_j9_envi, equal_var=False)\n",
    "print('t statistics: ', t_stat)\n",
    "print('p value: ', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d48f93-ec9b-4cc3-b977-f63f8991e9b7",
   "metadata": {},
   "source": [
    "P value is not less that 0.05. We cannot reject the null hypothesis. There is no significant difference between the transaction amount of fraud and non fraudulent transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c06839-9ef6-4378-befa-8e6caf8ad667",
   "metadata": {},
   "source": [
    "# 9. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Plotting Baseline Model for all 2018 15-min Data #######\n",
    "\n",
    "## This is a big graph, will be slow to run but gives visual of prediction accuracy\n",
    "# %matplotlib qt\n",
    "plt.xlabel('Baseline 15-Min Model')\n",
    "plt.ylabel('CHWTON')\n",
    "plt.plot(ModelPred['Actual CHWTON'], label = 'Actual CHWT')\n",
    "plt.plot(ModelPred['Predicted CHWTON'], label = 'Predicted CHWT')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5613547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting ENVI-met vs AZW vs Actual Data for June 9 from 5a - 8p\n",
    "\n",
    "positions = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "labels = ['5a', '6a', '7a', '8a', '9a', '10a', '11a', '12p', '1p', '2p', '3p', '4p', '5p', '6p', '7p', '8p']\n",
    "\n",
    "# plot EnviMet vs AZ_Weather results\n",
    "plt.xlabel('Time 5a - 8p')\n",
    "plt.ylabel('CHWTON')\n",
    "plt.xticks(positions, labels)\n",
    "plt.plot(Pred['Microclimate Predictions'], label = 'ENVIMET Weather')\n",
    "plt.plot(Pred['Baseline Predictions (AZW)'], label = 'Baseline Weather (AZW)')\n",
    "plt.plot(Pred['Actual'], label = 'Actual Data')\n",
    "plt.title(bldname)\n",
    "plt.legend()\n",
    "\n",
    "## show graphs\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1dfe7-6f7c-4ee8-b7b0-66e01f5bc295",
   "metadata": {},
   "source": [
    "# 10. Save DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5c79c-05fe-4112-8dfa-4d03b3a26212",
   "metadata": {},
   "source": [
    "## 10.1 Weather Station string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63503ef-9ddc-440b-a7e4-c88e240cdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_station.to_csv('./Data/weather_st2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2dbabd-8bf0-46ce-976a-87b75770fab3",
   "metadata": {},
   "source": [
    "## 10.2 June 9th Weather St\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57703357-ac1e-486b-9ef2-eba65fb5f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_st_June_9.to_csv('./Data/weather_j9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf5320-fa48-44b2-9a04-b3caa891ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_df.to_csv('./Data/score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ae9c6-60fe-47e6-84a3-22dd477cf556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myConda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b2ed8-783e-437f-b4dd-ee4536489cd9",
   "metadata": {},
   "source": [
    "Combined all building datas and create new Builiding column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6dbd75",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6345f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# parameters search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "# To: install catboost\n",
    "# !pip3 install catboost\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e621a",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98beeaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list to add csv files as df\n",
    "Bldg = []\n",
    "\n",
    "# Read all building data and append to list\n",
    "for path in pathlib.Path(\"../Data/microclimate_model/Combined/dataset1\").iterdir():\n",
    "        if path.is_file():\n",
    "            current_file = pd.read_csv(path)\n",
    "            current_file = current_file.drop(columns=['Unnamed: 0'])\n",
    "            Bldg.append(current_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f4377",
   "metadata": {},
   "source": [
    "## 1.1 Preprocessing \n",
    "\n",
    "1. Adding Month, Hour, and Minute to data\n",
    "2. Removing hours out of ENVI-met accuracy range (after 9 pm)\n",
    "3. Add CHWTON/SQFT to columns using condition area for each building taken from\n",
    "    https://fdm-apps.asu.edu/UFRM/FDS/FacilityData.aspx\n",
    "4. Drop na rows in limited data (some data points from campus metabolism not available)\n",
    "5. Add Absolute Humidity to Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Month, Hour, and Minute column for all dataframes in list\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg[i].Date_Time = pd.to_datetime(Bldg[i].Date_Time)\n",
    "    Bldg[i]['Month_num'] = Bldg[i].Date_Time.dt.month\n",
    "    Bldg[i]['Hour_num'] = Bldg[i].Date_Time.dt.hour\n",
    "    Bldg[i]['Minute_num'] = Bldg[i].Date_Time.dt.minute\n",
    "    Bldg[i]['Day_num'] = Bldg[i].Date_Time.dt.day\n",
    "\n",
    "# Remove data after 9pm\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg[i] = Bldg[i][(Bldg[i]['Hour_num'] <= 20) & (Bldg[i]['Hour_num'] > 0)]\n",
    "\n",
    "# Add Column: CHWTON/Condition Area (SqFt) or ['CHWTON/SQFT']\n",
    "cond_area = {'Noble Library':88658,'Biodesign B':132215,'Biodesign C':145410,\n",
    "             'Biodesign A':133016,'Psychology':69864,'Goldwater':165237,'Schwada COB':99857,\n",
    "             'ISTB 2':41404,'Bulldog Hall':68067,'ISTB 4':231646,'Psychology North':43034}\n",
    "for i in range(len(Bldg)):\n",
    "    if Bldg[i]['bldgname'][0] in cond_area:\n",
    "        Bldg[i]['CHWTON/SQFT'] = Bldg[i]['CHWTON'] / cond_area[Bldg[i]['bldgname'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eeb8b1-fb0c-4e32-b3c3-1164085b428e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Absolute Humidity Equations: https://www.hatchability.com/Vaisala.pdf. To test, compare with https://planetcalc.com/2167/ but notice the calculation made here is in g/m^3 and in this website it is in Kg/m^3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244321a-7dc9-401f-aa34-4f40c85bee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if NA in data\n",
    "for i in range(len(Bldg)):\n",
    "    null_data = Bldg[i][Bldg[i].isnull().any(axis=1)]\n",
    "#     print(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1aa27b-33e1-49f7-bc67-2eba12392932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA rows in data\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg[i] = Bldg[i].dropna()\n",
    "    Bldg[i] = Bldg[i].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9732bc-cc9f-4ebc-be71-a3c422273b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Rel Hum to Abs Hum\n",
    "for i in range(len(Bldg)):\n",
    "    T_i = Bldg[i]['Air Temp']\n",
    "    RH = Bldg[i]['Rel Hum']/100\n",
    "\n",
    "    T = T_i + 273.15\n",
    "    P_c = 220640\n",
    "    T_c = 647.096\n",
    "    C_1 = -7.85951783\n",
    "    C_2 = 1.84408259\n",
    "    C_3 =  -11.7866497\n",
    "    C_4 = 22.6807411\n",
    "    C_5 = -15.9618719\n",
    "    C_6 = 1.80122502\n",
    "    v = 1 - (T/T_c)\n",
    "\n",
    "    x = (T_c/T)*((C_1*v) + (C_2*np.power(v, 1.5)) + (C_3*np.power(v, 3)) \n",
    "                 + (C_4*np.power(v, 3.5)) + (C_5*np.power(v, 4)) + (C_6*np.power(v, 7.5))) \n",
    "\n",
    "    P_ws = np.exp(x)*P_c\n",
    "    P_w = P_ws*RH\n",
    "\n",
    "    C = 2.16679\n",
    "    A = C*P_w*100/T\n",
    "\n",
    "    Bldg[i]['Abs Hum'] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8bb22-1e56-4b54-b90b-10ef68e67856",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg[0].Date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427cc98-060f-45ed-9353-a7c97865e1f7",
   "metadata": {},
   "source": [
    "Month available:<br>\n",
    "May: 16, 23 <br>\n",
    "June: 7, 8, 20, 21, 25, 26<br>\n",
    "August: 3, 27<br>\n",
    "September: 11, 29<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096700f",
   "metadata": {},
   "source": [
    "### 2.2.3 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pd = pd.DataFrame(Bldg[bldgnum][['Time','Air Temp','Rel Hum','KW','HTmmBTU','Month_num','Hour_num','Day_num', 'CHWTON/SQFT', 'Abs Hum']])\n",
    "corrMatrix = corr_pd.corr()\n",
    "sns.heatmap(corrMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227ea14",
   "metadata": {},
   "source": [
    "# 3. All Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ced4e0-5235-4549-8c20-6b3d74d74a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbc16b-9ff6-4c16-8309-533358e59c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Bldg)):\n",
    "    Bldg_df = Bldg_df.append(Bldg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56611b45-68bf-4979-9c68-4c1f8962fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df.reset_index(drop = True , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8c93c-2647-4e11-a246-2bcd30933363",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4b6b1",
   "metadata": {},
   "source": [
    "## 3.1 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690c813",
   "metadata": {},
   "source": [
    "### 3.1.1 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bac77-99fd-42b8-bd10-0cd22ebe1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of building names so we can extract the name easily \n",
    "BldgName = [\"Noble Library\",\"Biodesign B\",\"Biodesign C\",\n",
    "              \"Biodesign A\", \"Psychology\", \"Goldwater\",\n",
    "              \"Schwada COB\", \"ISTB 2\", \"Bulldog Hall\",\n",
    "              \"ISTB 4\", \"Pyschology North\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2122d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create CHWTON boxplots for all buildings #\n",
    "def createBoxPlot(df, columnName, BldgName):\n",
    "    row_size = 6\n",
    "    column_size = 2\n",
    "    fig, ax = plt.subplots(row_size, column_size, figsize = (15,40))\n",
    "\n",
    "    i = 0\n",
    "    while i < (len(df)):\n",
    "        for row in range(row_size):\n",
    "            for col in range(column_size):\n",
    "                if i < len(df):\n",
    "                    df[i].boxplot(by='Hour_num',\n",
    "                                    column=[columnName],\n",
    "                                    grid = False,\n",
    "                                    figsize = (5,5),\n",
    "                                    ax = ax[row,col] )\n",
    "                    ax[row,col].title.set_text(BldgName[i])\n",
    "                    i += 1\n",
    "\n",
    "    fig.suptitle(columnName + ' Boxplot by Hour')\n",
    "    plt.show()\n",
    "    \n",
    "createBoxPlot(Bldg, 'CHWTON', BldgName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa283b62-6282-42d1-9f85-431f1c22dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "createBoxPlot(Bldg, 'Air Temp', BldgName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fd129",
   "metadata": {},
   "source": [
    "### 3.1.2 Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62d7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Print CHWTON/SQFT for all buildings and all timestamps in data\n",
    "ax = Bldg[0]['CHWTON/SQFT'].plot(figsize = (15,9))\n",
    "legendlabels = []\n",
    "for i in range(len(Bldg)-1):\n",
    "    Bldg[i+1]['CHWTON/SQFT'].plot(ax=ax)\n",
    "    legendlabels.append(Bldg[i].bldgname[0])\n",
    "    \n",
    "ax.legend(labels = legendlabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4d0e0-ec18-49fc-8026-69efa88fb02e",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d202e9-1384-4410-a5f1-c83e27216e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encode df columns into sine and cosine\n",
    "def encode(df, col, max_val):\n",
    "    df[col.replace('_num', '') + '_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
    "    df[col.replace('_num', '') + '_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
    "    df.drop(columns = [col], inplace = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef06d9-9619-4ac6-941e-28c5e9100d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of df for buildings with cyclical time features\n",
    "Bldg_cyclic = []\n",
    "\n",
    "Bldg_enc = Bldg_df.copy(deep = True)\n",
    "Bldg_enc = encode(Bldg_enc, 'Minute_num', 60.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Hour_num', 23.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Day_num', 30.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Month_num', 12.0)\n",
    "Bldg_cyclic = Bldg_enc\n",
    "    \n",
    "# Plot cyclical features sample\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,7))\n",
    "Bldg_cyclic.plot.scatter('Minute_sin', 'Minute_cos', ax = ax[0,0]).set_aspect('equal')\n",
    "Bldg_cyclic.plot.scatter('Hour_sin', 'Hour_cos', ax = ax[0,1]).set_aspect('equal')\n",
    "Bldg_cyclic.plot.scatter('Day_sin', 'Day_cos', ax = ax[1,0]).set_aspect('equal')\n",
    "Bldg_cyclic.plot.scatter('Month_sin', 'Month_cos', ax = ax[1,1]).set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f78039-0eae-4d64-8d94-04ad4469cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb80111-7320-4a40-8960-1826e4fca9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc094a-85cc-43b0-b416-71ba072e70ea",
   "metadata": {},
   "source": [
    "## 3.3 Modelling set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa8df0-a665-431e-8ea1-b4ff7fe172a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create scores dataframe and add building names ###\n",
    "scores_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecd35c-dbd6-43a4-9d18-8661bb1ec8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train a model and get its scores\n",
    "def trainAndGetScore(pModel, pModelName, pDf_all_bldg, pDf_scores):\n",
    "    # 1. drop na values if in dataframe\n",
    "    if (pDf_all_bldg.isnull().values.any() == True):\n",
    "        pDf_all_bldg = pDf_all_bldg.dropna()\n",
    "            \n",
    "    # 2. split data into X and y\n",
    "    X = pDf_all_bldg.drop(columns=['Date', 'Time','bldgname','HTmmBTU', 'Date_Time', 'CHWTON', 'CHWTON/SQFT'])\n",
    "    y = pDf_all_bldg['CHWTON']    \n",
    "        \n",
    "    # 3. Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n",
    "    # 4. fit model that already has parameters\n",
    "    pModel.fit(X_train, y_train)\n",
    "        \n",
    "    # 5. Get prediction\n",
    "    y_pred = pModel.predict(X_test)\n",
    "    ModelPred = pd.DataFrame({'Actual CHWTON':y_test, 'Predicted CHWTON':y_pred})\n",
    "    ModelPred = ModelPred.sort_index()\n",
    "    \n",
    "    # 6. Get best params if it's a random or grid search\n",
    "    if(\"random\" in pModelName) or (\"grid\" in pModelName):\n",
    "        print(pModel.best_estimator_.get_params())\n",
    "        \n",
    "    # Save scores\n",
    "    score = pModel.score(X_test, y_test)\n",
    "#     i = scores_df.shape[0] # get last index in the df\n",
    "    pDf_scores[pModelName] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4c33c",
   "metadata": {},
   "source": [
    "## 3.4 Model 1: Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eda26-53b7-47e4-89a3-a5b4c99f1437",
   "metadata": {},
   "source": [
    "### 3.4.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c2350-06e9-4db6-8bd3-5e21c401417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_base = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 2. split data into X and y\n",
    "X = Bldg_df.drop(columns=['Date', 'Time','bldgname','HTmmBTU', 'Date_Time', 'CHWTON', 'CHWTON/SQFT'])\n",
    "y = Bldg_df['CHWTON'] \n",
    "\n",
    "\n",
    "# 3. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "RF_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e737017-45c1-4d64-931e-907fefd1936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_base.predict(X_test)\n",
    "y_pred\n",
    "score = RF_base.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ee8c3-9d00-4fc4-8421-67d5ebbf4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_base = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 1. Base RF on base data\n",
    "trainAndGetScore(RF_base, \"RF_base\", Bldg_df, scores_df)\n",
    "\n",
    "# 2. Base RF on cyclical time features\n",
    "trainAndGetScore(RF_base, \"RF_cyclic\", Bldg_cyclic, scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3bc4d-586c-4bfc-b525-af5a68f064c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d73d4-6ebb-4047-870b-d7c749d13f89",
   "metadata": {},
   "source": [
    "### 3.4.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b3012-d20c-4e29-bcff-5ce18752423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for RF\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "\n",
    "# 2. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 3. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 4. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 1, 2, 4]\n",
    "\n",
    "# 5. Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# 6. Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ca3e5-9232-4954-ad93-7209b0541d87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_random = RandomizedSearchCV(estimator = RF_base,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_random, \"RF_random\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(RF_random, \"RF_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449aedf7-0456-4149-8a37-ed97ce22784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF_random.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33671b52-7533-4752-8dc6-14c39821ba97",
   "metadata": {},
   "source": [
    "### 3.4.3 Grid Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c444f9-a995-411b-b82a-5e0e8dc223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [200, 220, 230,240],\n",
    "               'max_features': [\"sqrt\"],\n",
    "               'max_depth': [17, 20, 22],\n",
    "               'min_samples_split': [2,3,4],\n",
    "               'min_samples_leaf': [ 1, 2],\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af34a8-bcc0-47a0-a2a9-957306fe144d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_grid = GridSearchCV(estimator = RF_base,\n",
    "                       param_grid = param_grid,\n",
    "                       cv = 5,\n",
    "                       scoring ='r2',\n",
    "                       n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_grid, \"RF_grid\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(RF_grid, \"RF_grid_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba86d-d905-4050-af9e-720be9883b29",
   "metadata": {},
   "source": [
    "## 3.5 Model 2: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f7a20-eeff-4122-b0f2-7e4519aaf62f",
   "metadata": {},
   "source": [
    "### 3.5.1. No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194165bb-5300-4014-9480-c31492e3d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create base model\n",
    "XGB_base = XGBRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 2. Base XGB on base data\n",
    "trainAndGetScore(XGB_base, \"XGB_base\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Base XGB on cyclica time features\n",
    "trainAndGetScore(XGB_base, \"XGB_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c0700-ac88-4cb9-b276-b9013c1284df",
   "metadata": {},
   "source": [
    "### 3.5.2. Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a779b-76b3-44ec-9fb3-77b4d3d54c4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "params = {\n",
    "    'n_estimators':[ 100, 250, 500, 1000],\n",
    "    'min_child_weight':[4,5,8], \n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "n_iter_search = 20\n",
    "XGB_random = RandomizedSearchCV(XGB_base,\n",
    "                                param_distributions = params,\n",
    "                                n_iter = n_iter_search,\n",
    "                                cv = 5,\n",
    "                                verbose = 2,\n",
    "                                random_state = 42,\n",
    "                                scoring ='r2',\n",
    "                                n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(XGB_random, \"XGB_random\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(XGB_random, \"XGB_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0500fd6-3e9d-4fc2-b6ea-ef51a7a72eb8",
   "metadata": {},
   "source": [
    "### 3.5.3 Bayesian Opt. tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198541a3-fe69-480e-b173-0fc22f408662",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "# for i in range(len(Bldg)):\n",
    "#         # 1. drop na values if in dataframe\n",
    "#         if (Bldg[i].isnull().values.any() == True):\n",
    "#             Bldg[i] = pDf_all_bldg[i].dropna()\n",
    "            \n",
    "#         # 2. split data into X and y\n",
    "#         X = Bldg[i].drop(columns=['Date', 'Time','bldgname','HTmmBTU', 'Date_Time', 'CHWTON', 'CHWTON/SQFT'])\n",
    "#         y = Bldg[i]['CHWTON']    \n",
    "        \n",
    "#         # 3. Train-Test Split\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "    \n",
    "# # 1. Function to maximimse score \n",
    "# # This function will take the the parameters we defined and obtain a score\n",
    "# def train_XGB(max_depth, gamma, n_estimators, learning_rate, subsample):\n",
    "#     params_XGB = {}\n",
    "#     params_XGB['max_depth'] = round(max_depth)\n",
    "#     params_XGB['gamma'] = gamma\n",
    "#     params_XGB['learning_rate'] = learning_rate\n",
    "#     params_XGB['n_estimators'] = round(n_estimators)\n",
    "#     params_XGB['subsample'] = subsample\n",
    "#     scores = cross_val_score(XGBRegressor(random_state=42, **params_XGB),\n",
    "#                              X_train, y_train, scoring='r2', cv=5).mean()\n",
    "#     score = scores.mean()\n",
    "#     return score\n",
    "               \n",
    "               \n",
    "               \n",
    "# params_XGB ={\n",
    "#     'max_depth':(3, 10),\n",
    "#     'gamma':(0, 1),\n",
    "#     'learning_rate':(0.01, 1),\n",
    "#     'n_estimators':(80, 150),\n",
    "#     'subsample': (0.8, 1)\n",
    "# }\n",
    "# XGB_bayes = BayesianOptimization(train_XGB, params_XGB, random_state=111)\n",
    "# XGB_bayes.maximize(init_points=20, n_iter=10)\n",
    "# print('It takes %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd4792-01f9-4d5e-9330-43b228a5b313",
   "metadata": {},
   "source": [
    "## 3.6 Model 3: LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482554db-64fa-4f25-9a5e-479b5cf525be",
   "metadata": {},
   "source": [
    "### 3.6.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b9a1-6a53-499e-8f10-88f57beb99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_base = lgb.LGBMRegressor(random_state = 42)\n",
    "\n",
    "# 2. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_base, \"LGBM_base\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Base LGBM on cyclica time features\n",
    "trainAndGetScore(LGBM_base, \"LGBM_cylic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3765ed-d58d-4341-adfe-dbf4727f33cb",
   "metadata": {},
   "source": [
    "### 3.6.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0e798-0697-49bc-8524-50513240672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "random_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'learning_rate': [0.1, 0.03, 0.003],\n",
    "    'max_depth': [-1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "LGBM_random = RandomizedSearchCV(estimator = LGBM_base,\n",
    "                                 param_distributions = random_grid, \n",
    "                                 n_iter = 100, cv = 2,\n",
    "                                 scoring='r2',\n",
    "                                 verbose= 2,\n",
    "                                 random_state= 42,\n",
    "                                 n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e469572-f06f-478b-8017-b3ba68af1708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_random, \"LGBM_random\", Bldg_df, scores_df)\n",
    "\n",
    "# 4. Base LGBM on cyclica time features\n",
    "trainAndGetScore(LGBM_random, \"LGBM_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45527caa-f145-4e8d-8eef-a18e1126c316",
   "metadata": {},
   "source": [
    "### 3.6.3 Bayesian Opt. tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4db96c-ed61-4d64-93f7-91f9306f61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results = lgb.cv(\n",
    "#         params,\n",
    "#         dftrainLGB,\n",
    "#         num_boost_round=100,\n",
    "#         nfold=3,\n",
    "#         metrics='mae',\n",
    "#         early_stopping_rounds=10,\n",
    "#         stratified=False\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba628875-88b7-4b70-bbaa-4665018d58af",
   "metadata": {},
   "source": [
    "XGBoost model trained on 3 buildings datas only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3470fa-5ba9-4de4-8bbe-c6562636c324",
   "metadata": {},
   "source": [
    "# 1. Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8eec3d-cd80-40fd-8f52-fc1c339babbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# uncomment to install the three models below >>>>>\n",
    "# !pip3 install catboost\n",
    "# !pip install lightgbm\n",
    "# !pip3 install xgboost\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# parameters search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# scoring\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972dc900-b2a2-4bbf-8380-36c7b7838610",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../Data/microclimate_model/Combined/three_bldgs_dropped.csv\"\n",
    "TEST_PATH = \"../Data/microclimate_model/Combined/three_bldgs_J9_dropped.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fd10a-6629-44c3-b201-175f96bdc824",
   "metadata": {},
   "source": [
    "# 2. Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddd56cb-10f9-42c0-ab23-7cdc737bdb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This class encapsulates the datas that we will need for training and testing.\n",
    "It only contains getters for the train and test data\n",
    "\"\"\"\n",
    "class Data(object):\n",
    "    def __init__(self, train_path, test_path):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            train_path (str) : The file path for the trainning csv file. \n",
    "            test_path (str) : The path for the test csv file. \n",
    "        \n",
    "        Both train and test datas have 16 columns with buildings already encoded\n",
    "        \"\"\"\n",
    "        \n",
    "        # - Train and validation data\n",
    "        self.train_val_df = pd.read_csv(train_path, index_col=0)\n",
    "        self.X_train_val = self.train_val_df.drop(columns=['CHWTON/SQM'])\n",
    "        self.y_train_val = self.train_val_df['CHWTON/SQM']  \n",
    "        \n",
    "        # - Test data\n",
    "        self.test_df = pd.read_csv(test_path, index_col=0)\n",
    "        self.X_test = self.test_df.drop(columns=['CHWTON/SQM'])\n",
    "        self.y_test = self.test_df['CHWTON/SQM'] \n",
    "        \n",
    "    \n",
    "    def get_xy_trainval(self):\n",
    "        \"\"\"\n",
    "        Return the X and y for training data which we can split to train and validation data later.\n",
    "        \"\"\"\n",
    "        return self.X_train_val, self.y_train_val\n",
    "    \n",
    "    def get_xy_test(self):\n",
    "        \"\"\"\n",
    "        Return the X and y for June 9th test data\n",
    "        \"\"\"\n",
    "        return self.X_test, self.y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfcd0b9-98f3-4638-8038-9fe520d7fa8e",
   "metadata": {},
   "source": [
    "# 3. Train Test Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d8a7e-fa55-4c2e-9579-b71fc42d4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This class encapsulates the the training and testing process.\n",
    "It stores the train and test datas that's already split to X and y\n",
    "\"\"\"\n",
    "class TrainTest(object):\n",
    "    def __init__(self, X_train_val, y_train_val, X_test, y_test):\n",
    "        # - scores_df to display the scores for all our models\n",
    "        self.columns=['model','r2_val', 'r2_test', 'rmse_test','mbe_test']\n",
    "        self.scores_df= pd.DataFrame(columns=self.columns)\n",
    "        \n",
    "        # - train and test data\n",
    "        self.X_train_val = X_train_val\n",
    "        self.y_train_val = y_train_val\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def get_scores_df(self):\n",
    "        return self.scores_df\n",
    "    \n",
    "    \n",
    "    def train_and_get_score(self, model, model_name):\n",
    "        \"\"\"\n",
    "        This function will use the trainning data to train the model, and get the r2 validation score\n",
    "        and append a new row to scores_df.\n",
    "        \n",
    "        Parameters:\n",
    "            model (regressor model) : The is a model object that will be trained and used in validation.\n",
    "                It can be RF, XGB, LGBM, or catboost regressor\n",
    "                \n",
    "            model_name (str) : the name of the model displayed in scores_df\n",
    "        \"\"\"\n",
    "        # 1. Train-Val Split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.X_train_val, \n",
    "                                                          self.y_train_val, \n",
    "                                                          test_size=0.3, \n",
    "                                                          random_state=20)\n",
    "\n",
    "        # 2. fit model that already has parameters\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        # - Get best params if it's a random or grid search\n",
    "        # if(\"random\" in pModelName) or (\"grid\" in pModelName):\n",
    "        #     print(pModel.best_estimator_.get_params())\n",
    "        \n",
    "        \n",
    "        # 3. get validation R2 score\n",
    "        val_r2 = model.score(X_val, y_val)\n",
    "        \n",
    "        # 4. store score\n",
    "        new_row_data = {'model':model_name, \"r2_val\":val_r2, \"r2_test\":0, 'rmse_test':0, 'mbe_test':0}\n",
    "        new_row = pd.DataFrame.from_records([new_row_data])\n",
    "        self.scores_df = pd.concat([self.scores_df, new_row])\n",
    "\n",
    "    def get_MBE(self, y_true, y_pred):\n",
    "        '''\n",
    "        Parameters:\n",
    "            y_true (array): Array of observed values\n",
    "            y_pred (array): Array of prediction values\n",
    "\n",
    "        Returns:\n",
    "            mbe (float): Bias score\n",
    "        '''\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = y_true.reshape(len(y_true),1)\n",
    "        y_pred = y_pred.reshape(len(y_pred),1)   \n",
    "        diff = (y_pred-y_true)\n",
    "        mbe = diff.mean()\n",
    "        return mbe\n",
    "\n",
    "        \n",
    "    def test_and_get_score(self, model, model_name):\n",
    "        \"\"\"\n",
    "        This function will use the test data and a trained model to compute the y_pred\n",
    "        and get the mbe, r2, and rmse result and insert it to scores_df\n",
    "        \n",
    "        Parameters:\n",
    "            model (regressor model): The model that has been trained and will be used to predict y using the test data\n",
    "                It can be RF, XGB, LGBM, or catboost regressor\n",
    "            model_name (string): the name of the model displayed in scores_df\n",
    "        \n",
    "        \"\"\"\n",
    "        # 1. Get prediction for the test data\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        \n",
    "        # 2. get the three scores\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        rmse = math.sqrt(mean_squared_error(self.y_test, y_pred))\n",
    "        mbe = self.get_MBE(self.y_test, y_pred)\n",
    "        \n",
    "        # 3. update scores_df with the 3 scores above\n",
    "        row_to_update = self.scores_df[\"model\"] == model_name\n",
    "        col_to_update = ['r2_test','rmse_test', 'mbe_test']\n",
    "        self.scores_df.loc[row_to_update, col_to_update] = [r2, rmse, mbe]\n",
    "        \n",
    "        # print(\"r2:\", r2)\n",
    "        # print(\"rmse:\", rmse)\n",
    "        # print(\"mbe:\", mbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242440bd-5d08-4a1e-b904-67a181794615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # get datas train_val and test\n",
    "    data_obj = Data(TRAIN_PATH, TEST_PATH)\n",
    "    X_train_val, y_train_val = data_obj.get_xy_trainval()\n",
    "    X_test, y_test = data_obj.get_xy_test()\n",
    "    tt = TrainTest(X_train_val, y_train_val,X_test, y_test)\n",
    "    \n",
    "    # RF\n",
    "    rf_base_name = \"RF_base\"\n",
    "    rf_base = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "    tt.train_and_get_score(rf_base, rf_base_name)\n",
    "    tt.test_and_get_score(rf_base, rf_base_name)\n",
    "\n",
    "    # XGB\n",
    "    xgb_base_name = \"XGB_base\"\n",
    "    xgb_base = XGBRegressor(n_estimators = 100, random_state = 42)\n",
    "    tt.train_and_get_score(xgb_base, xgb_base_name)\n",
    "    tt.test_and_get_score(xgb_base, xgb_base_name)\n",
    "    \n",
    "    \n",
    "    # LGBM\n",
    "    lgbm_base_name = \"LGBM_base\"\n",
    "    lgbm_base = LGBMRegressor(random_state = 42)\n",
    "    tt.train_and_get_score(lgbm_base, lgbm_base_name)\n",
    "    tt.test_and_get_score(lgbm_base, lgbm_base_name)\n",
    "    \n",
    "    \n",
    "    # Catboost\n",
    "    catboost_base_name = \"catboost_base\"\n",
    "    catboost_base = CatBoostRegressor(random_state = 42, verbose=False)\n",
    "    tt.train_and_get_score(catboost_base, catboost_base_name)\n",
    "    tt.test_and_get_score(catboost_base, catboost_base_name)\n",
    "    # print(catboost_base.get_all_params())\n",
    "    \n",
    "    \n",
    "    # display scores_df\n",
    "    scores_df = tt.get_scores_df()\n",
    "    print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229264e1-0ab8-4dde-a2df-2750dd1d970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b67a9-7574-4b56-8058-d9575d292ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

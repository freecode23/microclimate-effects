{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b2ed8-783e-437f-b4dd-ee4536489cd9",
   "metadata": {},
   "source": [
    "Data: Combined with added features , Shades and Radiation. <br>\n",
    "Split: Train, Validate, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6dbd75",
   "metadata": {},
   "source": [
    "# 1. Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6345f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# import shap\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# parameters search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "# To: install catboost\n",
    "# !pip3 install catboost\n",
    "\n",
    "# explain\n",
    "from sklearn.tree import export_graphviz\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebb1f0b-a683-4698-b193-f5f69a32068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98beeaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Bldg = pd.read_csv(\"../Data/microclimate_model/Combined/all_buildings_9pm.csv\")\n",
    "Bldg = Bldg.drop(columns = ['Unnamed: 0','CHWTON'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0b7837-8d20-4c30-bf9e-549551671d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_X = pd.read_csv(\"../Data/microclimate_model/Combined/June_9_trees.csv\")\n",
    "Tree_X = Tree_X.drop(columns = ['Unnamed: 0','CHWTON','CHWTON/SQFT' ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4b6b1",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab63c2-52db-47e2-9eaf-5c8c5f322305",
   "metadata": {},
   "source": [
    "## 2.1 Compare Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199bf251-1a79-4a19-9adc-78d7890fc47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bldgname</th>\n",
       "      <th>Base</th>\n",
       "      <th>Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>29.578951</td>\n",
       "      <td>29.507257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>29.068746</td>\n",
       "      <td>29.047179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>28.741506</td>\n",
       "      <td>28.767364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>28.550811</td>\n",
       "      <td>28.576198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>28.346988</td>\n",
       "      <td>28.372186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>38.580270</td>\n",
       "      <td>38.546036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>38.333556</td>\n",
       "      <td>38.309903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>38.067908</td>\n",
       "      <td>38.041853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>37.871024</td>\n",
       "      <td>37.850644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>37.654008</td>\n",
       "      <td>37.636041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          bldgname       Base       Tree\n",
       "0    Noble Library  29.578951  29.507257\n",
       "1    Noble Library  29.068746  29.047179\n",
       "2    Noble Library  28.741506  28.767364\n",
       "3    Noble Library  28.550811  28.576198\n",
       "4    Noble Library  28.346988  28.372186\n",
       "..             ...        ...        ...\n",
       "635    Biodesign B  38.580270  38.546036\n",
       "636    Biodesign B  38.333556  38.309903\n",
       "637    Biodesign B  38.067908  38.041853\n",
       "638    Biodesign B  37.871024  37.850644\n",
       "639    Biodesign B  37.654008  37.636041\n",
       "\n",
       "[640 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_9 = Bldg[(Bldg['Month'] == 6) & (Bldg['Day'] == 9)]\n",
    "\n",
    "\n",
    "temperature = pd.DataFrame()\n",
    "temperature['bldgname'] = J_9['bldgname']\n",
    "temperature['Base'] = J_9['Air Temp']\n",
    "temperature = temperature.reset_index()\n",
    "temperature['Tree'] = Tree_X['Air Temp']\n",
    "\n",
    "temperature.drop(columns = ['index'], inplace = True)\n",
    "\n",
    "temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7c317f-139b-4934-8d0c-9ba2f8436032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     29.507257\n",
       "1     29.047179\n",
       "2     28.767364\n",
       "3     28.576198\n",
       "4     28.372186\n",
       "        ...    \n",
       "59    38.527226\n",
       "60    38.326451\n",
       "61    38.080587\n",
       "62    37.902603\n",
       "63    37.707359\n",
       "Name: Tree, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature[temperature['bldgname'] == 'Noble Library']['Tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d128005-5b12-46bb-b42d-0769f811f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. get label for plot\n",
    "BldgName = list(Bldg.bldgname.unique())\n",
    "BldgnameTest = BldgName \n",
    "BldgnameTest.pop(1) # remove the second building (data doesnt exists)\n",
    "\n",
    "\n",
    "# 2. get position for plots\n",
    "# print the number of elements per building\n",
    "for i in range(len(BldgnameTest)-1):\n",
    "    print((temperature.bldgname == BldgName[i]).sum())\n",
    "    \n",
    "# # create array accordingly\n",
    "position = np.linspace(0, 640, num=11).tolist()\n",
    "\n",
    "# remove last index\n",
    "position.pop()\n",
    "\n",
    "\n",
    "for i in range(len(BldgnameTest)):\n",
    "    # from matplotlib.pyplot import figure\n",
    "    figure(figsize=(5, 3), dpi=150)\n",
    "    # plt.xticks( position, BldgnameTest )\n",
    "    plt.plot(temperature[temperature['bldgname'] == BldgnameTest[i]]['Base'], label = 'Air Temp Base', color=\"orange\")\n",
    "    plt.plot(temperature[temperature['bldgname'] == BldgnameTest[i]]['Tree'], label = 'Air Temp Tree', color=\"green\")\n",
    "    plt.legend()\n",
    "    plt.title(BldgnameTest[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690c813",
   "metadata": {},
   "source": [
    "## 2.2 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bac77-99fd-42b8-bd10-0cd22ebe1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Create List of building names so we can extract the name easily \n",
    "# BldgName = list(Bldg.bldgname.unique())\n",
    "\n",
    "# # 2. Create list of building df to do time series plot of CHWTON\n",
    "# BldgList = []\n",
    "\n",
    "# for i in range(len(BldgName)):\n",
    "#     bldg_single = Bldg[Bldg['bldgname'] == BldgName[i]]\n",
    "#     bldg_single = bldg_single[['bldgname', 'Date_Time','CHWTON/SQFT','Hour']]\n",
    "#     bldg_single[BldgName[i]] = bldg_single['CHWTON/SQFT']\n",
    "#     bldg_single = bldg_single.drop(columns = ['bldgname'])\n",
    "#     BldgList.append(bldg_single)\n",
    "    \n",
    "\n",
    "# #3. Create CHWTON boxplots for all buildings #\n",
    "# def createBoxPlot(df, columnName, BldgName):\n",
    "#     row_size = 6\n",
    "#     column_size = 2\n",
    "#     fig, ax = plt.subplots(row_size, column_size, figsize = (15,40))\n",
    "\n",
    "#     i = 0\n",
    "#     # 1. loop through the 11 buildings\n",
    "#     while i < (len(BldgName)):\n",
    "#         # 2. Create row (6)\n",
    "#         for row in range(row_size):\n",
    "#             #4. Create column 2\n",
    "#             for col in range(column_size):\n",
    "#                 if i < (len(BldgName)):\n",
    "                    \n",
    "#                     # create boxplot of this df\n",
    "#                     df[i].boxplot(by='Hour',\n",
    "#                                     column=[columnName],\n",
    "#                                     grid = False,\n",
    "#                                     figsize = (4,4),\n",
    "#                                     ax = ax[row,col] )\n",
    "#                     ax[row,col].title.set_text(BldgName[i])\n",
    "#                     i += 1\n",
    "\n",
    "#     fig.suptitle(columnName + ' Boxplot by Hour')\n",
    "#     plt.show()\n",
    "    \n",
    "# createBoxPlot(BldgList, 'CHWTON/SQFT', BldgName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca55884-22cd-449f-822a-e3e1a7da1c23",
   "metadata": {},
   "source": [
    "## 2.3 Feature engineering Temp and Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a7c3a-2b4d-4fee-813d-a7110cbbb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Air Temp X Abs Hum\n",
    "Bldg = Bldg.drop(columns = ['Rel Hum'])\n",
    "\n",
    "Bldg['AirTempXAbsHum'] = Bldg['Air Temp'] * Bldg['Abs Hum']\n",
    "Bldg['AirTempSq'] = Bldg['Air Temp'] * Bldg['Air Temp']\n",
    "Bldg['AbsHumSq'] = Bldg['Abs Hum'] * Bldg['Abs Hum']\n",
    "Bldg = Bldg.drop(columns = ['Air Temp', 'Abs Hum'])\n",
    "\n",
    "# Remove August and September data\n",
    "Bldg = Bldg[~((Bldg['Month'] == 8) | (Bldg['Month'] == 9))]\n",
    "\n",
    "\n",
    "# Get Air Temp X Abs Hum\n",
    "Tree_X = Tree_X.drop(columns = ['Rel Hum'])\n",
    "\n",
    "Tree_X['AirTempXAbsHum'] = Tree_X['Air Temp'] * Tree_X['Abs Hum']\n",
    "Tree_X['AirTempSq'] = Tree_X['Air Temp'] * Tree_X['Air Temp']\n",
    "Tree_X['AbsHumSq'] = Tree_X['Abs Hum'] * Tree_X['Abs Hum']\n",
    "Tree_X = Tree_X.drop(columns = ['Air Temp', 'Abs Hum'])\n",
    "\n",
    "# Remove August and September data\n",
    "Tree_X = Tree_X[~((Tree_X['Month'] == 8) | (Tree_X['Month'] == 9))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fd129",
   "metadata": {},
   "source": [
    "## 2.4 Time Series Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62d7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Create List of building names so we can extract the name easily \n",
    "BldgName = list(Bldg.bldgname.unique())\n",
    "\n",
    "# 2. Create list of building df to do time series plot of CHWTON\n",
    "BldgList = []\n",
    "\n",
    "for i in range(len(BldgName)):\n",
    "    bldg_single = Bldg[Bldg['bldgname'] == BldgName[i]]\n",
    "    bldg_single = bldg_single[['bldgname', 'Date_Time','CHWTON/SQFT']]\n",
    "    bldg_single[BldgName[i]] = bldg_single['CHWTON/SQFT']\n",
    "    bldg_single = bldg_single.drop(columns = ['bldgname', 'CHWTON/SQFT'])\n",
    "    BldgList.append(bldg_single)\n",
    "    \n",
    "Bldg = Bldg.drop(columns = ['Date_Time'])\n",
    "\n",
    "from functools import reduce\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date_Time'],\n",
    "                                            how='outer'), BldgList)\n",
    "\n",
    "\n",
    "# Print CHWTON/SQFT for all buildings and all timestamps in data\n",
    "ax = df_merged['Noble Library'].plot(figsize = (15,9))\n",
    "legendlabels = []\n",
    "legendlabels.append('Noble Library')\n",
    "\n",
    "for i in range(2, 12):\n",
    "    bldgName = df_merged.columns[i]\n",
    "    df_merged[bldgName].plot(ax=ax)\n",
    "    legendlabels.append(df_merged.columns[i])\n",
    "    \n",
    "ax.legend(labels = legendlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e887047-bea4-431e-b801-a5cafd583cc3",
   "metadata": {},
   "source": [
    "## 2.5 Corr. Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed0f1b-2b0d-4cc3-914d-ed176901f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = Bldg.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corrMatrix, cmap='RdYlGn', annot = True, linewidths = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4d0e0-ec18-49fc-8026-69efa88fb02e",
   "metadata": {},
   "source": [
    "# 3. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72278137-6595-4858-81fd-5bff57b3105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer Encode\n",
    "Bldg = pd.get_dummies(Bldg, drop_first = True)\n",
    "Bldg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc094a-85cc-43b0-b416-71ba072e70ea",
   "metadata": {},
   "source": [
    "# 4. Modelling set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578b327-cdc8-42ad-98ec-8109d6b6f036",
   "metadata": {},
   "source": [
    "## 4.1 Pick desired date for Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323ca82-af8b-416d-a1a4-bfd9f6437038",
   "metadata": {},
   "source": [
    "Month available:<br>\n",
    "May: 10, 16, 23, 28<br>\n",
    "June: 7, 8, 9, 20, 21, 25, 26, 27<br>\n",
    "July: 1<br>\n",
    "\n",
    "Not Usable:<br>\n",
    "August: 1, 3, 27<br>\n",
    "September: 11, 29<br>\n",
    "\n",
    "June 9 tree<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb509f-7401-452b-a690-5d74d912fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get user to pick the day\n",
    "day = (input(\"Pick month and day <mm dd> or 00 00 for tree: \"))\n",
    "m,d = day.split(\" \")\n",
    "m = int(m)\n",
    "d= int(d)\n",
    "\n",
    "# 2. If its tree:\n",
    "if (m == 0) & (d == 0):\n",
    "    print(\"you picked tree scenario\")\n",
    "else:\n",
    "    # if not tree and not available:\n",
    "    while (len(Bldg[(Bldg['Month'] == m) & (Bldg['Day'] == d)]) == 0):\n",
    "        day = (input(\"Date unavailable, pick month and day <mm dd>: \"))\n",
    "        m,d = day.split(\" \")\n",
    "        m = int(m)\n",
    "        d = int(d)\n",
    "    \n",
    "\n",
    "print(\"You picked month: \", m, \", day: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b931cc-abdb-4c88-8b3d-ef7e93c6b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this test data\n",
    "# Bldg[(Bldg['Month'] == m) & (Bldg['Day'] == d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb72a9-d8fc-44ec-a608-3689d9017a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data frame\n",
    "if(m == 0) & (d == 0):\n",
    "    Test_df = Tree_df\n",
    "else:\n",
    "    Test_df = Bldg[(Bldg['Month'] == m) & (Bldg['Day'] == d)]\n",
    "    Test_df.reset_index(drop = True, inplace = True)\n",
    "    Test_df\n",
    "\n",
    "    # Remove Test From Bldg df \n",
    "Bldg = Bldg[~((Bldg['Month'] == m) & (Bldg['Day'] == d))]\n",
    "\n",
    "\n",
    "# Check if the day is still there\n",
    "Bldg[(Bldg['Month'] == m) & (Bldg['Day'] == d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5096d63-8fc6-48c0-afde-cd7adbeff8c0",
   "metadata": {},
   "source": [
    "## 4.3 Cyclic Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cdd44-428a-455b-9efc-c9f2f40f71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. function to encode df columns into sine and cosine\n",
    "def encode(df, col, max_val):\n",
    "    df[col.replace('_num', '') + '_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
    "    df[col.replace('_num', '') + '_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
    "    df.drop(columns = [col], inplace = True)\n",
    "    return df\n",
    "\n",
    "# 2. create a list of df for datas with cyclical time features\n",
    "Bldg_cyclic = []\n",
    "\n",
    "Bldg_enc = Bldg.copy(deep = True)\n",
    "Bldg_enc = encode(Bldg_enc, 'Minute', 60.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Hour', 23.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Day', 30.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Month', 12.0)\n",
    "\n",
    "# \n",
    "Bldg_cyclic = Bldg_enc\n",
    "print(Bldg_cyclic.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc5d0a-51c5-42c9-b9a5-c89c699af7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create a list of df for Test dates with cyclical time features\n",
    "Test_cyclic = []\n",
    "\n",
    "Test_enc = Test_df.copy(deep = True)\n",
    "Test_enc = encode(Test_enc, 'Minute', 60.0)\n",
    "Test_enc = encode(Test_enc, 'Hour', 23.0)\n",
    "Test_enc = encode(Test_enc, 'Day', 30.0)\n",
    "Test_enc = encode(Test_enc, 'Month', 12.0)\n",
    "\n",
    "Test_cyclic = Test_enc \n",
    "print(Test_cyclic.columns)\n",
    "Test_cyclic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a2120-dceb-4fc8-a504-5fb7d75ad780",
   "metadata": {},
   "source": [
    "## 4.4 Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecd35c-dbd6-43a4-9d18-8661bb1ec8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame()\n",
    "# function to train a model and get its scores\n",
    "def trainAndGetScore(pModel, pModelName, pTuningType, pDf_all_bldg, pDf_scores, pTest_df):\n",
    "    # 1. drop na values if in dataframe\n",
    "    if (pDf_all_bldg.isnull().values.any() == True):\n",
    "        pDf_all_bldg = pDf_all_bldg.dropna()\n",
    "            \n",
    "    # 2. split data into X and y\n",
    "    X = pDf_all_bldg.drop(columns=['CHWTON/SQFT'])\n",
    "    y = pDf_all_bldg['CHWTON/SQFT']  \n",
    "    \n",
    "    X_test = pTest_df.drop(columns=['CHWTON/SQFT'])\n",
    "    y_test = pTest_df['CHWTON/SQFT']  \n",
    "    \n",
    "    # 3. Train-Validate Split\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n",
    "    # 4. Fit model that already has parameters\n",
    "    pModel.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # 5. Get best params if it's a random or grid search\n",
    "    if(\"random\" in pTuningType) or (\"grid\" in pTuningType):\n",
    "        print(pModel.best_estimator_.get_params())\n",
    "        \n",
    "    # 6. Get score\n",
    "    scoreTrain = pModel.score(X_train, y_train)\n",
    "    scoreValidate = pModel.score(X_validate, y_validate)\n",
    "    scoreTest = pModel.score(X_test, y_test)\n",
    "    \n",
    "    print(X_test.columns)\n",
    "    # 7. Get prediction on test set\n",
    "    y_pred = pModel.predict(X_test)\n",
    "    pred_df = pd.DataFrame({'Bldgname': Tree_X.bldgname ,'Act CHWTON/SQFT':y_test, 'Pred CHWTON/SQFT':y_pred})\n",
    "    pred_df = pred_df.sort_index()\n",
    "    print(pred_df)\n",
    "    \n",
    "    \n",
    "    # 8. Save Score\n",
    "    \n",
    "    # 8.1 Get index\n",
    "    # a) if this is the first entry\n",
    "    if (len(pDf_scores) == 0):\n",
    "        i = 0\n",
    "    else:\n",
    "        modelNameExist = False\n",
    "        # b) if the model name we have is already existing df's row , use that index\n",
    "        for df_index in range(len(pDf_scores)):\n",
    "            if pDf_scores.loc[df_index, 'modelName'] == pModelName:\n",
    "                i = df_index\n",
    "                modelNameExist = True\n",
    "        # c) if this a a new model name:\n",
    "        if modelNameExist == False:\n",
    "                # new model name add to new row\n",
    "                i = len(pDf_scores)\n",
    "            \n",
    "    # 8.2 Add scores to df\n",
    "    pDf_scores.loc[i,'TestDate'] = str(m) + \" \" + str(d)\n",
    "    pDf_scores.loc[i,'modelName'] = pModelName\n",
    "    pDf_scores.loc[i,pTuningType + \"Train\"] = scoreTrain\n",
    "    pDf_scores.loc[i,pTuningType + \"Validate\"] = scoreValidate\n",
    "    pDf_scores.loc[i,pTuningType + \"Test\"] = scoreTest\n",
    "    \n",
    "    return pred_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4c33c",
   "metadata": {},
   "source": [
    "# 5. Model 1: Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eda26-53b7-47e4-89a3-a5b4c99f1437",
   "metadata": {},
   "source": [
    "## 5.1 Predict Base - No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ee8c3-9d00-4fc4-8421-67d5ebbf4b53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RF_base = RandomForestRegressor(n_estimators = 100, random_state = 42, oob_score = True)\n",
    "# 1. Base RF on base data\n",
    "predBase = trainAndGetScore(RF_base, \"RF\", \"base\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 2. Base RF on cyclical time features\n",
    "# predCyclic = trainAndGetScore(RF_base, \"RF_cyclic\", \"base\", Bldg_cyclic, scores_df, Test_cyclic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3dae8-f025-4c0b-848f-c2c4c1e25af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f64c1-d826-4b57-9f48-295c26456cfa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_list = list(Bldg.drop(columns = ['CHWTON/SQFT']).columns)\n",
    "feature_imp = pd.Series(RF_base.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(\"\\033[1m\" + \"Feature Importances:\" + \"\\033[0m\")\n",
    "print(feature_imp, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a8404-749f-42eb-a762-55832919ce03",
   "metadata": {},
   "source": [
    "### 5.1.1 Predict Tree June 9th - No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f7305-d723-41ab-8c73-f21e54c1ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up column for our Tree_X dataframe\n",
    "# drop unused column\n",
    "Tree_X.drop(columns = ['Date_Time'], inplace = True)\n",
    "\n",
    "# Integer Encode\n",
    "Tree_X = pd.get_dummies(Tree_X, drop_first = True)\n",
    "Tree_X.columns\n",
    "\n",
    "# add bldgname_Biodesign C column assign 0\n",
    "Tree_X['bldgname_Biodesign C'] = 0\n",
    "\n",
    "# Rearrange Column\n",
    "Tree_X = Tree_X[['Month', 'Day', 'Hour', 'Minute', 'DSW Top', 'DSW North', 'DSW East',\n",
    "       'DSW South', 'DSW West', 'Shade North', 'Shade East', 'Shade South',\n",
    "       'Shade West', 'KW', 'HTmmBTU', 'AirTempXAbsHum', 'AirTempSq',\n",
    "       'AbsHumSq', 'bldgname_Biodesign B', 'bldgname_Biodesign C',\n",
    "       'bldgname_Bulldog Hall', 'bldgname_Goldwater', 'bldgname_ISTB 2',\n",
    "       'bldgname_ISTB 4', 'bldgname_Noble Library', 'bldgname_Psychology',\n",
    "       'bldgname_Psychology North', 'bldgname_Schwada COB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af6d55-5aa3-41f2-b7fd-3e16295283e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = RF_base.predict(Tree_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36100e-aa00-49a0-bb28-394cf6ae1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predBase['Tree pred CHWTON/SQFT'] = tree_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da5ef3-0ce8-4c73-8c9a-66ceb78bcc03",
   "metadata": {},
   "source": [
    "### 5.1.2 Plot Base June 9th Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda9bac-2bec-4d1a-abc0-16262b550f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "predBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bd05e-21c2-4ae3-baba-e4ef7d13095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(BldgnameTest)):\n",
    "    figure(figsize=(10, 7), dpi=100)\n",
    "    # plt.xticks(position, BldgnameTest )\n",
    "               \n",
    "    single_bld = predBase[predBase['Bldgname'] == BldgnameTest[i]]   \n",
    "    plt.ylabel('CHWTON/SQFT')\n",
    "    plt.plot(single_bld['Act CHWTON/SQFT'], label = 'J9 Actual')\n",
    "    plt.plot(single_bld['Pred CHWTON/SQFT'], label = 'J9 Base Prediction')\n",
    "    plt.plot(single_bld['Tree pred CHWTON/SQFT'], label = 'J9 Tree Prediction')\n",
    "    plt.legend()\n",
    "    plt.title(BldgnameTest[i])           \n",
    "\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d73d4-6ebb-4047-870b-d7c749d13f89",
   "metadata": {},
   "source": [
    "## 5.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e98ed-9b0c-4b47-a1bc-1f0d7055d585",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/20463281/how-do-i-solve-overfitting-in-random-forest-of-python-sklearn\n",
    "\n",
    "1. n_estimators:  In general the more trees the less likely the algorithm is to overfit. So try increasing this. The lower this number, the closer the model is to a decision tree, with a restricted feature set. <br>\n",
    "2. max_features: try reducing this number (try 30-50% of the number of features). This determines how many features each tree is randomly assigned. The smaller, the less likely to overfit, but too small will start to introduce under fitting.<br>\n",
    "3. max_depth: Experiment with this. This will reduce the complexity of the learned models, lowering over fitting risk. Try starting small, say 5-10, and increasing you get the best result. <br>\n",
    "4. min_samples_leaf: Try setting this to values greater than one. This has a similar effect to the max_depth parameter, it means the branch will stop splitting once the leaves have that number of samples each. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b3012-d20c-4e29-bcff-5ce18752423f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters for RF\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "\n",
    "# 2. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 3. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 4. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 1, 2, 4]\n",
    "\n",
    "# 5. Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# 6. Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ca3e5-9232-4954-ad93-7209b0541d87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_random = RandomizedSearchCV(estimator = RF_base,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_random, \"RF\", \"random\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(RF_random, \"RF_cyclic\", \"random\", Bldg_cyclic, scores_df, Test_cyclic)\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449aedf7-0456-4149-8a37-ed97ce22784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF_random.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424c1ef-a59c-40fe-a18d-9d8277b5bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get oob score for best random model\n",
    "\n",
    "# 1. grab the param from best random search result\n",
    "RF_best_limit_depth = RandomForestRegressor(n_estimators = 150,\n",
    "                                       random_state = 42,\n",
    "                                       max_depth = 7,\n",
    "                                       oob_score = True,\n",
    "                                       min_samples_split= 2,\n",
    "                                       min_samples_leaf=1,\n",
    "                                       min_weight_fraction_leaf = 0.0)\n",
    "\n",
    "RF_best_limit_depth\n",
    "# 2. split data into X and y\n",
    "X = Bldg.drop(columns=['CHWTON/SQFT'])\n",
    "y = Bldg['CHWTON/SQFT']  \n",
    "    \n",
    "X_test = Test_df.drop(columns=['CHWTON/SQFT'])\n",
    "y_test = Test_df['CHWTON/SQFT']  \n",
    "    \n",
    "# 3. Train-Test Split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n",
    "# 4. Fit model that already has parameters\n",
    "RF_best_limit_depth.fit(X_train, y_train)\n",
    "RF_best_limit_depth.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ae283-3522-4f0a-8c57-bda420f18348",
   "metadata": {},
   "source": [
    "## 5.3 RF Explain Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b172c0-194c-416f-82d7-99caff62c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X for Explaining\n",
    "BldgX = Bldg.drop(columns = 'CHWTON/SQFT')\n",
    "Bldg_cyclicX = Bldg_cyclic.drop(columns = 'CHWTON/SQFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089771e-f107-48db-ace1-cf2cf8d684b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best_limit_depth = RandomForestRegressor(n_estimators = 100, random_state = 42, oob_score = True, max_depth = 7)\n",
    "# 1. Base RF on base data\n",
    "trainAndGetScore(RF_best_limit_depth, \"RF_limit_depth\", \"base\", Bldg, scores_df, Test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64e999-30cb-41d2-9b2b-0d040f5e1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Extract single tree\n",
    "estimator = RF_best_limit_depth.estimators_[3]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# 4. Export tree as dot file\n",
    "export_graphviz(estimator,\n",
    "                out_file='tree.dot', \n",
    "                feature_names = BldgX.columns,\n",
    "                rounded = True,\n",
    "                proportion = False, \n",
    "                precision = 7,\n",
    "                filled = True)\n",
    "\n",
    "# # 5. Convert the tree to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# # 6. Display png image of this one tree in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34ff35-b24e-422e-928d-2749378863d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ff982-0c87-4ce1-b747-5b04990281f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(estimator, X_train, y_train, feature_names=X_train.columns, target_name='CHWTON/SQFT')\n",
    "viz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c5f3b-4847-44b7-b7b4-8792a5b85d04",
   "metadata": {},
   "source": [
    "## 5.4 RF Lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f29a13-25db-4cf8-bb5a-545a265764b8",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2ff7d-5062-4160-9150-7b8db65baf61",
   "metadata": {},
   "source": [
    "### 5.4.1 Create Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db83fb2-d152-40a9-9ba6-79dc01f5b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                   feature_names = BldgX,\n",
    "                                                   class_names = 'CHWTON/SQFT',\n",
    "                                                   verbose = True,\n",
    "                                                   mode = 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee902a-ec6a-41e7-9138-7916264fe68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 10\n",
    "exp = explainer.explain_instance(X_test.values[i], RF_best_limit_depth.predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c2ce8-8ebb-47b8-a991-58349f69eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652e14b-4091-4e27-b407-aeff4eba0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33671b52-7533-4752-8dc6-14c39821ba97",
   "metadata": {},
   "source": [
    "## 5.5 RF Grid Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c444f9-a995-411b-b82a-5e0e8dc223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [150, 170],\n",
    "               'max_features': [\"sqrt\"],\n",
    "               'max_depth': [50,60,70],\n",
    "               'min_samples_split': [2, 3],\n",
    "               'min_samples_leaf': [ 1, 2],\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af34a8-bcc0-47a0-a2a9-957306fe144d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_grid = GridSearchCV(estimator = RF_base,\n",
    "                       param_grid = param_grid,\n",
    "                       cv = 5,\n",
    "                       scoring ='r2',\n",
    "                       n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_grid, \"RF\", \"grid\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(RF_grid, \"RF_cyclic\", \"grid\", Bldg_cyclic, scores_df, Test_cyclic)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba86d-d905-4050-af9e-720be9883b29",
   "metadata": {},
   "source": [
    "# 6. Model 2: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f7a20-eeff-4122-b0f2-7e4519aaf62f",
   "metadata": {},
   "source": [
    "## 6.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194165bb-5300-4014-9480-c31492e3d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create base model\n",
    "XGB_base = XGBRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 2. Base XGB on base data\n",
    "trainAndGetScore(XGB_base, \"XGB\", \"base\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 3. Base XGB on cyclica time features\n",
    "trainAndGetScore(XGB_base, \"XGB_cyclic\", \"base\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c0700-ac88-4cb9-b276-b9013c1284df",
   "metadata": {},
   "source": [
    "## 6.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a779b-76b3-44ec-9fb3-77b4d3d54c4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "params = {\n",
    "    'n_estimators':[ 100, 250, 500, 1000],\n",
    "    'min_child_weight':[4,5,8], \n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "n_iter_search = 20\n",
    "XGB_random = RandomizedSearchCV(XGB_base,\n",
    "                                param_distributions = params,\n",
    "                                n_iter = n_iter_search,\n",
    "                                cv = 5,\n",
    "                                verbose = 2,\n",
    "                                random_state = 42,\n",
    "                                scoring ='r2',\n",
    "                                n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(XGB_random, \"XGB\", \"random\", Bldg, scores_df,Test_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(XGB_random, \"XGB_random_cyclic\", Bldg_cyclic, scores_df, Test_cyclic)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd4792-01f9-4d5e-9330-43b228a5b313",
   "metadata": {},
   "source": [
    "# 7. Model 3: LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482554db-64fa-4f25-9a5e-479b5cf525be",
   "metadata": {},
   "source": [
    "## 7.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b9a1-6a53-499e-8f10-88f57beb99cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "LGBM_base = lgb.LGBMRegressor(random_state = 42)\n",
    "\n",
    "# 2. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_base, \"LGBM\" , \"base\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 3. Base LGBM on cyclica time features\n",
    "# trainAndGetScore(LGBM_base, \"LGBM_cylic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3765ed-d58d-4341-adfe-dbf4727f33cb",
   "metadata": {},
   "source": [
    "## 7.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0e798-0697-49bc-8524-50513240672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "random_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'learning_rate': [0.1, 0.03, 0.003],\n",
    "    'max_depth': [-1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "LGBM_random = RandomizedSearchCV(estimator = LGBM_base,\n",
    "                                 param_distributions = random_grid, \n",
    "                                 n_iter = 100, cv = 2,\n",
    "                                 scoring='r2',\n",
    "                                 verbose= 2,\n",
    "                                 random_state= 42,\n",
    "                                 n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e469572-f06f-478b-8017-b3ba68af1708",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Base LGBM on base data\n",
    "# trainAndGetScore(LGBM_random, \"LGBM_random\", Bldg, scores_df)\n",
    "trainAndGetScore(LGBM_base, \"LGBM\" , \"random\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 4. Base LGBM on cyclica time features\n",
    "# trainAndGetScore(LGBM_random, \"LGBM_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44931bcb-05ad-4338-8170-a084813c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ONE HOT ENCODING SCORE:\")\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d96e91-cbab-40f8-8dd9-56fec3293225",
   "metadata": {},
   "source": [
    "# 8. Model 4: Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fecc75-a865-45ec-8819-31aee54b9e2c",
   "metadata": {},
   "source": [
    "## 8.1 Prepare datas using label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20778bad-021e-4293-9b56-4e491308fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df_cat = pd.DataFrame()\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg_df_cat = Bldg_df_cat.append(Bldg[i])\n",
    "    \n",
    "Bldg_df_cat.reset_index(drop = True , inplace = True)\n",
    "Bldg_df_cat.drop(columns=['Date', 'Time', 'Date_Time'],inplace = True)\n",
    "\n",
    "# # create a list of df for buildings with cyclical time features\n",
    "# Bldg_cyclic_cat = []\n",
    "\n",
    "# Bldg_enc = Bldg_df_cat.copy(deep = True)\n",
    "# Bldg_enc = encode(Bldg_enc, 'Minute_num', 60.0)\n",
    "# Bldg_enc = encode(Bldg_enc, 'Hour_num', 23.0)\n",
    "# Bldg_enc = encode(Bldg_enc, 'Day_num', 30.0)\n",
    "# Bldg_enc = encode(Bldg_enc, 'Month_num', 12.0)\n",
    "# Bldg_cyclic_cat = Bldg_enc\n",
    "    \n",
    "# # Plot cyclical features sample\n",
    "# fig, ax = plt.subplots(2,2, figsize = (8,7))\n",
    "# Bldg_cyclic_cat.plot.scatter('Minute_sin', 'Minute_cos', ax = ax[0,0]).set_aspect('equal')\n",
    "# Bldg_cyclic_cat.plot.scatter('Hour_sin', 'Hour_cos', ax = ax[0,1]).set_aspect('equal')\n",
    "# Bldg_cyclic_cat.plot.scatter('Day_sin', 'Day_cos', ax = ax[1,0]).set_aspect('equal')\n",
    "# Bldg_cyclic_cat.plot.scatter('Month_sin', 'Month_cos', ax = ax[1,1]).set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c02b73-1e67-4f58-937e-c49546effa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bldg_cyclic_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa8721-b0ff-4615-8167-ab74927d1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Assigning numerical values and storing in another column\n",
    "Bldg_df_cat['bldgname'] = label_encoder.fit_transform(Bldg_df_cat['bldgname'])\n",
    "Bldg_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc9057f-6c1c-4cf6-943d-faa5db36072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df_cat.bldgname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7699ef3-2967-42ed-b973-68657f48b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split data into X and y\n",
    "X = Bldg_df_cat.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "y = Bldg_df_cat['CHWTON/SQFT']   \n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n",
    "X_test = test_df.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "y_test = test_df['CHWTON/SQFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52751b-0ea9-44cd-8119-fc2da6e89720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d679f18-daf9-415d-aae1-6ea41cda0e1a",
   "metadata": {},
   "source": [
    "## 8.2 Catboost Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc5589-94b8-4429-96b2-f390df338a56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. hyperparameter grid\n",
    "cb_grid = {'iterations': [50, 100, 150, 200, 250],\n",
    "            'learning_rate': [0.03, 0.1],\n",
    "            'depth': [2, 4, 8, 10, 12],\n",
    "            'l2_leaf_reg': [0.2, 0.5, 1, 3, 5, 7]}\n",
    "\n",
    "# 2. instantiate RandomSearchCv object\n",
    "CB_random_obj = RandomizedSearchCV(estimator = catboost,\n",
    "                               param_distributions = cb_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "\n",
    "# 3. Fit the model\n",
    "CB_random_obj.fit(X_train,y_train)\n",
    "\n",
    "# 4. print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(CB_random_obj.best_estimator_.get_params())\n",
    "pprint(CB_random_obj.best_score_)\n",
    "\n",
    "# 5. get the best model\n",
    "CB_random = CB_random_obj.best_estimator_\n",
    "\n",
    "# 6. get validation , test score \n",
    "scoreTrain = CB_random.score(X_train, y_train)\n",
    "scoreValidate = CB_random.score(X_validate, y_validate)\n",
    "scoreTest = CB_random.score(X_test, y_yest)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5afb4-f368-4d8a-a757-409481fb572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoreTrain, scoreValidate, scoreTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a696e-920c-4f96-87b0-e3cb345d02d7",
   "metadata": {},
   "source": [
    "## 8.3 Catboost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3bcfd-1787-467f-b71a-594bc2e4a25c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. initialize model and grid\n",
    "catboost = cb.CatBoostRegressor(loss_function='RMSE')\n",
    "grid = {'depth': [8, 10,12],\n",
    "        'iterations': [230,250,270],\n",
    "        'learning_rate': [0.08, 0.1, 0.15],\n",
    "        'l2_leaf_reg': [0.8, 1, 2]}\n",
    "\n",
    "\n",
    "# 4. search parameter\n",
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)\n",
    "result = catboost.grid_search(grid,\n",
    "                           train_dataset,\n",
    "                           cv = 5,\n",
    "                           search_by_train_test_split=True,\n",
    "                           shuffle = True,\n",
    "                           refit = True,\n",
    "                           verbose = True,\n",
    "                           train_size = 0.8 )\n",
    "\n",
    "\n",
    "# 4. get best params\n",
    "best_params = result['params']\n",
    "\n",
    "# 5. fit model with best params\n",
    "CB_grid = cb.CatBoostRegressor(depth = best_params['depth'],\n",
    "                               iterations = best_params['iterations'],\n",
    "                               learning_rate= best_params['learning_rate'],\n",
    "                               l2_leaf_reg = best_params['l2_leaf_reg'])\n",
    "CB_grid.fit(train_dataset)\n",
    "\n",
    "# 6. get score \n",
    "score = CB_grid.score(X_test, y_test)\n",
    "scores_df['CB_grid']=score\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4e309-f5c3-4893-ba68-f392f3b65119",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1d4f9-6272-4d82-80e1-f8351958a029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myConda]",
   "language": "python",
   "name": "conda-env-myConda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b2ed8-783e-437f-b4dd-ee4536489cd9",
   "metadata": {},
   "source": [
    "### Combined all building datas and create new Builiding column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6dbd75",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6345f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# import h2o\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# parameters search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "# To: install catboost\n",
    "# !pip3 install catboost\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13b3447-eee2-48bf-bad6-019de550093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e621a",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98beeaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list to add csv files as df\n",
    "Bldg = []\n",
    "\n",
    "# Read all building data and append to list\n",
    "for path in pathlib.Path(\"../Data/microclimate_model/Combined/dataset1\").iterdir():\n",
    "        if path.is_file():\n",
    "            current_file = pd.read_csv(path)\n",
    "            current_file = current_file.drop(columns=['Unnamed: 0'])\n",
    "            Bldg.append(current_file)\n",
    "    \n",
    "# Bldg = pd.read_csv(\"../Data/microclimate_model/Combined/dataset1/all_buildings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dbe77be-8d4d-4416-8696-203f4a3b79ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bldg.pop(4)\n",
    "len(Bldg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f4377",
   "metadata": {},
   "source": [
    "## 1.1 Preprocessing \n",
    "\n",
    "1. Adding Month, Hour, and Minute to data\n",
    "2. Removing hours out of ENVI-met accuracy range (after 9 pm)\n",
    "3. Add CHWTON/SQFT to columns using condition area for each building taken from\n",
    "    https://fdm-apps.asu.edu/UFRM/FDS/FacilityData.aspx\n",
    "4. Drop na rows in limited data (some data points from campus metabolism not available)\n",
    "5. Add Absolute Humidity to Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Month, Hour, and Minute column for all dataframes in list\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg[i]['Date_Time'] = pd.to_datetime(Bldg[i].Date_Time)\n",
    "    Bldg[i]['Month_num'] = Bldg[i].Date_Time.dt.month\n",
    "    Bldg[i]['Hour_num'] = Bldg[i].Date_Time.dt.hour\n",
    "    Bldg[i]['Minute_num'] = Bldg[i].Date_Time.dt.minute\n",
    "    Bldg[i]['Day_num'] = Bldg[i].Date_Time.dt.day\n",
    "\n",
    "# Remove data after 9pm\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg[i] = Bldg[i][(Bldg[i]['Hour_num'] <= 20) & (Bldg[i]['Hour_num'] > 0)]\n",
    "\n",
    "# Add Column: CHWTON/Condition Area (SqFt) or ['CHWTON/SQFT']\n",
    "cond_area = {'Noble Library':88658,'Biodesign B':132215,'Biodesign C':145410,\n",
    "             'Biodesign A':133016,'Psychology':69864,'Goldwater':165237,'Schwada COB':99857,\n",
    "             'ISTB 2':41404,'Bulldog Hall':68067,'ISTB 4':231646,'Psychology North':43034}\n",
    "for i in range(len(Bldg)):\n",
    "    if Bldg[i]['bldgname'][0] in cond_area:\n",
    "        Bldg[i]['CHWTON/SQFT'] = Bldg[i]['CHWTON'] / cond_area[Bldg[i]['bldgname'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eeb8b1-fb0c-4e32-b3c3-1164085b428e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Absolute Humidity Equations: https://www.hatchability.com/Vaisala.pdf. To test, compare with https://planetcalc.com/2167/ but notice the calculation made here is in g/m^3 and in this website it is in Kg/m^3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244321a-7dc9-401f-aa34-4f40c85bee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if NA in data\n",
    "for i in range(len(Bldg)):\n",
    "    null_data = Bldg[i][Bldg[i].isnull().any(axis=1)]\n",
    "#     print(null_data)\n",
    "\n",
    "# Drop NA rows in data\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg[i] = Bldg[i].dropna()\n",
    "    Bldg[i] = Bldg[i].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9732bc-cc9f-4ebc-be71-a3c422273b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Rel Hum to Abs Hum\n",
    "for i in range(len(Bldg)):\n",
    "    T_i = Bldg[i]['Air Temp']\n",
    "    RH = Bldg[i]['Rel Hum']/100\n",
    "\n",
    "    T = T_i + 273.15\n",
    "    P_c = 220640\n",
    "    T_c = 647.096\n",
    "    C_1 = -7.85951783\n",
    "    C_2 = 1.84408259\n",
    "    C_3 =  -11.7866497\n",
    "    C_4 = 22.6807411\n",
    "    C_5 = -15.9618719\n",
    "    C_6 = 1.80122502\n",
    "    v = 1 - (T/T_c)\n",
    "\n",
    "    x = (T_c/T)*((C_1*v) + (C_2*np.power(v, 1.5)) + (C_3*np.power(v, 3)) \n",
    "                 + (C_4*np.power(v, 3.5)) + (C_5*np.power(v, 4)) + (C_6*np.power(v, 7.5))) \n",
    "\n",
    "    P_ws = np.exp(x)*P_c\n",
    "    P_w = P_ws*RH\n",
    "\n",
    "    C = 2.16679\n",
    "    A = C*P_w*100/T\n",
    "\n",
    "    Bldg[i]['Abs Hum'] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8bb22-1e56-4b54-b90b-10ef68e67856",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg[0].Date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427cc98-060f-45ed-9353-a7c97865e1f7",
   "metadata": {},
   "source": [
    "Month available:<br>\n",
    "May: 16, 23 <br>\n",
    "June: 7, 8, 20, 21, 25, 26<br>\n",
    "August: 3, 27<br>\n",
    "September: 11, 29<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227ea14",
   "metadata": {},
   "source": [
    "# 3. All Buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4b6b1",
   "metadata": {},
   "source": [
    "## 3.1 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690c813",
   "metadata": {},
   "source": [
    "### 3.1.1 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bac77-99fd-42b8-bd10-0cd22ebe1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of building names so we can extract the name easily \n",
    "BldgName = [\"Noble Library\",\"Biodesign B\",\"Biodesign C\",\n",
    "              \"Biodesign A\", \"Psychology\", \"Goldwater\",\n",
    "              \"Schwada COB\", \"ISTB 2\", \"Bulldog Hall\",\n",
    "              \"ISTB 4\", \"Pyschology North\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb5f01-97cf-4532-ae7e-54ed5047b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Bldg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2122d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create CHWTON boxplots for all buildings #\n",
    "def createBoxPlot(df, columnName, BldgName):\n",
    "    row_size = 6\n",
    "    column_size = 2\n",
    "    fig, ax = plt.subplots(row_size, column_size, figsize = (15,40))\n",
    "\n",
    "    i = 0\n",
    "    while i < (len(df)):\n",
    "        print(i)\n",
    "        for row in range(row_size):\n",
    "            for col in range(column_size):\n",
    "                if i < len(df):\n",
    "                    df[i].boxplot(by='Hour_num',\n",
    "                                    column=[columnName],\n",
    "                                    grid = False,\n",
    "                                    figsize = (5,5),\n",
    "                                    ax = ax[row,col] )\n",
    "                    ax[row,col].title.set_text(BldgName[i])\n",
    "                    i += 1\n",
    "\n",
    "    fig.suptitle(columnName + ' Boxplot by Hour')\n",
    "    plt.show()\n",
    "    \n",
    "createBoxPlot(Bldg, 'CHWTON', BldgName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa283b62-6282-42d1-9f85-431f1c22dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "createBoxPlot(Bldg, 'Air Temp', BldgName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fd129",
   "metadata": {},
   "source": [
    "### 3.1.2 Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fe0f1-0e06-4a76-8aa1-96433ede68b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62d7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Print CHWTON/SQFT for all buildings and all timestamps in data\n",
    "ax = Bldg[0]['CHWTON/SQFT'].plot(figsize = (15,9))\n",
    "legendlabels = []\n",
    "for i in range(len(Bldg)-1):\n",
    "    Bldg[i+1]['CHWTON/SQFT'].plot(ax=ax)\n",
    "    legendlabels.append(Bldg[i].bldgname[0])\n",
    "    \n",
    "ax.legend(labels = legendlabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334680f-8845-42a6-9917-0bdad23027cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb4d0e0-ec18-49fc-8026-69efa88fb02e",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895b107-8cba-4a85-9db5-b8f67ca4f2c2",
   "metadata": {},
   "source": [
    "### 3.2.1 Combine all building data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee9476-e326-47b4-936e-8ab29ec1443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df = pd.DataFrame()\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg_df = Bldg_df.append(Bldg[i])\n",
    "    \n",
    "Bldg_df.reset_index(drop = True , inplace = True)\n",
    "Bldg_df.drop(columns=['Date', 'Time', 'Date_Time'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729cb8e-cb3c-4101-9b16-ffc7a23cdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e290f-3ed7-45a6-9651-f839e37ce60d",
   "metadata": {},
   "source": [
    "### 3.2.1 One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72278137-6595-4858-81fd-5bff57b3105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer Encode\n",
    "Bldg_df = pd.get_dummies(Bldg_df, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e383c-718c-47fe-b881-1f00699200f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f88ad-19e4-4daf-a42b-0211853768c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_pd = pd.DataFrame(Bldg_df)\n",
    "# corrMatrix = corr_pd.corr()\n",
    "# sns.heatmap(corrMatrix)\n",
    "\n",
    "corrMatrix = Bldg_df.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corrMatrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cea02a-1d27-481d-81df-3fb87ce38754",
   "metadata": {},
   "source": [
    "### 3.2.3 Cyclic Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d202e9-1384-4410-a5f1-c83e27216e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encode df columns into sine and cosine\n",
    "def encode(df, col, max_val):\n",
    "    df[col.replace('_num', '') + '_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
    "    df[col.replace('_num', '') + '_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
    "    df.drop(columns = [col], inplace = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef06d9-9619-4ac6-941e-28c5e9100d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of df for buildings with cyclical time features\n",
    "Bldg_cyclic = []\n",
    "\n",
    "Bldg_enc = Bldg_df.copy(deep = True)\n",
    "Bldg_enc = encode(Bldg_enc, 'Minute_num', 60.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Hour_num', 23.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Day_num', 30.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Month_num', 12.0)\n",
    "Bldg_cyclic = Bldg_enc\n",
    "    \n",
    "# Plot cyclical features sample\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,7))\n",
    "Bldg_cyclic.plot.scatter('Minute_sin', 'Minute_cos', ax = ax[0,0]).set_aspect('equal')\n",
    "Bldg_cyclic.plot.scatter('Hour_sin', 'Hour_cos', ax = ax[0,1]).set_aspect('equal')\n",
    "Bldg_cyclic.plot.scatter('Day_sin', 'Day_cos', ax = ax[1,0]).set_aspect('equal')\n",
    "Bldg_cyclic.plot.scatter('Month_sin', 'Month_cos', ax = ax[1,1]).set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f78039-0eae-4d64-8d94-04ad4469cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb80111-7320-4a40-8960-1826e4fca9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fb4a2-135c-492b-9aa0-15c1b024f46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ffc094a-85cc-43b0-b416-71ba072e70ea",
   "metadata": {},
   "source": [
    "## 3.3 Modelling set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa8df0-a665-431e-8ea1-b4ff7fe172a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecd35c-dbd6-43a4-9d18-8661bb1ec8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train a model and get its scores\n",
    "def trainAndGetScore(pModel, pModelName, pDf_all_bldg, pDf_scores):\n",
    "    # 1. drop na values if in dataframe\n",
    "    if (pDf_all_bldg.isnull().values.any() == True):\n",
    "        pDf_all_bldg = pDf_all_bldg.dropna()\n",
    "            \n",
    "    # 2. split data into X and y\n",
    "    X = pDf_all_bldg.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "    y = pDf_all_bldg['CHWTON/SQFT']  \n",
    "    print('X:\\n',X.columns)\n",
    "    print('y:\\n',y)       \n",
    "    # 3. Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n",
    "    # 4. fit model that already has parameters\n",
    "    pModel.fit(X_train, y_train)\n",
    "        \n",
    "    # 5. Get prediction\n",
    "    y_pred = pModel.predict(X_test)\n",
    "    ModelPred = pd.DataFrame({'Actual CHWTON/SQFT':y_test, 'Predicted CHWTON/SQFT':y_pred})\n",
    "    ModelPred = ModelPred.sort_index()\n",
    "    print(ModelPred)\n",
    "    \n",
    "    # 6. Get best params if it's a random or grid search\n",
    "    if(\"random\" in pModelName) or (\"grid\" in pModelName):\n",
    "        print(pModel.best_estimator_.get_params())\n",
    "        \n",
    "    # Save scores\n",
    "    score = pModel.score(X_test, y_test)\n",
    "    pDf_scores.loc[0,pModelName] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4c33c",
   "metadata": {},
   "source": [
    "## 3.4 Model 1: Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eda26-53b7-47e4-89a3-a5b4c99f1437",
   "metadata": {},
   "source": [
    "### 3.4.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ee8c3-9d00-4fc4-8421-67d5ebbf4b53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RF_base = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 1. Base RF on base data\n",
    "trainAndGetScore(RF_base, \"RF_base\", Bldg_df, scores_df)\n",
    "\n",
    "# 2. Base RF on cyclical time features\n",
    "trainAndGetScore(RF_base, \"RF_cyclic\", Bldg_cyclic, scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3dae8-f025-4c0b-848f-c2c4c1e25af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d73d4-6ebb-4047-870b-d7c749d13f89",
   "metadata": {},
   "source": [
    "### 3.4.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b3012-d20c-4e29-bcff-5ce18752423f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters for RF\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "\n",
    "# 2. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 3. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 4. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 1, 2, 4]\n",
    "\n",
    "# 5. Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# 6. Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ca3e5-9232-4954-ad93-7209b0541d87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_random = RandomizedSearchCV(estimator = RF_base,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_random, \"RF_random\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(RF_random, \"RF_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449aedf7-0456-4149-8a37-ed97ce22784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF_random.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33671b52-7533-4752-8dc6-14c39821ba97",
   "metadata": {},
   "source": [
    "### 3.4.3 Grid Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c444f9-a995-411b-b82a-5e0e8dc223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [200, 220, 230,240],\n",
    "               'max_features': [\"sqrt\"],\n",
    "               'max_depth': [17, 20, 22],\n",
    "               'min_samples_split': [2,3,4],\n",
    "               'min_samples_leaf': [ 1, 2],\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af34a8-bcc0-47a0-a2a9-957306fe144d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_grid = GridSearchCV(estimator = RF_base,\n",
    "                       param_grid = param_grid,\n",
    "                       cv = 5,\n",
    "                       scoring ='r2',\n",
    "                       n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_grid, \"RF_grid\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(RF_grid, \"RF_grid_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba86d-d905-4050-af9e-720be9883b29",
   "metadata": {},
   "source": [
    "## 3.5 Model 2: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f7a20-eeff-4122-b0f2-7e4519aaf62f",
   "metadata": {},
   "source": [
    "### 3.5.1. No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194165bb-5300-4014-9480-c31492e3d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create base model\n",
    "XGB_base = XGBRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 2. Base XGB on base data\n",
    "trainAndGetScore(XGB_base, \"XGB_base\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Base XGB on cyclica time features\n",
    "trainAndGetScore(XGB_base, \"XGB_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c0700-ac88-4cb9-b276-b9013c1284df",
   "metadata": {},
   "source": [
    "### 3.5.2. Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a779b-76b3-44ec-9fb3-77b4d3d54c4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "params = {\n",
    "    'n_estimators':[ 100, 250, 500, 1000],\n",
    "    'min_child_weight':[4,5,8], \n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "n_iter_search = 20\n",
    "XGB_random = RandomizedSearchCV(XGB_base,\n",
    "                                param_distributions = params,\n",
    "                                n_iter = n_iter_search,\n",
    "                                cv = 5,\n",
    "                                verbose = 2,\n",
    "                                random_state = 42,\n",
    "                                scoring ='r2',\n",
    "                                n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(XGB_random, \"XGB_random\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(XGB_random, \"XGB_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd4792-01f9-4d5e-9330-43b228a5b313",
   "metadata": {},
   "source": [
    "## 3.6 Model 3: LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482554db-64fa-4f25-9a5e-479b5cf525be",
   "metadata": {},
   "source": [
    "### 3.6.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b9a1-6a53-499e-8f10-88f57beb99cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "LGBM_base = lgb.LGBMRegressor(random_state = 42)\n",
    "\n",
    "# 2. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_base, \"LGBM_base\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Base LGBM on cyclica time features\n",
    "trainAndGetScore(LGBM_base, \"LGBM_cylic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3765ed-d58d-4341-adfe-dbf4727f33cb",
   "metadata": {},
   "source": [
    "### 3.6.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0e798-0697-49bc-8524-50513240672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "random_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'learning_rate': [0.1, 0.03, 0.003],\n",
    "    'max_depth': [-1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "LGBM_random = RandomizedSearchCV(estimator = LGBM_base,\n",
    "                                 param_distributions = random_grid, \n",
    "                                 n_iter = 100, cv = 2,\n",
    "                                 scoring='r2',\n",
    "                                 verbose= 2,\n",
    "                                 random_state= 42,\n",
    "                                 n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e469572-f06f-478b-8017-b3ba68af1708",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_random, \"LGBM_random\", Bldg_df, scores_df)\n",
    "\n",
    "# 4. Base LGBM on cyclica time features\n",
    "trainAndGetScore(LGBM_random, \"LGBM_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44931bcb-05ad-4338-8170-a084813c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ONE HOT ENCODING SCORE:\")\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d96e91-cbab-40f8-8dd9-56fec3293225",
   "metadata": {},
   "source": [
    "## 3.7 Model 4: Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fecc75-a865-45ec-8819-31aee54b9e2c",
   "metadata": {},
   "source": [
    "### 3.7.0 Prepare datas using label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20778bad-021e-4293-9b56-4e491308fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df_cat = pd.DataFrame()\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg_df_cat = Bldg_df_cat.append(Bldg[i])\n",
    "    \n",
    "Bldg_df_cat.reset_index(drop = True , inplace = True)\n",
    "Bldg_df_cat.drop(columns=['Date', 'Time', 'Date_Time'],inplace = True)\n",
    "# create a list of df for buildings with cyclical time features\n",
    "Bldg_cyclic_cat = []\n",
    "\n",
    "Bldg_enc = Bldg_df_cat.copy(deep = True)\n",
    "Bldg_enc = encode(Bldg_enc, 'Minute_num', 60.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Hour_num', 23.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Day_num', 30.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Month_num', 12.0)\n",
    "Bldg_cyclic_cat = Bldg_enc\n",
    "    \n",
    "# Plot cyclical features sample\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,7))\n",
    "Bldg_cyclic_cat.plot.scatter('Minute_sin', 'Minute_cos', ax = ax[0,0]).set_aspect('equal')\n",
    "Bldg_cyclic_cat.plot.scatter('Hour_sin', 'Hour_cos', ax = ax[0,1]).set_aspect('equal')\n",
    "Bldg_cyclic_cat.plot.scatter('Day_sin', 'Day_cos', ax = ax[1,0]).set_aspect('equal')\n",
    "Bldg_cyclic_cat.plot.scatter('Month_sin', 'Month_cos', ax = ax[1,1]).set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c02b73-1e67-4f58-937e-c49546effa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa8721-b0ff-4615-8167-ab74927d1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "Bldg_df_cat['bldgname'] = label_encoder.fit_transform(Bldg_df_cat['bldgname'])\n",
    "Bldg_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc9057f-6c1c-4cf6-943d-faa5db36072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df_cat.bldgname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7699ef3-2967-42ed-b973-68657f48b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split data into X and y\n",
    "X = Bldg_df_cat.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "y = Bldg_df_cat['CHWTON/SQFT']   \n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d679f18-daf9-415d-aae1-6ea41cda0e1a",
   "metadata": {},
   "source": [
    "### 3.7.1 Catboost Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc5589-94b8-4429-96b2-f390df338a56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. hyperparameter grid\n",
    "cb_grid = {'iterations': [50, 100, 150, 200, 250],\n",
    "            'learning_rate': [0.03, 0.1],\n",
    "            'depth': [2, 4, 8, 10, 12],\n",
    "            'l2_leaf_reg': [0.2, 0.5, 1, 3, 5, 7]}\n",
    "\n",
    "# 2. instantiate RandomSearchCv object\n",
    "CB_random_obj = RandomizedSearchCV(estimator = catboost,\n",
    "                               param_distributions = cb_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "\n",
    "# 3. Fit the model\n",
    "CB_random_obj.fit(X_train,y_train)\n",
    "\n",
    "# 4. print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(CB_random_obj.best_estimator_.get_params())\n",
    "pprint(CB_random_obj.best_score_)\n",
    "\n",
    "# 5. get the best model\n",
    "CB_random = CB_random_obj.best_estimator_\n",
    "\n",
    "# 6. get score \n",
    "score = CB_random.score(X_test, y_test)\n",
    "scores_df['CB_random']=score\n",
    "print(score)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5afb4-f368-4d8a-a757-409481fb572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a696e-920c-4f96-87b0-e3cb345d02d7",
   "metadata": {},
   "source": [
    "### 3.7.2 Catboost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3bcfd-1787-467f-b71a-594bc2e4a25c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. initialize model and grid\n",
    "catboost = cb.CatBoostRegressor(loss_function='RMSE')\n",
    "grid = {'depth': [8, 10,12],\n",
    "        'iterations': [230,250,270],\n",
    "        'learning_rate': [0.08, 0.1, 0.15],\n",
    "        'l2_leaf_reg': [0.8, 1, 2]}\n",
    "\n",
    "\n",
    "# 4. search parameter\n",
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)\n",
    "result = catboost.grid_search(grid,\n",
    "                           train_dataset,\n",
    "                           cv = 5,\n",
    "                           search_by_train_test_split=True,\n",
    "                           shuffle = True,\n",
    "                           refit = True,\n",
    "                           verbose = True,\n",
    "                           train_size = 0.8 )\n",
    "\n",
    "\n",
    "# 4. get best params\n",
    "best_params = result['params']\n",
    "\n",
    "# 5. fit model with best params\n",
    "CB_grid = cb.CatBoostRegressor(depth = best_params['depth'],\n",
    "                               iterations = best_params['iterations'],\n",
    "                               learning_rate= best_params['learning_rate'],\n",
    "                               l2_leaf_reg = best_params['l2_leaf_reg'])\n",
    "CB_grid.fit(train_dataset)\n",
    "\n",
    "# 6. get score \n",
    "score = CB_grid.score(X_test, y_test)\n",
    "scores_df['CB_grid']=score\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4e309-f5c3-4893-ba68-f392f3b65119",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1d4f9-6272-4d82-80e1-f8351958a029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

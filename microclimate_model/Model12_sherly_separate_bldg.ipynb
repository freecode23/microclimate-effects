{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a9ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm\n",
    "\n",
    "# Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# parameters search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scoring\n",
    "import math\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "\n",
    "\n",
    "# Local config\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca9cf9-1efe-45b8-936c-677cca195189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \"\"\"\n",
    "    This class encapsulates the datas that we will need for training and testing for each building.\n",
    "    It uses July 7th for the test data.\n",
    "    \"\"\"\n",
    "    def __init__(self, bldg_name, df, dropped_cols=[]):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            bldgs_df_list (str) : list of dataframe with each dataframe consisting of a single building. \n",
    "            dropped_cols (str) : The path for the test csv file. \n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        # Filter out the data for July 7\n",
    "        df[config.DATE_TIME] = pd.to_datetime(df[config.DATE_TIME])\n",
    "        test_data = df[(df[config.DATE_TIME].dt.month == 7) & (df[config.DATE_TIME].dt.day == 7)]\n",
    "        train_data = df[~((df[config.DATE_TIME].dt.month == 7) & (df[config.DATE_TIME].dt.day == 7))]\n",
    "        \n",
    "        # Cols to keep.\n",
    "        model_cols = ['CHWTON/SQM','AirT_Mean', 'AbsH_Mean','ShortW_North',\n",
    "              'ShortW_East', 'ShortW_South', 'ShortW_West', 'ShortW_Top',\n",
    "             'Shade_North', 'Shade_East', 'Shade_South', 'Shade_West', 'Shade_Top', 'KW/SQM']\n",
    "\n",
    "        train_data = train_data[model_cols]\n",
    "        test_data = test_data[model_cols]\n",
    "        \n",
    "        # Prepare features and target variable\n",
    "        self.bldg_name = bldg_name\n",
    "        self.X_train = train_data.drop(config.CHWTON_SQM, axis=1)\n",
    "        self.y_train = train_data[config.CHWTON_SQM]\n",
    "        self.X_test = test_data.drop(config.CHWTON_SQM, axis=1)\n",
    "        self.y_test = test_data[config.CHWTON_SQM]\n",
    "        self.df = df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00beb8f-3e58-4719-9be3-24d8fd1a0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    '''\n",
    "    Given a base model and grid or random params, the class will create\n",
    "    the search grid and assign the name to each of this model.\n",
    "    '''\n",
    "    def __init__(self, name, base_model, param, cv, n_iter, search_mode):\n",
    "        # Base model\n",
    "        self.name = name\n",
    "        self.base = base_model\n",
    "        self.search_mode = search_mode\n",
    "        self.best = None\n",
    "        \n",
    "        # Randomized search model\n",
    "        if search_mode == \"random\":\n",
    "            self.clf = RandomizedSearchCV(\n",
    "                estimator = self.base,\n",
    "                param_distributions = param,\n",
    "                n_iter = n_iter,\n",
    "                cv = cv,\n",
    "                verbose = 0,\n",
    "                random_state = config.RANDOM_STATE,\n",
    "                scoring = config.SCORING,\n",
    "                n_jobs = config.N_JOBS)\n",
    "            \n",
    "        # Grid search model\n",
    "        else:\n",
    "            self.clf = GridSearchCV(\n",
    "                estimator=self.base,\n",
    "                param_grid = param, \n",
    "                cv = cv, \n",
    "                verbose = 0, \n",
    "                scoring = config.SCORING,\n",
    "                n_jobs = config.N_JOBS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbca5c6-5f1f-4ead-8ff5-f602f4d17ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scores(object):\n",
    "    \"\"\"\n",
    "    This class stores all scores for all models for all buildings.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialized scores dataframe to store the scores for all the models trained.\n",
    "        self.columns=['model', 'bldg', 'r2_train', 'r2_test', 'rmse_test','mbe_test']\n",
    "        self.scores_df= pd.DataFrame(columns=self.columns)\n",
    "        \n",
    "    def get_MBE(self, y_true, y_pred):\n",
    "        '''\n",
    "        Parameters:\n",
    "            y_true (array): Array of observed values\n",
    "            y_pred (array): Array of prediction values\n",
    "\n",
    "        Returns:\n",
    "            mbe (float): Bias score\n",
    "        '''\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = y_true.reshape(len(y_true),1)\n",
    "        y_pred = y_pred.reshape(len(y_pred),1)   \n",
    "        diff = (y_pred-y_true)\n",
    "        mbe = diff.mean()\n",
    "        return mbe\n",
    "    \n",
    "    def train_test_and_store_score(self, model, model_name, data):\n",
    "        '''\n",
    "        Function to train the model and make prediction using the data object's X_test df.\n",
    "        Return the best model after training if the model input is a search classifier.\n",
    "        '''\n",
    "        print(\"\\nmodel_name:\", model_name)\n",
    "        \n",
    "        # Train and get r2 scores.\n",
    "        model.fit(data.X_train, data.y_train)\n",
    "        if(\"random\" in model_name) or (\"grid\" in model_name):\n",
    "            print(\"best_params=\", model.best_params_)\n",
    "            # reassign using the best model.\n",
    "            model = model.best_estimator_\n",
    "            \n",
    "        r2_train = model.score(data.X_train, data.y_train)\n",
    "        \n",
    "        # Test and get r2, rmse, and mbe scores.\n",
    "        y_pred = model.predict(data.X_test)\n",
    "        r2 = r2_score(data.y_test, y_pred)\n",
    "        rmse = math.sqrt(mean_squared_error(data.y_test, y_pred))\n",
    "        mbe = self.get_MBE(data.y_test, y_pred)\n",
    "        \n",
    "        # Store all the scores.\n",
    "        new_score_data = {\n",
    "            'model': model_name,\n",
    "            'bldg': data.bldg_name,\n",
    "            \"r2_train\":r2_train,\n",
    "            \"r2_test\":r2,\n",
    "            'rmse_test':rmse,\n",
    "            'mbe_test':mbe}\n",
    "        new_score_row = pd.DataFrame.from_records([new_score_data])\n",
    "        self.scores_df = pd.concat([self.scores_df, new_score_row])\n",
    "        \n",
    "        # Return the best model.\n",
    "        return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c839be-7849-4666-85a0-738f01f307cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_bldg_and_model(bldg_data, model_name, model):\n",
    "    '''\n",
    "    Function to plot the scenario prediction of CHWTON/SQM.\n",
    "    '''\n",
    "    # Get the prediction for the baseline data (not scenario).\n",
    "    y_pred = model.predict(bldg_data.X_test)\n",
    "    \n",
    "    # Get the prediction for scenarios for the bldg.\n",
    "    for scen in scens:\n",
    "        scen_data = pd.read_csv(f'{config.SCENARIOS_DIR_PATH}/{scen}/{bldg_data.bldg_name}.csv')\n",
    "        scen_data[config.DATE_TIME] = pd.to_datetime(scen_data[config.DATE_TIME])\n",
    "        scen_data = scen_data[(scen_data[config.DATE_TIME].dt.month == 7) & (scen_data[config.DATE_TIME].dt.day == 7)]\n",
    "        scen_data = scen_data.drop_duplicates(subset=[config.DATE_TIME])\n",
    "        \n",
    "        X_scen = scen_data[bldg_data.X_test.columns]\n",
    "        \n",
    "        # Get the prediction for scenario data.\n",
    "        scen_pred = model.predict(X_scen)\n",
    "        \n",
    "        # Extract Date_Time for the test set\n",
    "        date_time_test = bldg_data.df[(bldg_data.df[config.DATE_TIME].dt.month == 7) & (bldg_data.df[config.DATE_TIME].dt.day == 7)][config.DATE_TIME]\n",
    "\n",
    "        # Create a new DataFrame for plotting\n",
    "        plot_df = pd.DataFrame({\n",
    "            config.DATE_TIME: date_time_test,\n",
    "            'Actual': bldg_data.y_test,\n",
    "            'Predicted': y_pred,\n",
    "            'Scenario' : scen_pred\n",
    "        })\n",
    "\n",
    "        # Calculations\n",
    "        sum_p = sum(plot_df['Predicted'])\n",
    "        sum_s = sum(plot_df['Scenario'])\n",
    "        print(\"\\033[1m\" + scen + \"\\033[0m\")\n",
    "        print('Predicted Total (CHWTON/SQM): ', sum_p)\n",
    "        print('Scenario Total (CHWTON/SQM):  ', sum_s)\n",
    "        percent_diff = ((sum_s - sum_p)/sum_p)*100\n",
    "        print('Percent Difference: ', percent_diff)\n",
    "\n",
    "        # Sort by Date_Time\n",
    "        plot_df.sort_values(by=config.DATE_TIME, inplace=True)\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(plot_df[config.DATE_TIME], plot_df['Actual'], label='Actual')\n",
    "        plt.plot(plot_df[config.DATE_TIME], plot_df['Predicted'], label='Predicted', alpha=0.7)\n",
    "        plt.plot(plot_df[config.DATE_TIME], plot_df['Scenario'], label= scen, alpha = 0.5)\n",
    "        plt.xlabel(config.DATE_TIME)\n",
    "        plt.ylabel(config.CHWTON_SQM)\n",
    "        plt.title(f\"{bldg_data.bldg_name}/{model_name}/{scen} Predicted vs. Scenario Comparison percent_diff={percent_diff}\\n\")\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "        # Save with path: config.RESULT_DIR_PATH + \"/\" {model_name}/{bldg_data.bldg_name}_{scen}.png\n",
    "        # Ensure the directory exists\n",
    "        model_dir = os.path.join(config.RESULT_DIR_PATH, model_name)\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "\n",
    "        # Specify the file path for saving the plot\n",
    "        file_path = os.path.join(model_dir, f\"{bldg_data.bldg_name}_{scen}.png\")\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(file_path)\n",
    "        plt.show()\n",
    "        \n",
    "def load_train_test_score_plot(bldg_name, scores):\n",
    "    # 1. Load Data\n",
    "    df = pd.read_csv(f\"{config.BASE_PATH}/{bldg_name}.csv\")\n",
    "    data = Data(bldg_name, df)\n",
    "    search_mode=\"grid\"\n",
    "    \n",
    "    # 2. Random Forest\n",
    "    rf = Model(config.rf_name, \n",
    "               config.rf_base, \n",
    "               config.rf_param,\n",
    "               config.CV, \n",
    "               config.N_ITER, \n",
    "               search_mode=search_mode)\n",
    "    \n",
    "    # 3. XGB\n",
    "    xgb = Model(\n",
    "        config.xgb_name, \n",
    "        config.xgb_base, \n",
    "        config.xgb_param,\n",
    "        config.CV, \n",
    "        config.N_ITER, \n",
    "        search_mode=search_mode)\n",
    "    \n",
    "    \n",
    "    # 4. LGBM\n",
    "    lgbm = Model(\n",
    "        config.lgbm_name, \n",
    "        config.lgbm_base, \n",
    "        config.lgbm_param,\n",
    "        config.CV, \n",
    "        config.N_ITER, \n",
    "        search_mode=search_mode)\n",
    "    \n",
    "    \n",
    "    # 5. CATBOOST\n",
    "    cb = Model(config.cb_name, \n",
    "               config.cb_base, \n",
    "               config.cb_param, \n",
    "               config.CV, \n",
    "               config.N_ITER,\n",
    "               search_mode=search_mode)\n",
    "    \n",
    "    # models = [rf, xgb, lgbm, cb]\n",
    "    models = [rf]\n",
    "    \n",
    "    for model in models:\n",
    "        # Base model: train, test, score.\n",
    "        scores.train_test_and_store_score(model.base, model.name + \"_base\", data)\n",
    "\n",
    "        # CV classifier: train, test, score, plot.\n",
    "        model.best = scores.train_test_and_store_score(model.clf, model.name + \"_\" + model.search_mode, data)\n",
    "        \n",
    "        # Plot using the best model.\n",
    "        plot_by_bldg_and_model(data, model.name + \"_\" + search_mode, model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9da848-6cf0-45af-930e-530d08cd38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up scenarios and scores df.\n",
    "scens = ['high_albedo_walls', 'cool_pavement', 'trees_surround', 'wall_shade', 'pv_sidewalks', 'pv_rooftop_and_trees', 'trees_extreme', 'pv_rooftop']\n",
    "scores = Scores()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a056969",
   "metadata": {},
   "source": [
    "# Psychology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d49cc7-5059-4144-8da3-e82e5e5468a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model_name: rf_base\n",
      "\n",
      "model_name: rf_grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2q/t3fsvj_55599x9w4b0lkqym00000gn/T/ipykernel_98020/1086953295.py:58: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.scores_df = pd.concat([self.scores_df, new_score_row])\n"
     ]
    }
   ],
   "source": [
    "load_train_test_score_plot(\"Psychology\", scores)\n",
    "scores.scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046910e",
   "metadata": {},
   "source": [
    "# Psychology North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995dc93-3c5a-4e43-b8d2-94e9c9dc5c96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_train_test_score_plot(\"Psychology_North\", scores)\n",
    "scores.scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f92bb",
   "metadata": {},
   "source": [
    "# ISTB 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e1b8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_train_test_score_plot(\"Istb_4\", scores)\n",
    "scores.scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198d875-8dd0-4f4a-aaae-cd56c16d1562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores.scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c3c99-85bc-4102-b9e0-ee1a9d3face5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be9996-0dc1-42f3-8abe-50eea79f198a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4fc0f-2c3d-4188-8f1a-635e088dd97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b2ed8-783e-437f-b4dd-ee4536489cd9",
   "metadata": {},
   "source": [
    "Data: Combined with added features , Shades and Radiation. <br>\n",
    "Split: Train, Validate, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6dbd75",
   "metadata": {},
   "source": [
    "# 1. Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6345f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# parameters search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "# To: install catboost\n",
    "# !pip3 install catboost\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98beeaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Bldg = pd.read_csv(\"../Data/microclimate_model/Combined/all_buildings.csv\")\n",
    "Bldg = Bldg.drop(columns = ['Unnamed: 0', \"Date_Time\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4b6b1",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690c813",
   "metadata": {},
   "source": [
    "## 2.1 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bac77-99fd-42b8-bd10-0cd22ebe1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of building names so we can extract the name easily \n",
    "BldgName = list(Bldg.bldgname.unique())\n",
    "\n",
    "# Create list of building df to do time series plot\n",
    "BldgList = []\n",
    "\n",
    "for i in range(len(BldgName)):\n",
    "    bldg_single = Bldg[Bldg['bldgname'] == BldgName[i]]\n",
    "    BldgList.append(bldg_single)\n",
    "    \n",
    "for bldg in BldgList:\n",
    "    bldg = bldg.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2122d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create CHWTON boxplots for all buildings #\n",
    "def createBoxPlot(df, columnName, BldgName):\n",
    "    row_size = 6\n",
    "    column_size = 2\n",
    "    fig, ax = plt.subplots(row_size, column_size, figsize = (15,40))\n",
    "\n",
    "    i = 0\n",
    "    # 1. loop through the 11 buildings\n",
    "    while i < (len(BldgName)):\n",
    "        # 2. Create row (6)\n",
    "        for row in range(row_size):\n",
    "            #4. Create column 2\n",
    "            for col in range(column_size):\n",
    "                if i < (len(BldgName)):\n",
    "                    \n",
    "                    # create boxplot of this df\n",
    "                    df[i].boxplot(by='Hour',\n",
    "                                    column=[columnName],\n",
    "                                    grid = False,\n",
    "                                    figsize = (5,5),\n",
    "                                    ax = ax[row,col] )\n",
    "                    ax[row,col].title.set_text(BldgName[i])\n",
    "                    i += 1\n",
    "\n",
    "    fig.suptitle(columnName + ' Boxplot by Hour')\n",
    "    plt.show()\n",
    "    \n",
    "createBoxPlot(BldgList, 'CHWTON', BldgName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa283b62-6282-42d1-9f85-431f1c22dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "createBoxPlot(BldgList, 'Air Temp', BldgName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fd129",
   "metadata": {},
   "source": [
    "## 2.2 Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62d7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Print CHWTON/SQFT for all buildings and all timestamps in data\n",
    "ax = BldgList[0]['CHWTON/SQFT'].plot(figsize = (15,9))\n",
    "legendlabels = []\n",
    "\n",
    "for i in range(len(BldgList)-1):\n",
    "    BldgList[i+1]['CHWTON/SQFT'].plot(ax=ax)\n",
    "    legendlabels.append(BldgList[i].bldgname[0])\n",
    "    \n",
    "ax.legend(labels = legendlabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4d0e0-ec18-49fc-8026-69efa88fb02e",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895b107-8cba-4a85-9db5-b8f67ca4f2c2",
   "metadata": {},
   "source": [
    "## 3.1 Remove unused column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729cb8e-cb3c-4101-9b16-ffc7a23cdb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9e290f-3ed7-45a6-9651-f839e37ce60d",
   "metadata": {},
   "source": [
    "## 3.2 One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72278137-6595-4858-81fd-5bff57b3105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer Encode\n",
    "Bldg = pd.get_dummies(Bldg, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f88ad-19e4-4daf-a42b-0211853768c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corrMatrix = Bldg.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corrMatrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cea02a-1d27-481d-81df-3fb87ce38754",
   "metadata": {},
   "source": [
    "## 3.3 Cyclic Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d202e9-1384-4410-a5f1-c83e27216e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Bldg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bfe83a7342b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mBldg_cyclic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mBldg_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBldg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mBldg_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBldg_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Minute'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mBldg_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBldg_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Bldg' is not defined"
     ]
    }
   ],
   "source": [
    "# function to encode df columns into sine and cosine\n",
    "def encode(df, col, max_val):\n",
    "    df[col.replace('_num', '') + '_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
    "    df[col.replace('_num', '') + '_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
    "    df.drop(columns = [col], inplace = True)\n",
    "    return df\n",
    "\n",
    "# create a list of df for buildings with cyclical time features\n",
    "Bldg_cyclic = []\n",
    "\n",
    "Bldg_enc = Bldg.copy(deep = True)\n",
    "Bldg_enc = encode(Bldg_enc, 'Minute', 60.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Hour', 23.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Day', 30.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Month', 12.0)\n",
    "Bldg_cyclic = Bldg_enc\n",
    "    \n",
    "# Plot cyclical features sample\n",
    "# fig, ax = plt.subplots(2,2, figsize = (8,7))\n",
    "# Bldg_cyclic.plot.scatter('Minute_sin', 'Minute_cos', ax = ax[0,0]).set_aspect('equal')\n",
    "# Bldg_cyclic.plot.scatter('Hour_sin', 'Hour_cos', ax = ax[0,1]).set_aspect('equal')\n",
    "# Bldg_cyclic.plot.scatter('Day_sin', 'Day_cos', ax = ax[1,0]).set_aspect('equal')\n",
    "# Bldg_cyclic.plot.scatter('Month_sin', 'Month_cos', ax = ax[1,1]).set_aspect('equal')\n",
    "Bldg_cyclic.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc094a-85cc-43b0-b416-71ba072e70ea",
   "metadata": {},
   "source": [
    "# 4. Modelling set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578b327-cdc8-42ad-98ec-8109d6b6f036",
   "metadata": {},
   "source": [
    "## 4.1 Pick desired date for Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323ca82-af8b-416d-a1a4-bfd9f6437038",
   "metadata": {},
   "source": [
    "Month available:<br>\n",
    "May: 16, 23 <br>\n",
    "June: 7, 8, 20, 21, 25, 26<br>\n",
    "August: 3, 27<br>\n",
    "September: 11, 29<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb509f-7401-452b-a690-5d74d912fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get user to pick the day\n",
    "day = (input(\"Pick month and day <mm dd>: \"))\n",
    "x,y = day.split(\" \")\n",
    "x = int(x)\n",
    "y = int(y)\n",
    "\n",
    "# 2. If date is unavailable ask to pick again\n",
    "while (len(Bldg[(Bldg['Month'] == x) & (Bldg['Day'] == y)]) == 0):\n",
    "    day = (input(\"Date unavailable, pick month and day <mm dd>: \"))\n",
    "    x,y = day.split(\" \")\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "\n",
    "print(\"You picked month: \", x, \", day: \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb72a9-d8fc-44ec-a608-3689d9017a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df = Bldg[(Bldg['Month'] == x) & (Bldg['Day'] == y)]\n",
    "Test_df.reset_index(drop = True, inplace = True)\n",
    "Test_df\n",
    "\n",
    "# Remove Test From Bldg df \n",
    "Bldg = Bldg[~((Bldg['Month'] == x) & (Bldg['Day'] == y))]\n",
    "\n",
    "# Check if the day is still there\n",
    "Bldg.Day.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a2120-dceb-4fc8-a504-5fb7d75ad780",
   "metadata": {},
   "source": [
    "## 4.2 Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecd35c-dbd6-43a4-9d18-8661bb1ec8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame()\n",
    "# function to train a model and get its scores\n",
    "def trainAndGetScore(pModel, pModelName, pTuningType, pDf_all_bldg, pDf_scores, pTest_df):\n",
    "    # 1. drop na values if in dataframe\n",
    "    if (pDf_all_bldg.isnull().values.any() == True):\n",
    "        pDf_all_bldg = pDf_all_bldg.dropna()\n",
    "            \n",
    "    # 2. split data into X and y\n",
    "    X = pDf_all_bldg.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "    y = pDf_all_bldg['CHWTON/SQFT']  \n",
    "    \n",
    "    X_test = pTest_df.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "    y_test = pTest_df['CHWTON/SQFT']  \n",
    "    \n",
    "    # 3. Train-Test Split\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n",
    "    # 4. fit model that already has parameters\n",
    "    pModel.fit(X_train, y_train)\n",
    "        \n",
    "    # 5. Get prediction\n",
    "    y_pred = pModel.predict(X_validate)\n",
    "    ModelPred = pd.DataFrame({'Actual CHWTON/SQFT':y_validate, 'Predicted CHWTON/SQFT':y_pred})\n",
    "    ModelPred = ModelPred.sort_index()\n",
    "    print(ModelPred)\n",
    "    \n",
    "    # 6. Get best params if it's a random or grid search\n",
    "    if(\"random\" in pTuningType) or (\"grid\" in pTuningType):\n",
    "        print(pModel.best_estimator_.get_params())\n",
    "        \n",
    "    # 7. Get score\n",
    "    scoreTrain = pModel.score(X_train, y_train)\n",
    "    scoreValidate = pModel.score(X_validate, y_validate)\n",
    "    scoreTest = pModel.score(X_test, y_test)\n",
    "    \n",
    "    # 8. Save Score\n",
    "    # 8.1 Get index\n",
    "    # if the model name we have is already in previous df's row , use that index\n",
    "    if (len(pDf_scores) == 0):\n",
    "        print(\" zero length\")\n",
    "        i = 0\n",
    "    else:\n",
    "        # if the model name we have is already in previous df's row , use that index\n",
    "        last_index = len(pDf_scores) - 1\n",
    "        if (pDf_scores.loc[last_index,'modelName'] == pModelName):\n",
    "            i = last_index\n",
    "        else:\n",
    "        # new model name add to new row\n",
    "            i = len(pDf_scores)\n",
    "            \n",
    "    # 8.2 add scores to df\n",
    "    pDf_scores.loc[i,'modelName'] = pModelName\n",
    "    pDf_scores.loc[i,pTuningType + \"Train\"] = scoreTrain\n",
    "    pDf_scores.loc[i,pTuningType + \"Validate\"] = scoreValidate\n",
    "    pDf_scores.loc[i,pTuningType + \"Test\"] = scoreTest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae049e-fb3b-4128-8154-6704c29bbba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4c33c",
   "metadata": {},
   "source": [
    "# 5. Model 1: Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eda26-53b7-47e4-89a3-a5b4c99f1437",
   "metadata": {},
   "source": [
    "## 5.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ee8c3-9d00-4fc4-8421-67d5ebbf4b53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RF_base = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 1. Base RF on base data\n",
    "trainAndGetScore(RF_base, \"RF\", \"base\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 2. Base RF on cyclical time features\n",
    "# trainAndGetScore(RF_base, \"RF_cyclic\", \"base\", Bldg_cyclic, scores_df, Test_cyclic_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3dae8-f025-4c0b-848f-c2c4c1e25af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d73d4-6ebb-4047-870b-d7c749d13f89",
   "metadata": {},
   "source": [
    "## 5.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b3012-d20c-4e29-bcff-5ce18752423f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters for RF\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "\n",
    "# 2. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 3. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 4. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 1, 2, 4]\n",
    "\n",
    "# 5. Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# 6. Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ca3e5-9232-4954-ad93-7209b0541d87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_random = RandomizedSearchCV(estimator = RF_base,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_random, \"RF\", \"random\", Bldg, scores_df, Test_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "# trainAndGetScore(RF_random, \"RF_cyclic\", \"random\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449aedf7-0456-4149-8a37-ed97ce22784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF_random.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a367a80-a14d-4793-8c57-0338b49edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33671b52-7533-4752-8dc6-14c39821ba97",
   "metadata": {},
   "source": [
    "## 5.3. Grid Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c444f9-a995-411b-b82a-5e0e8dc223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [200, 220, 230,240],\n",
    "               'max_features': [\"sqrt\"],\n",
    "               'max_depth': [17, 20, 22],\n",
    "               'min_samples_split': [2,3,4],\n",
    "               'min_samples_leaf': [ 1, 2],\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af34a8-bcc0-47a0-a2a9-957306fe144d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set parameters on random_RF\n",
    "RF_grid = GridSearchCV(estimator = RF_base,\n",
    "                       param_grid = param_grid,\n",
    "                       cv = 5,\n",
    "                       scoring ='r2',\n",
    "                       n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(RF_grid, \"RF\", \"grid\", Bldg_df, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "# trainAndGetScore(RF_grid, \"RF_grid_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba86d-d905-4050-af9e-720be9883b29",
   "metadata": {},
   "source": [
    "# 6. Model 2: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f7a20-eeff-4122-b0f2-7e4519aaf62f",
   "metadata": {},
   "source": [
    "## 6.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194165bb-5300-4014-9480-c31492e3d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create base model\n",
    "XGB_base = XGBRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 2. Base XGB on base data\n",
    "trainAndGetScore(XGB_base, \"XGB_base\", Bldg, scores_df)\n",
    "\n",
    "# 3. Base XGB on cyclica time features\n",
    "trainAndGetScore(XGB_base, \"XGB_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c0700-ac88-4cb9-b276-b9013c1284df",
   "metadata": {},
   "source": [
    "## 6.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a779b-76b3-44ec-9fb3-77b4d3d54c4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "params = {\n",
    "    'n_estimators':[ 100, 250, 500, 1000],\n",
    "    'min_child_weight':[4,5,8], \n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "n_iter_search = 20\n",
    "XGB_random = RandomizedSearchCV(XGB_base,\n",
    "                                param_distributions = params,\n",
    "                                n_iter = n_iter_search,\n",
    "                                cv = 5,\n",
    "                                verbose = 2,\n",
    "                                random_state = 42,\n",
    "                                scoring ='r2',\n",
    "                                n_jobs = -1)\n",
    "\n",
    "# 2. Train on base data\n",
    "trainAndGetScore(XGB_random, \"XGB_random\", Bldg, scores_df)\n",
    "\n",
    "# 3. Train on data with cyclical time features\n",
    "trainAndGetScore(XGB_random, \"XGB_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd4792-01f9-4d5e-9330-43b228a5b313",
   "metadata": {},
   "source": [
    "# 7. Model 3: LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482554db-64fa-4f25-9a5e-479b5cf525be",
   "metadata": {},
   "source": [
    "## 7.1 No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b9a1-6a53-499e-8f10-88f57beb99cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "LGBM_base = lgb.LGBMRegressor(random_state = 42)\n",
    "\n",
    "# 2. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_base, \"LGBM_base\", Bldg, scores_df)\n",
    "\n",
    "# 3. Base LGBM on cyclica time features\n",
    "trainAndGetScore(LGBM_base, \"LGBM_cylic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3765ed-d58d-4341-adfe-dbf4727f33cb",
   "metadata": {},
   "source": [
    "## 7.2 Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0e798-0697-49bc-8524-50513240672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define grid\n",
    "random_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'learning_rate': [0.1, 0.03, 0.003],\n",
    "    'max_depth': [-1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "# 2. Set up model with grid\n",
    "LGBM_random = RandomizedSearchCV(estimator = LGBM_base,\n",
    "                                 param_distributions = random_grid, \n",
    "                                 n_iter = 100, cv = 2,\n",
    "                                 scoring='r2',\n",
    "                                 verbose= 2,\n",
    "                                 random_state= 42,\n",
    "                                 n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e469572-f06f-478b-8017-b3ba68af1708",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Base LGBM on base data\n",
    "trainAndGetScore(LGBM_random, \"LGBM_random\", Bldg, scores_df)\n",
    "\n",
    "# 4. Base LGBM on cyclica time features\n",
    "trainAndGetScore(LGBM_random, \"LGBM_random_cyclic\", Bldg_cyclic, scores_df)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44931bcb-05ad-4338-8170-a084813c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ONE HOT ENCODING SCORE:\")\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d96e91-cbab-40f8-8dd9-56fec3293225",
   "metadata": {},
   "source": [
    "# 8. Model 4: Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fecc75-a865-45ec-8819-31aee54b9e2c",
   "metadata": {},
   "source": [
    "## 8.1 Prepare datas using label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20778bad-021e-4293-9b56-4e491308fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df_cat = pd.DataFrame()\n",
    "for i in range(len(Bldg)):\n",
    "    Bldg_df_cat = Bldg_df_cat.append(Bldg[i])\n",
    "    \n",
    "Bldg_df_cat.reset_index(drop = True , inplace = True)\n",
    "Bldg_df_cat.drop(columns=['Date', 'Time', 'Date_Time'],inplace = True)\n",
    "# create a list of df for buildings with cyclical time features\n",
    "Bldg_cyclic_cat = []\n",
    "\n",
    "Bldg_enc = Bldg_df_cat.copy(deep = True)\n",
    "Bldg_enc = encode(Bldg_enc, 'Minute_num', 60.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Hour_num', 23.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Day_num', 30.0)\n",
    "Bldg_enc = encode(Bldg_enc, 'Month_num', 12.0)\n",
    "Bldg_cyclic_cat = Bldg_enc\n",
    "    \n",
    "# Plot cyclical features sample\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,7))\n",
    "Bldg_cyclic_cat.plot.scatter('Minute_sin', 'Minute_cos', ax = ax[0,0]).set_aspect('equal')\n",
    "Bldg_cyclic_cat.plot.scatter('Hour_sin', 'Hour_cos', ax = ax[0,1]).set_aspect('equal')\n",
    "Bldg_cyclic_cat.plot.scatter('Day_sin', 'Day_cos', ax = ax[1,0]).set_aspect('equal')\n",
    "Bldg_cyclic_cat.plot.scatter('Month_sin', 'Month_cos', ax = ax[1,1]).set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c02b73-1e67-4f58-937e-c49546effa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_cyclic_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa8721-b0ff-4615-8167-ab74927d1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "Bldg_df_cat['bldgname'] = label_encoder.fit_transform(Bldg_df_cat['bldgname'])\n",
    "Bldg_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc9057f-6c1c-4cf6-943d-faa5db36072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bldg_df_cat.bldgname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7699ef3-2967-42ed-b973-68657f48b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split data into X and y\n",
    "X = Bldg_df_cat.drop(columns=['CHWTON', 'CHWTON/SQFT'])\n",
    "y = Bldg_df_cat['CHWTON/SQFT']   \n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d679f18-daf9-415d-aae1-6ea41cda0e1a",
   "metadata": {},
   "source": [
    "## 8.2 Catboost Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc5589-94b8-4429-96b2-f390df338a56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. hyperparameter grid\n",
    "cb_grid = {'iterations': [50, 100, 150, 200, 250],\n",
    "            'learning_rate': [0.03, 0.1],\n",
    "            'depth': [2, 4, 8, 10, 12],\n",
    "            'l2_leaf_reg': [0.2, 0.5, 1, 3, 5, 7]}\n",
    "\n",
    "# 2. instantiate RandomSearchCv object\n",
    "CB_random_obj = RandomizedSearchCV(estimator = catboost,\n",
    "                               param_distributions = cb_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "\n",
    "# 3. Fit the model\n",
    "CB_random_obj.fit(X_train,y_train)\n",
    "\n",
    "# 4. print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(CB_random_obj.best_estimator_.get_params())\n",
    "pprint(CB_random_obj.best_score_)\n",
    "\n",
    "# 5. get the best model\n",
    "CB_random = CB_random_obj.best_estimator_\n",
    "\n",
    "# 6. get score \n",
    "score = CB_random.score(X_test, y_test)\n",
    "scores_df['CB_random']=score\n",
    "print(score)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5afb4-f368-4d8a-a757-409481fb572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a696e-920c-4f96-87b0-e3cb345d02d7",
   "metadata": {},
   "source": [
    "## 8.3 Catboost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3bcfd-1787-467f-b71a-594bc2e4a25c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. initialize model and grid\n",
    "catboost = cb.CatBoostRegressor(loss_function='RMSE')\n",
    "grid = {'depth': [8, 10,12],\n",
    "        'iterations': [230,250,270],\n",
    "        'learning_rate': [0.08, 0.1, 0.15],\n",
    "        'l2_leaf_reg': [0.8, 1, 2]}\n",
    "\n",
    "\n",
    "# 4. search parameter\n",
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)\n",
    "result = catboost.grid_search(grid,\n",
    "                           train_dataset,\n",
    "                           cv = 5,\n",
    "                           search_by_train_test_split=True,\n",
    "                           shuffle = True,\n",
    "                           refit = True,\n",
    "                           verbose = True,\n",
    "                           train_size = 0.8 )\n",
    "\n",
    "\n",
    "# 4. get best params\n",
    "best_params = result['params']\n",
    "\n",
    "# 5. fit model with best params\n",
    "CB_grid = cb.CatBoostRegressor(depth = best_params['depth'],\n",
    "                               iterations = best_params['iterations'],\n",
    "                               learning_rate= best_params['learning_rate'],\n",
    "                               l2_leaf_reg = best_params['l2_leaf_reg'])\n",
    "CB_grid.fit(train_dataset)\n",
    "\n",
    "# 6. get score \n",
    "score = CB_grid.score(X_test, y_test)\n",
    "scores_df['CB_grid']=score\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4e309-f5c3-4893-ba68-f392f3b65119",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1d4f9-6272-4d82-80e1-f8351958a029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

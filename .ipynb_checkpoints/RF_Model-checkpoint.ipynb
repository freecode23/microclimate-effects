{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f6a95c-cd5a-4267-a601-ad667c78e46e",
   "metadata": {},
   "source": [
    "Build a baseline model using the weather station data (this approach used all days in 2018 since the data was available).\n",
    "\n",
    "\n",
    "Then use the model to make predictions for the ENVI-met(micro-climate) data for that specific day and compare it to model predictions using weather station data also for the same day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e1207-9300-4a88-8a5c-018f487b78bf",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5def07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "\n",
    "#  for multicolinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "#  for outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import PyQt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8de9e-804f-4b18-9045-f1c3f386126f",
   "metadata": {},
   "source": [
    "# 2. Import Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1cc7b-a97c-4f1a-bc03-a3a5f508eb33",
   "metadata": {},
   "source": [
    "## 2.1 Save csv files as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116d399-5c7a-47f3-8c0f-c0dc69e3e18d",
   "metadata": {},
   "source": [
    "Only run this once to save our csv data as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954bfc0-fd9e-48cf-8bee-b070ad6b8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> NO NEED TO RUN SAVED AS PICKLE FILES <--\n",
    "# WEATHER FILES ##\n",
    "\n",
    "# # 1. AZ PHX Sky Harbor Data #\n",
    "# AZW_15 = pd.read_csv(\"./Data/Weather Data/KPHX-15.csv\")\n",
    "\n",
    "# # 2. ENVIMET DATA #\n",
    "# BPS = []\n",
    "# Fname = []\n",
    "# for path in pathlib.Path(\"./Data/BPS\").iterdir():\n",
    "#     if path.is_file():\n",
    "#         current_file = pd.read_csv(path)\n",
    "#         BPS.append(current_file)\n",
    "#         Fname.append(path.name.replace('.csv', ''))\n",
    "\n",
    "# # Drop last row of EnviMet Data\n",
    "# for i in range(len(BPS)):\n",
    "#     BPS[i] = BPS[i].drop(16)\n",
    "\n",
    "# # 3. CAMPUS METABOLISM DATA #\n",
    "# metabol14 = []\n",
    "# for path in pathlib.Path('./Data/ASU 2018').iterdir():\n",
    "#     if path.is_file():\n",
    "#         current_file = pd.read_csv(path)\n",
    "#         metabol14.append(current_file)\n",
    "\n",
    "\n",
    "# # 5. Save files as pickle\n",
    "# AZW_15.to_pickle(\"./Data/AZW_15.pkl\")\n",
    "\n",
    "# with open('./Data/BPS.pkl', 'wb') as f:\n",
    "#     pickle.dump(BPS, f)\n",
    "\n",
    "# with open('./Data/Fname.pkl', 'wb') as f:\n",
    "#     pickle.dump(Fname, f)\n",
    "\n",
    "# with open('./Data/metabol14.pkl', 'wb') as f:\n",
    "#     pickle.dump(metabol14, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a4864-e1d6-49c8-9a69-72d440091748",
   "metadata": {},
   "source": [
    "## 2.2 Reload Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8004c9-b0fc-4451-bd33-c3c54739a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will convert these to df depending on the building we choose\n",
    "# 1. Load 14 envimet bldgData (14 filtered buildings)\n",
    "with open('./Data/BPS.pkl', 'rb') as f:\n",
    "    envi14 = pickle.load(f)\n",
    "\n",
    "# 2. Load names of Envimet files\n",
    "with open('./Data/Fname.pkl', 'rb') as f:\n",
    "    Fname = pickle.load(f)\n",
    "\n",
    "# 3. Load 14 campus metabolism building energy data\n",
    "with open('./Data/metabol14.pkl', 'rb') as f:\n",
    "    metabol14 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff27af-83bb-4831-8ee1-d76d132e7f13",
   "metadata": {},
   "source": [
    "## 2.3 Choose files to import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1fe6ab-00f4-4953-81fa-38fdca55b5d8",
   "metadata": {},
   "source": [
    "### 2.3.1 Building name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51c48fa-6e04-463c-b72e-3365e3b6773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Services\n",
      "Interdisciplinary AB\n",
      "Bio Design Institute A\n",
      "Lifescience A_B_D\n",
      "Bio Design Institute B\n",
      "COD North\n",
      "Goldwater\n",
      "University Club\n",
      "Engineering Research Ctr\n",
      "Best Hall\n",
      "ISTB 1\n",
      "ISTB 2\n",
      "ISTB 4\n",
      "ISTB 5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter building name:  Lifescience A_B_D\n"
     ]
    }
   ],
   "source": [
    "##Print Building Names ##\n",
    "for i in range(len(Fname)):\n",
    "    print(Fname[i])\n",
    "    \n",
    "bldname = input('Enter building name: ')\n",
    "\n",
    "for i in range(len(envi14)):\n",
    "    if bldname == Fname[i]:\n",
    "        # save \n",
    "        envi_bldg = envi14[i]\n",
    "\n",
    "if bldname not in Fname:\n",
    "    print(\"\\x1b[31m\\\"Please enter a valid name from the list above\\\"\\x1b[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941ea31-0168-4be3-9392-84f5264f85c6",
   "metadata": {},
   "source": [
    "### 2.3.2 Choose baseline data (and year):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e861ed-b360-4aa6-a51b-e804c85040ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 'asu' or 'station':  station\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train using station data\n"
     ]
    }
   ],
   "source": [
    "base_name = input('Enter \\'asu\\' or \\'station\\': ')\n",
    "print('We will train using' , base_name, 'data')\n",
    "\n",
    "if(base_name == 'asu'):\n",
    "    year_picked = input('Enter year between 2017 - 2020 inclusive: ')\n",
    "    print('You picked year: ', year_picked )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ffdc5-57f3-43e4-a5e5-97fe862a79a9",
   "metadata": {},
   "source": [
    "## 2.4 Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f13e172-2ae4-455b-aebe-f8eb064195b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifescience A_B_D\n"
     ]
    }
   ],
   "source": [
    "# 1. DF for Envimet\n",
    "class building:\n",
    "    \n",
    "    def __init__(self, bldname):\n",
    "        self.bldgname = bldname\n",
    "    \n",
    "    def campusmetabolism(self):\n",
    "        for i in range(len(metabol14)):\n",
    "            if metabol14[i]['bldgname'][0] == bldname:\n",
    "                cmp = metabol14[i]\n",
    "            elif (metabol14[i]['bldgname'][0] == 'ISTB-5'):\n",
    "                cmp = metabol14[i]\n",
    "        return cmp\n",
    "    \n",
    "    def envimet(self):\n",
    "        env = envi_bldg[['Date', 'Time', 'AirTempInFrontOfAllFacades_MEAN', 'RelativeAirHumidityInFrontOfAllFacades_MEAN',\n",
    "                     'WindSpeedInFrontOfAllFacades_MEAN']]\n",
    "        \n",
    "        env = env.rename(columns = {'AirTempInFrontOfAllFacades_MEAN':'Air Temp',\n",
    "                                    'RelativeAirHumidityInFrontOfAllFacades_MEAN':'Rel Humid',\n",
    "                                    'WindSpeedInFrontOfAllFacades_MEAN':'Wind Speed'})\n",
    "        return env\n",
    "\n",
    "\n",
    "\n",
    "Bldg = building(bldname)\n",
    "metabol = Bldg.campusmetabolism() # campus metabolism\n",
    "envimet = Bldg.envimet()          # envimet\n",
    "print(bldname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d7dd0c-aff7-4747-b818-db72663ee9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        56.93\n",
       "1        65.03\n",
       "2        47.84\n",
       "3        53.82\n",
       "4        51.24\n",
       "         ...  \n",
       "35028    36.37\n",
       "35029    33.81\n",
       "35030    37.18\n",
       "35031    48.24\n",
       "35032    36.64\n",
       "Name: CHWTON, Length: 35033, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metabol['CHWTON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfddc21-eea4-4882-82fc-468f3470a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DF for weather\n",
    "if(base_name == 'asu'):\n",
    "    path_name = \"./Data/ASU_Weather/x-weather(\" + year_picked + \").csv\"\n",
    "    baseline_df = pd.read_csv(path_name)\n",
    "    \n",
    "    # get year\n",
    "    baseline_df[\"Date and Time\"] = pd.to_datetime(baseline_df[\"Date and Time\"])\n",
    "    baseline_df[\"year\"] = baseline_df[\"Date and Time\"].dt.year\n",
    "\n",
    "    # remove wrong year\n",
    "    baseline_df = baseline_df[baseline_df[\"year\"] == int(year_picked)]\n",
    "    \n",
    "    # remove year and unnamed column\n",
    "    baseline_df = baseline_df.iloc[: , :-2]\n",
    "    \n",
    "    # rename column\n",
    "    new_column = ['Date_Time', 'Dew', 'Air Temp', 'Rel Humid', 'Solar Rad', 'Wind']\n",
    "    baseline_df.set_axis(new_column, axis =1, inplace = True)\n",
    "\n",
    "    # choose column\n",
    "    baseline_df = baseline_df[['Date_Time','Air Temp', 'Rel Humid']]    \n",
    "\n",
    "    # convert date time to string\n",
    "    baseline_df['Date_Time'] = baseline_df['Date_Time'].dt.strftime('%m/%d/%Y %H:%M')\n",
    "    \n",
    "    # Convert temp. from F to C\n",
    "    baseline_df = baseline_df.assign(Air = lambda x: (5/9) * (x['Air Temp'] - 32))\n",
    "    baseline_df['Air Temp'] = baseline_df['Air']\n",
    "    baseline_df.drop(columns = ['Air'], inplace = True)\n",
    "else:\n",
    "    # 3. DF for weather station (15-min)\n",
    "    baseline_df = pd.read_pickle('./Data/AZW_15.pkl')   \n",
    "\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b284403b-4b4b-4cf8-919d-6b0b4a90be8b",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5060df-c598-4830-9411-f2a61f1cd6e7",
   "metadata": {},
   "source": [
    "## 3.1 Formatting Date and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e6d10-528d-4c9e-9af7-ad9a0871ce64",
   "metadata": {},
   "source": [
    "### a) Envimet dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ad52e-095f-45bf-b17b-4b1e68bcd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. format time\n",
    "envimet['Time'] = envimet['Time'].str.replace('.',':')\n",
    "envimet['Time'] = envimet['Time'].str.replace('01','00')\n",
    "\n",
    "# convert to 24 hour format\n",
    "envimet['Time'] = pd.to_datetime(envimet['Time']).dt.strftime('%H:%M')\n",
    "\n",
    "# 2. format date (still in string)\n",
    "envimet['Date'] = pd.to_datetime(envimet['Date']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# 3. combine date time column as string and set as index\n",
    "envimet['Date_Time'] = envimet['Date'] + ' ' + envimet['Time']\n",
    "\n",
    "# 4. Get string type for month and time\n",
    "envimet['Month'] = envimet['Date_Time'].str[0:2]\n",
    "envimet['Time'] = envimet['Time'].str.replace(':','')\n",
    "\n",
    "# 5. Rearrange columns\n",
    "print(list(envimet.columns))\n",
    "envimet = envimet[['Date_Time','Month','Time', 'Air Temp', 'Rel Humid' ]]\n",
    "\n",
    "envimet = envimet.set_index('Date_Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5f714-f56b-417b-92ec-f4a915675eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Get numeric for month hour and minute\n",
    "# microclimate.Date_Time = pd.to_datetime(microclimate.Date_Time)\n",
    "# microclimate['Month_num'] = microclimate.Date_Time.dt.month\n",
    "# microclimate['Hour_num'] = microclimate.Date_Time.dt.hour\n",
    "# microclimate['Minute_num'] = microclimate.Date_Time.dt.minute\n",
    "# microclimate.Date_Time = pd.to_datetime(microclimate.Date_Time).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# # 6. Rearrange columns\n",
    "# print(list(microclimate.columns))\n",
    "# microclimate = microclimate[['Date_Time','Month','Time','Month_num', 'Hour_num', 'Minute_num', 'Air Temp', 'Rel Humid' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33881579-f925-4b92-8822-7209d85d92a8",
   "metadata": {},
   "source": [
    "### b) Baseline weather dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a46d7b-0964-4a40-b050-bb1573b272d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get string type for month and time\n",
    "baseline_df['Month'] = baseline_df['Date_Time'].str[0:2]\n",
    "baseline_df['Time'] = baseline_df['Date_Time'].str[11:]\n",
    "baseline_df['Time'] = baseline_df['Time'].str.replace(':','')\n",
    "\n",
    "# 2. Get numeric for month hour and minute\n",
    "baseline_df.Date_Time = pd.to_datetime(baseline_df.Date_Time) # convert to datetime object\n",
    "baseline_df['Month_num'] = baseline_df.Date_Time.dt.month \n",
    "baseline_df['Hour_num'] = baseline_df.Date_Time.dt.hour\n",
    "baseline_df['Minute_num'] = baseline_df.Date_Time.dt.minute\n",
    "baseline_df.Date_Time = pd.to_datetime(baseline_df.Date_Time).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# 3. set date time as index\n",
    "baseline_df = baseline_df.set_index('Date_Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59d7e7-c179-4b0e-b21e-f9251baabb7f",
   "metadata": {},
   "source": [
    "### d) Building energy dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1844c88-eaa2-4559-8aa7-3ea657c21f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabol.tstamp = pd.to_datetime(metabol.tstamp).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# remove unwanted columns\n",
    "metabol = metabol[['tstamp','KW', 'CHWTON']]\n",
    "\n",
    "# set date time as index\n",
    "metabol = metabol.set_index('tstamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa15a6-0d08-4376-8178-1fe4861253a9",
   "metadata": {},
   "source": [
    "## 3.2 Append Energy Consumption to baseline weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcf70a-15e1-4927-8e60-3ad37c51e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df =  pd.concat([metabol, baseline_df], axis = 1, join = \"inner\")\n",
    "\n",
    "# rearrange column\n",
    "baseline_df = baseline_df[['Month','Time','Month_num', 'Hour_num', 'Minute_num', 'Air Temp', 'Rel Humid', 'KW','CHWTON' ]]\n",
    "\n",
    "# save data with string and numeric date format\n",
    "baseline_df.to_csv('./Data/' + base_name +'.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50e43d-0b7b-455d-9e67-6d789a89b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1385a4a-bbf8-4ef0-9463-4ed2e7ab3e0b",
   "metadata": {},
   "source": [
    "# 4. Create June 9th Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa30942-496f-432d-9ac9-0577ac767f0d",
   "metadata": {},
   "source": [
    "For both microclimate and weather_station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea1607-36cf-49c4-9b6b-6d6c74bc4f96",
   "metadata": {},
   "source": [
    "## 4.1 For Microclimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68eda78-49d3-43b2-a168-3cf574ea3d5c",
   "metadata": {},
   "source": [
    "We want: month, hour, minute, CHWTON, KW, date, air temp, and real humidity for microclimate June 9th.\n",
    "We do this by merging with building_energy to get KW and CHWTON on the dates that appear in microclimate data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd1aa1-970d-4135-b009-61c014b4e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "envimet_j9 = pd.merge(envimet, metabol, left_index = True, right_index = True)\n",
    "envimet_j9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d8266-241c-4bbb-b5c3-139a441eb80c",
   "metadata": {},
   "source": [
    "## 4.2 For Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc0379-f708-41ee-a459-ad531b96cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert to datetime so we can remove June 9th weather\n",
    "baseline_df.index = pd.to_datetime(baseline_df.index)\n",
    "\n",
    "# 2. Extract all of june 9th data \n",
    "baseline_j9 = baseline_df[(baseline_df.index.month == 6) & (baseline_df.index.day == 9)]\n",
    "\n",
    "# 3. drop all of June 9th from baseline_df data\n",
    "baseline_df = baseline_df.drop(baseline_j9.index)\n",
    "\n",
    "# 4. Filter time ( only minute 00) from june 9th data\n",
    "baseline_j9 = baseline_j9[ (baseline_j9['Hour_num'] >= 5) & (baseline_j9['Hour_num'] <= 20) & (baseline_j9['Minute_num'] == 0)]\n",
    "\n",
    "# 5. drop numeric variables\n",
    "baseline_df = baseline_df.drop(labels = ['Hour_num', 'Month_num','Minute_num'], axis = 1)\n",
    "baseline_j9 = baseline_j9.drop(labels = ['Hour_num', 'Month_num','Minute_num'], axis = 1)\n",
    "\n",
    "# 6. ensure theres no more june 9th data between 5am to 8pm on baseline_df data\n",
    "print(baseline_df[(baseline_df.index.month == 6) & (baseline_df.index.day == 9)])\n",
    "\n",
    "# 7. convert index back to string types\n",
    "baseline_df.index = pd.to_datetime(baseline_df.index).strftime('%m/%d/%Y %H:%M')\n",
    "baseline_j9.index = pd.to_datetime(baseline_j9.index).strftime('%m/%d/%Y %H:%M')\n",
    "baseline_j9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6bfc3-5446-4faf-b314-d2e5ee8ad8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save June 9th data as CSV as csv\n",
    "envimet_j9.to_csv('./Data/envimet_j9.csv')\n",
    "baseline_j9.to_csv('./Data/' + base_name +'_j9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4e2ef-a37f-4d3a-95f9-31c707c7891e",
   "metadata": {},
   "source": [
    "# 5. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4529b3-a1a4-4fdf-91e6-0dfe21411fad",
   "metadata": {},
   "source": [
    "## 5.1 Comparing two baseline station:\n",
    "## *PHX station* VS. *ASU facilities*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951855ce-a03f-4de7-b891-f148308ebc74",
   "metadata": {},
   "source": [
    "NOTE! You can run this only if you have *asu_j9.csv* file. \n",
    "To get that file run this notebook using ASU facilities data as your baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1eedb9-a815-4120-803e-9e39b7126dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Get station_j9, asu_j9\n",
    "# station_j9 = pd.read_csv(\"./Data/station_j9.csv\", index_col=0)\n",
    "# asu_j9 = pd.read_csv(\"./Data/asu_j9.csv\", index_col=0)\n",
    "\n",
    "# temp_df = pd.DataFrame()\n",
    "# name = ['station', 'asu', 'envimet ']\n",
    "# dfs = [station_j9, asu_j9, envimet_j9]\n",
    "\n",
    "# # 2. get air temp in each df\n",
    "# i = 0\n",
    "# for df in dfs:\n",
    "#     temp_df[name[i]] = df['Air Temp']\n",
    "#     i+= 1\n",
    "\n",
    "\n",
    "# # 3. Set time as index\n",
    "# temp_df['Time'] = baseline_j9['Time']\n",
    "# temp_df = temp_df.set_index('Time')\n",
    "\n",
    "# # 4. plot\n",
    "# temp_df.plot(figsize=(10, 5), title = bldname + ' Air Temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38ceb8-f25b-4165-b5fe-2470ae7d72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. get humidty in each df\n",
    "# humid_df = pd.DataFrame()\n",
    "# i = 0\n",
    "# for df in dfs:\n",
    "#     humid_df[name[i]] = df['Rel Humid']\n",
    "#     i+= 1\n",
    "\n",
    "# # 2. Set time as index\n",
    "# humid_df['Time'] = baseline_j9['Time']\n",
    "# humid_df = humid_df.set_index('Time')\n",
    "\n",
    "# # 3. plot \n",
    "# humid_df.plot(figsize=(10, 5), title = bldname + ' Rel Humidity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11113220-7418-4f1d-a302-894ffdfba123",
   "metadata": {},
   "source": [
    "## 5.2 Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05e2d0-f268-4d16-aae0-d8aa92ef90fd",
   "metadata": {},
   "source": [
    "### 5.2.1 For weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d2940-79b4-4da8-ae0f-e61cfb537bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.boxplot(by ='Month', column =['Air Temp'], grid = False, figsize = (7, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9194f-cfeb-4914-bed3-ff911ab56207",
   "metadata": {},
   "source": [
    "There is no outliers for air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0592e1-243d-4765-a1e4-d6732bd0f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.boxplot(by ='Month', column =['Rel Humid'], grid = False, figsize = (7, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3237ad-a44e-4ca0-9e59-b26678495ece",
   "metadata": {},
   "source": [
    "### 5.1.2 For CHWTON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec62cc-a629-48a4-b281-3b0826fc24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.boxplot(by ='Month', column =['CHWTON'], grid = False, figsize = (7, 6))\n",
    "plt.suptitle(bldname + ' - before removing outliers')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a1467-f91d-4f22-a60a-0887f561d8c5",
   "metadata": {},
   "source": [
    "### 5.1.3 Detect Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a26837-e3f0-40d2-81f7-75c4b31a84c9",
   "metadata": {},
   "source": [
    "We will use isolation Forest to detect outliers for CHWTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478338c9-fadd-4dee-951c-e9c5f914070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get CHWTON column\n",
    "x = baseline_df[['CHWTON']]\n",
    "\n",
    "# 2. Use row number as index instead of dates\n",
    "x = x.reset_index(drop = True)\n",
    "x['index'] = x.index\n",
    "x = x[['index','CHWTON']]\n",
    "\n",
    "# 3. Convert as numpy\n",
    "x = x.values\n",
    "print('numpy: \\n', x, '\\n')\n",
    "\n",
    "# 4. Create iForest model and train\n",
    "iForestModel = IsolationForest(contamination=.1)\n",
    "iForestModel.fit(x)\n",
    "\n",
    "# 5. Get outliers detection (-1 means outliers). The result is a numpy \n",
    "outliers_prediction = iForestModel.predict(x)\n",
    "\n",
    "# 6. Get indices of the outliers.\n",
    "# it's a tuplel\n",
    "outliers_index = np.where(outliers_prediction < 0)\n",
    "print('outliers index: \\n', outliers_index,'\\n')\n",
    "\n",
    "# 7. Get outliers prediction as df so we can remove it\n",
    "outliers_df = pd.DataFrame({'dropIndex':outliers_prediction})\n",
    "\n",
    "# 8. Plot\n",
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.scatter(x[outliers_index,0], x[outliers_index,1], edgecolors='r')\n",
    "plt.title(bldname)\n",
    "plt.xlabel(\"row_index\")\n",
    "plt.ylabel(\"CHWTON\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5d7ac-685a-451e-919e-6b828a11f87a",
   "metadata": {},
   "source": [
    "### 5.1.4 Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60308e28-fb5c-43cd-86ab-7f2734792185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reset Index so we can merge outliers and original data on index\n",
    "baseline_df_reset_index = baseline_df.reset_index()\n",
    "\n",
    "# 2. Merge outliers data and original data\n",
    "baseline_df_reset_index = pd.merge(baseline_df_reset_index, outliers_df, left_index = True, right_index = True)\n",
    "\n",
    "# 3. Remove outliers\n",
    "baseline_df_outl_removed = baseline_df_reset_index[baseline_df_reset_index .dropIndex == 1]\n",
    "baseline_df_outl_removed\n",
    "\n",
    "# 4. Remove dropIndex Column\n",
    "baseline_df_outl_removed.drop(columns = ['dropIndex'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec9fd7-4421-4139-a092-01a5a40715e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df_outl_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7962cdb-7d46-4573-bd07-7eb4f2ea9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df_outl_removed.boxplot(by ='Month', column =['CHWTON'], grid = False, figsize = (7, 6))\n",
    "plt.suptitle(bldname + ' - after removing outliers')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888dafb-6aec-4b5a-b874-deb973aba9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put back our date as index\n",
    "baseline_df = baseline_df_outl_removed\n",
    "baseline_df.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d77199-f83f-40b3-a10b-690e4e53dc3a",
   "metadata": {},
   "source": [
    "## 5.2 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f833d54-9677-4c71-aba1-da46203054e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = baseline_df.corr()\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(corrMatrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927e0df-112e-4fba-89d7-d019b9235067",
   "metadata": {},
   "source": [
    "## 5.3 Multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700cca6-109e-44b8-a079-87cc4faf8711",
   "metadata": {},
   "source": [
    "A simple method to detect multicollinearity in a model is by using something called the variance inflation factor or the VIF for each predicting variable. An acceptable VIF is if it’s less than the max of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a826edd-daf9-496e-b92f-2bcadbd83703",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get X and Y\n",
    "Y = baseline_df['CHWTON']\n",
    "X = baseline_df.drop(labels = ['CHWTON'], axis = 1)\n",
    "\n",
    "X_int = X.drop(labels = ['Month', 'Time'], axis = 1)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_int.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_int.values, i) for i in range(len(X_int.columns))]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f84ee-452d-4f45-ba11-ce06eaed8a43",
   "metadata": {},
   "source": [
    "# 6. Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11a3af-50da-4091-8db9-254c79ccaef0",
   "metadata": {},
   "source": [
    "Scoring:\n",
    "One one hand, RMSE tells us the typical distance between the predicted value made by the regression model and the actual value.\n",
    "\n",
    "On the other hand, R2 tells us how well the predictor variables can explain the variation in the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8407d6-5079-4f49-8067-04ae14d26590",
   "metadata": {},
   "source": [
    "## 6.1 Train Test (all year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ RANDOM FORESTS #################################3\n",
    "# 1. import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Split into train test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "\n",
    "# 2. Set up model. Number of trees 100\n",
    "base_RF = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# 3. Train data\n",
    "base_RF.fit(X_train, Y_train)\n",
    "\n",
    "# 4. Get prediction\n",
    "Y_pred = base_RF.predict(X_test)\n",
    "ModelPred = pd.DataFrame({'Actual CHWTON':Y_test, 'Predicted CHWTON':Y_pred})\n",
    "ModelPred = ModelPred.sort_index()\n",
    "print(ModelPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7982fad-9579-4d84-82f0-93530b378f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for scoring\n",
    "# 1. This function will returns R2 and RMSE score given a model and X, Y tests data\n",
    "def evaluate(model, X_tests, Y_tests):\n",
    "    Y_preds = model.predict(X_tests)\n",
    "    R2 = model.score(X_tests, Y_tests)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(Y_tests, Y_preds))\n",
    "    return [R2, RMSE]\n",
    "\n",
    "# 2. This function will append a new all year score (row) to our scores data frame\n",
    "def append_all_year_score(dataframe, score_list, model_name):\n",
    "    i = dataframe.shape[0] # new index\n",
    "    dataframe.loc[ i, 'model' ] = model_name\n",
    "    dataframe.loc[ i, ('all_year','R2') ] = score_list[0]\n",
    "    dataframe.loc[ i, ('all_year','RMSE') ] = score_list[1]\n",
    "    return dataframe\n",
    "\n",
    "# 3. This function will append a new June 9th score (column) to our scores data frame of the last row\n",
    "def append_j9_score(dataframe, score_list, isEnvimet = False):\n",
    "    # 1. Check which baseline model we used\n",
    "    data_name = 'baseline'\n",
    "    if(isEnvimet == True):\n",
    "        data_name = 'envimet'\n",
    "    \n",
    "    # 2. get last index\n",
    "    i = dataframe.shape[0] - 1 \n",
    "    \n",
    "    # 3.  add scores to the last index\n",
    "    dataframe.loc[i, (data_name, 'R2')] = score_list[0]\n",
    "    dataframe.loc[i, (data_name, 'RMSE')] = score_list[1]\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# 4. This function will append all scores to score df\n",
    "# it will call evaluate(), append_all_year_score(), and append_j9_score() above\n",
    "def get_model_score_df(pModel, pX_test, pY_test, pX_j9, pX_j9_envi, pY_j9, pScore_df, pModel_name):\n",
    "    # 1. all year \n",
    "    all_year_score = evaluate(pModel, pX_test, pY_test) # evaluate\n",
    "    pScore_df = append_all_year_score(pScore_df, all_year_score, pModel_name) # append to score_df\n",
    "    \n",
    "    # 2. weather station\n",
    "    weather_st_score = evaluate(pModel, pX_j9, pY_j9) # evaluate\n",
    "    pScore_df = append_j9_score(pScore_df, weather_st_score, isEnvimet = False)  # append to score_df\n",
    "    \n",
    "    # 3. envimet\n",
    "    envimet_score = evaluate(pModel, pX_j9_envi, pY_j9) # evaluate\n",
    "    pScore_df = append_j9_score(pScore_df, envimet_score, isEnvimet = True) # append to score_df\n",
    "\n",
    "    return pScore_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d870d2-de87-4ceb-85f9-9490abda7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get score\n",
    "r2rmse = evaluate(base_RF, X_test, Y_test)\n",
    "\n",
    "# 2. create score df\n",
    "arrays = [[\"all_year\", \"all_year\"],['R2', 'RMSE']]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples)\n",
    "scores_df = pd.DataFrame([[2,1]], columns=index)\n",
    "\n",
    "# 3. fill model name and score\n",
    "scores_df['model'] = 'base RF'\n",
    "scores_df['all_year', 'R2'] = r2rmse[0]\n",
    "scores_df['all_year', 'RMSE'] = r2rmse[1]\n",
    "scores_df = scores_df[['model', 'all_year']]\n",
    "scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd7913-16c3-4e98-92e2-d6b101f553d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_list = list(X_train.columns)\n",
    "feature_imp = pd.Series(base_RF.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(\"\\033[1m\" + \"Feature Importances:\" + \"\\033[0m\")\n",
    "print(feature_imp, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365c4eb-50f7-492d-bea1-74322741ce20",
   "metadata": {},
   "source": [
    "## 6.2 June 9th Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c671c8c-72d4-4126-8033-f823696ba22c",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91ba6c-659f-4724-a4e1-4bf0c98b01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get X and Y (all test)\n",
    "X_j9 = baseline_j9.drop(labels = ['CHWTON'], axis = 1)\n",
    "Y_j9 = baseline_j9['CHWTON']\n",
    "\n",
    "# 2. calc scores \n",
    "base_score = evaluate(base_RF, X_j9, Y_j9)\n",
    "\n",
    "# 3. insert scores to scores_df row 0 to 1\n",
    "scores_df = append_j9_score(scores_df, base_score, isEnvimet = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87bbc2-fef7-486c-8360-3dafc679dcc5",
   "metadata": {},
   "source": [
    "### Microclimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb686a-4b9d-41e6-b94a-253557aa3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get X and Y (all test)\n",
    "X_j9_envi = envimet_j9.drop(labels = ['CHWTON'], axis = 1)\n",
    "\n",
    "# 2. calc scores \n",
    "base_score = evaluate(base_RF, X_j9_envi, Y_j9)\n",
    "\n",
    "# 3. insert scores to scores_df row 0 to 1\n",
    "scores_df = append_j9_score(scores_df, base_score, isEnvimet = True)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8098c0a-62a3-48ef-8596-9037137efa4c",
   "metadata": {},
   "source": [
    "# 7. Model 2: RF using Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c3899-0fa3-49bb-a046-032b4af609e5",
   "metadata": {},
   "source": [
    "## 7.1 RF Set parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9bfde8-b977-4c95-aa83-418c36819871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "\n",
    "# 2. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 3. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 4. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 1, 2, 4]\n",
    "\n",
    "# 5. Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# 6. Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91589409-4733-4b1e-9466-05a9f09de121",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.2 RF Train, Test, Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eccdfb-e54b-4335-8dff-b9e370c3ed06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# 1.Create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# 2. Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# 3. Fit the random search model\n",
    "rf_random.fit(X_train, Y_train)\n",
    "\n",
    "# 4. print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(rf_random.best_estimator_.get_params())\n",
    "pprint(rf_random.best_score_)\n",
    "\n",
    "# 5. get the best model\n",
    "random_RF = rf_random.best_estimator_\n",
    "\n",
    "\n",
    "# 6. get all score as df\n",
    "scores_df = get_model_score_df(random_RF,\n",
    "                               X_test, Y_test,\n",
    "                               X_j9,X_j9_envi,\n",
    "                               Y_j9,\n",
    "                               scores_df,\n",
    "                               'random RF')    \n",
    "scores_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b6a68-3b32-4267-8016-87917241979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  1. Get all yearscore\n",
    "# random_rf_score = evaluate(random_RF, X_test, Y_test)\n",
    "# scores_df = append_all_year_score(scores_df, random_rf_score , 'random RF')\n",
    "\n",
    "# # 2. Weather Station\n",
    "# random_score = evaluate(random_RF, X_j9, Y_j9)\n",
    "# scores_df = append_j9_score(scores_df, random_score, isEnvimet = False)\n",
    "\n",
    "# # 3. Microclimate\n",
    "# random_score = evaluate(random_RF, X_j9_envi, Y_j9)\n",
    "# scores_df = append_j9_score(scores_df, random_score, isEnvimet = True)\n",
    "# scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf38de8-05c6-40e0-8a0e-7388101f0f92",
   "metadata": {},
   "source": [
    "# 8. Model 3: Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4e229-2dc2-46ca-9aef-7946ec970fad",
   "metadata": {},
   "source": [
    "## 8.1 Catboost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b04a49-9865-4167-99f9-37b6cf41925e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "\n",
    "# 1. initialize model and grid\n",
    "catboost = cb.CatBoostRegressor(loss_function='RMSE')\n",
    "grid = {'depth': [2, 4, 8, 10],\n",
    "        'iterations': [50, 100, 150, 200],\n",
    "        'learning_rate': [0.03, 0.1],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3, 5]}\n",
    "\n",
    "\n",
    "# 2. search parameter\n",
    "train_dataset = cb.Pool(X_train, Y_train) \n",
    "test_dataset = cb.Pool(X_test, Y_test)\n",
    "result = catboost.grid_search(grid,\n",
    "                           train_dataset,\n",
    "                           cv = 5,\n",
    "                           search_by_train_test_split=True,\n",
    "                           shuffle = True,\n",
    "                           refit = True,\n",
    "                           verbose = True,\n",
    "                           train_size = 0.8 )\n",
    "\n",
    "\n",
    "# 3. get best params\n",
    "best_params = result['params']\n",
    "\n",
    "# 4. fit model with best params\n",
    "grid_CB = cb.CatBoostRegressor(depth = best_params['depth'],\n",
    "                               iterations = best_params['iterations'],\n",
    "                               learning_rate= best_params['learning_rate'],\n",
    "                               l2_leaf_reg = best_params['l2_leaf_reg'])\n",
    "grid_CB.fit(train_dataset)\n",
    "\n",
    "# 5. get score as df\n",
    "scores_df = get_model_score_df(grid_CB,\n",
    "                               X_test, Y_test,\n",
    "                               X_j9,X_j9_envi,\n",
    "                               Y_j9,\n",
    "                               scores_df,\n",
    "                               'grid CB')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e52e9-2262-4e4a-83d7-fbdbdb476d31",
   "metadata": {},
   "source": [
    "## 8.2 Catboost Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749add5-0cfd-4bb1-9e50-03a0b75d0da9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# catboost = cb.CatBoostRegressor(loss_function='RMSE', random_state = 42)\n",
    "\n",
    "# 1. hyperparameter grid\n",
    "cb_grid = {'iterations': [50, 100, 150, 200, 250],\n",
    "            'learning_rate': [0.03, 0.1],\n",
    "            'depth': [2, 4, 8, 10, 12],\n",
    "            'l2_leaf_reg': [0.2, 0.5, 1, 3, 5, 7]}\n",
    "\n",
    "# 2. instantiate RandomSearchCv object\n",
    "catboost_random = RandomizedSearchCV(estimator = catboost,\n",
    "                               param_distributions = cb_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose = 2,\n",
    "                               scoring ='r2',\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "\n",
    "# 3. Fit the model\n",
    "catboost_random.fit(X_train,Y_train)\n",
    "\n",
    "# 4. print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(catboost_random.best_estimator_.get_params())\n",
    "pprint(catboost_random.best_score_)\n",
    "\n",
    "# 5. get the best model\n",
    "random_CB = catboost_random.best_estimator_\n",
    "\n",
    "# 6. get score\n",
    "scores_df = get_model_score_df(random_CB,\n",
    "                               X_test, Y_test,\n",
    "                               X_j9,X_j9_envi,\n",
    "                               Y_j9,\n",
    "                               scores_df,\n",
    "                               'random CB')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dee384-d7ee-4036-83a9-04ea3176dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bldname)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806ec6a-9906-4d41-85d3-8c917ee841e8",
   "metadata": {},
   "source": [
    "# 9. Model 4: Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e33839-00f1-4e54-87b6-60ab269ce660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adaboost = AdaBoostRegressor(random_state = 42)\n",
    "\n",
    "\n",
    "# 1. hyperparameter grid\n",
    "adaBoost_params = {'learning_rate':[0.05,0.1,0.2,0.6,0.8,1],\n",
    "                   'n_estimators': [50,60,100],\n",
    "                   'loss' : ['linear', 'square', 'exponential']}\n",
    "\n",
    "# 2. instantiate RandomSearchCv object\n",
    "adaboost_random = RandomizedSearchCV(adaboost,\n",
    "                                     param_distributions=adaBoost_params,\n",
    "                                     n_iter = 100,\n",
    "                                     scoring ='r2',\n",
    "                                     random_state = 42,\n",
    "                                     n_jobs = -1)\n",
    "\n",
    "# 3. Fit the model\n",
    "adaboost_random.fit(X_train,Y_train)\n",
    "\n",
    "# 4. print winning set of hyperparameters\n",
    "pprint(adaboost_random.best_estimator_.get_params())\n",
    "pprint(adaboost_random.best_score_)\n",
    "\n",
    "# 5. get the best model\n",
    "random_ADA = adaboost_random.best_estimator_\n",
    "\n",
    "# 6. get score\n",
    "scores_df = get_model_score_df(random_ADA,\n",
    "                               X_test, Y_test,\n",
    "                               X_j9,X_j9_envi,\n",
    "                               Y_j9,\n",
    "                               scores_df,\n",
    "                               'random ADA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d77abe-0df3-4978-bb53-7d16706d6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bldname)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96959657-12c5-419c-b8bb-d6604e784565",
   "metadata": {},
   "source": [
    "# 10. Save Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a6043-df1d-42e0-9388-170e1aafb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "scores_df['bld_name'] = bldname\n",
    "scores_df = scores_df[['bld_name', 'model', 'all_year', 'baseline', 'envimet']]\n",
    "scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a386b-5edc-48b7-a386-37dfec81faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(base_name == 'station'):\n",
    "    pathname = './Data/scores.csv'\n",
    "else:\n",
    "    pathname = './Data/scores_asu.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e8fa0-8448-4be8-b3d5-e2575b4db631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. if file does not exist write header \n",
    "if not os.path.isfile(pathname):\n",
    "    scores_df.to_csv(pathname, header='column_names')\n",
    "else: # 2. else it exists so append without writing the header\n",
    "    with open(pathname,'a') as f:\n",
    "        \n",
    "        f.write('\\n')  # 4. got to next line before writing\n",
    "    # 5. write:\n",
    "    scores_df.to_csv(pathname, index = True, header = False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be894292-4827-46b1-8c34-6ec513d4db09",
   "metadata": {},
   "source": [
    "# 11. Get prediction of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea93c54-1395-4c23-9504-9526754905ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get best model\n",
    "best_model = grid_CB\n",
    "\n",
    "# 2. get weather station prediction\n",
    "Y_pred_j9 = best_model.predict(X_j9)\n",
    "\n",
    "# 3. get envimet prediction\n",
    "Y_pred_j9_envi = best_model.predict(X_j9_envi)\n",
    "\n",
    "# 4. show predictions\n",
    "Pred = pd.DataFrame({'Actual':Y_j9,'Baseline Predictions (AZW)': Y_pred_j9, 'Microclimate Predictions': Y_pred_j9_envi})\n",
    "Pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50086d1d-8cc9-4ab1-a013-f6a2897ff0bf",
   "metadata": {},
   "source": [
    "# 12. Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de764d-ae41-41bf-a5a3-651cffecaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([Y_pred_j9, Y_pred_j9_envi])\n",
    "plt.xticks([1,2],['Baseline_pred', 'Microclimate_pred'])\n",
    "print(Y_pred_j9.mean())\n",
    "print(Y_pred_j9_envi.mean())\n",
    "print('mu:', Y_pred_j9.mean()- Y_pred_j9_envi.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364231d",
   "metadata": {},
   "source": [
    "# Two-Sample T Test\n",
    "\n",
    "\n",
    "mean differences in CHWTON = $ \\mu_{baseline} - \\mu_{microclimate}$ \n",
    "\n",
    "$ H_0: $ Mean of CHWTON in baseline and microclimate are the same\n",
    "\n",
    "$ H_1: $ Mean of CHWTON in baseline and microclimate are NOT the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16c2e6-e6cd-4a43-bcf4-8e7c843c47cd",
   "metadata": {},
   "source": [
    "## 12.1 calculate standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8632054-a03d-4c1d-a822-37cea5e7dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.variance\n",
    "var_baseline = Y_pred_j9.var(ddof = 1)\n",
    "var_micro = Y_pred_j9_envi.var(ddof = 1)\n",
    "print('var:',var_baseline, var_micro)\n",
    "\n",
    "# 2. standard deviation\n",
    "s = np.sqrt((var_baseline + var_micro)/2)\n",
    "print('s:',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e0198-7135-481e-aeed-eaf39ea9e6b5",
   "metadata": {},
   "source": [
    "## 12.2 calculate T-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5af72c-d801-4bd2-84c1-ced1e04d87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "t_stat, p_val = stats.ttest_ind(Y_pred_j9, Y_pred_j9_envi, equal_var=False)\n",
    "print('t statistics: ', t_stat)\n",
    "print('p value: ', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d48f93-ec9b-4cc3-b977-f63f8991e9b7",
   "metadata": {},
   "source": [
    "P value is not less that 0.05. We cannot reject the null hypothesis. There is no significant difference between the transaction amount of fraud and non fraudulent transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c06839-9ef6-4378-befa-8e6caf8ad667",
   "metadata": {},
   "source": [
    "# 13. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33a9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Plotting Baseline Model for all 2018 15-min Data #######\n",
    "\n",
    "## This is a big graph, will be slow to run but gives visual of prediction accuracy\n",
    "# %matplotlib qt\n",
    "plt.xlabel('Baseline 15-Min Model')\n",
    "plt.ylabel('CHWTON')\n",
    "plt.plot(ModelPred['Actual CHWTON'], label = 'Actual CHWT')\n",
    "plt.plot(ModelPred['Predicted CHWTON'], label = 'Predicted CHWT')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5613547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting ENVI-met vs AZW vs Actual Data for June 9 from 5a - 8p\n",
    "positions = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "labels = ['5a', '6a', '7a', '8a', '9a', '10a', '11a', '12p', '1p', '2p', '3p', '4p', '5p', '6p', '7p', '8p']\n",
    "\n",
    "# plot EnviMet vs AZ_Weather results\n",
    "plt.xlabel('Time 5a - 8p')\n",
    "plt.ylabel('CHWTON')\n",
    "plt.xticks(positions, labels)\n",
    "plt.plot(Pred['Microclimate Predictions'], label = 'ENVIMET Prediction')\n",
    "plt.plot(Pred['Baseline Predictions (AZW)'], label = 'Baseline Prediction')\n",
    "plt.plot(Pred['Actual'], label = 'Actual Data')\n",
    "plt.title(bldname)\n",
    "plt.legend()\n",
    "\n",
    "## show graphs\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f0357-801c-4cff-9e73-524a1f23612a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139a1a6-83c4-425e-9243-76d1f14ab4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myConda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

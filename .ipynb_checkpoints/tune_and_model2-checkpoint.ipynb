{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# graph\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "#  for multicolinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = ['Month', 'Time']\n",
    "\n",
    "dict_dtypes = {x : 'str'  for x in string_cols}\n",
    "\n",
    "# 1. all year data\n",
    "all_year = pd.read_csv('./Data//weather_station_numstr', index_col = 0, dtype = dict_dtypes)\n",
    "weather_j9 = pd.read_csv('./Data/weather_j9', index_col = 0, dtype = dict_dtypes)\n",
    "envi_j9 = pd.read_csv('./Data/weather_j9', index_col = 0, dtype = dict_dtypes)\n",
    "\n",
    "# 2. score data\n",
    "scores_df = pd.read_csv('./Data/score', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "all_year_dum = pd.read_csv('./Data/weather_st', index_col = 0, dtype = dict_dtypes)\n",
    "all_year_dum = all_year_dum.drop(labels = ['Hour_num', 'Month_num','Minute_num'], axis = 1)\n",
    "\n",
    "# 1. dummify dates and time\n",
    "all_year_dum = pd.get_dummies(all_year_dum, prefix=None, prefix_sep='_')\n",
    "\n",
    "# 2. get j9 data\n",
    "j9_dum = all_year_dum.iloc[15150:15246]\n",
    "\n",
    "# 3. concat j9_dum with j9 to remove non 0 minute\n",
    "j9_dum =  pd.concat([j9_dum, j9.drop(labels = ['Air Temp', 'Rel Humid', 'KW'], axis = 1)], axis = 1, join = \"inner\")\n",
    "\n",
    "# 3. drop June 9th data on original data\n",
    "all_year_dum = all_year_dum.drop(all_year_dum.index[15150:15246])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get X and Y\n",
    "X_dum = all_year_dum.drop(labels = ['CHWTON'], axis =1)\n",
    "\n",
    "# 5. Train test split\n",
    "X_train_dum, X_test_dum, Y_train, Y_test = train_test_split(X_dum, Y, test_size=0.2, random_state = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "    'n_estimators':[50, 100 , 250],\n",
    "    'min_child_weight':[4,5], \n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "reg = XGBRegressor()\n",
    "\n",
    "n_iter_search = 20\n",
    "xgb_random = RandomizedSearchCV(reg,\n",
    "                                param_distributions = params,\n",
    "                                n_iter = n_iter_search,\n",
    "                                cv = 5,\n",
    "                                verbose = 2,\n",
    "                                random_state = 20,\n",
    "                                scoring ='r2',\n",
    "                                n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "xgb_random.fit(X_train_dum, Y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. print winning set of hyperparameters\n",
    "pprint(xgb_random.best_estimator_.get_params())\n",
    "pprint(xgb_random.best_score_)\n",
    "\n",
    "# 2. save model\n",
    "xgb_best = xgb_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# June 9th prediction\n",
    "# 1. get X\n",
    "X_j9_dum = j9_dum.drop(labels = ['CHWTON', 'Month', 'Time'], axis = 1)\n",
    "\n",
    "# 2. Ypred\n",
    "Y_pred_xgb_j9 = xgb_best.predict(X_j9_dum)\n",
    "\n",
    "# 3. Score\n",
    "R2_j9_xgb = xgb_best.score(X_j9_dum, Y_j9)\n",
    "RMSE_j9_xgb = np.sqrt(metrics.mean_squared_error(Y_j9, Y_pred_xgb_j9))\n",
    "\n",
    "# 4. append to score df\n",
    "score_J9_xgb = [R2_j9_xgb, RMSE_j9_xgb]\n",
    "scores_df['XGB_J9_AZ'] = score_J9_xgb\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
